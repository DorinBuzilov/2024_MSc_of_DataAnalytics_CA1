{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d81b2d76",
   "metadata": {},
   "source": [
    "# Customer Churn Forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b71aa5a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://10.0.2.15:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.1.3</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=PySparkShell>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "eaf1a19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2194fec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = spark.read.csv('/CA1_customer_churn/customer_churn.csv', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cae18329",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+---------+--------------------+--------------+--------------+----------------+----------------+-----------------------+---------+-----------+------+---+--------------+-----+\n",
      "|Call  Failure|Complains|Subscription  Length|Charge  Amount|Seconds of Use|Frequency of use|Frequency of SMS|Distinct Called Numbers|Age Group|Tariff Plan|Status|Age|Customer Value|Churn|\n",
      "+-------------+---------+--------------------+--------------+--------------+----------------+----------------+-----------------------+---------+-----------+------+---+--------------+-----+\n",
      "|            8|        0|                  38|             0|          4370|              71|               5|                     17|        3|          1|     1| 30|        197.64|    0|\n",
      "|            0|        0|                  39|             0|           318|               5|               7|                      4|        2|          1|     2| 25|        46.035|    0|\n",
      "|           10|        0|                  37|             0|          2453|              60|             359|                     24|        3|          1|     1| 30|       1536.52|    0|\n",
      "|           10|        0|                  38|             0|          4198|              66|               1|                     35|        1|          1|     1| 15|        240.02|    0|\n",
      "|            3|        0|                  38|             0|          2393|              58|               2|                     33|        1|          1|     1| 15|       145.805|    0|\n",
      "+-------------+---------+--------------------+--------------+--------------+----------------+----------------+-----------------------+---------+-----------+------+---+--------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a496adf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Call  Failure</th>\n",
       "      <th>Complains</th>\n",
       "      <th>Subscription  Length</th>\n",
       "      <th>Charge  Amount</th>\n",
       "      <th>Seconds of Use</th>\n",
       "      <th>Frequency of use</th>\n",
       "      <th>Frequency of SMS</th>\n",
       "      <th>Distinct Called Numbers</th>\n",
       "      <th>Age Group</th>\n",
       "      <th>Tariff Plan</th>\n",
       "      <th>Status</th>\n",
       "      <th>Age</th>\n",
       "      <th>Customer Value</th>\n",
       "      <th>Churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>4370</td>\n",
       "      <td>71</td>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>197.64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>318</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>46.035</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>2453</td>\n",
       "      <td>60</td>\n",
       "      <td>359</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>1536.52</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>4198</td>\n",
       "      <td>66</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>240.02</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>2393</td>\n",
       "      <td>58</td>\n",
       "      <td>2</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>145.805</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>3775</td>\n",
       "      <td>82</td>\n",
       "      <td>32</td>\n",
       "      <td>28</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>282.28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>2360</td>\n",
       "      <td>39</td>\n",
       "      <td>285</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>1235.96</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>2</td>\n",
       "      <td>9115</td>\n",
       "      <td>121</td>\n",
       "      <td>144</td>\n",
       "      <td>43</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>945.44</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>13773</td>\n",
       "      <td>169</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>557.68</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>4515</td>\n",
       "      <td>83</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>191.92</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Call  Failure Complains Subscription  Length Charge  Amount Seconds of Use  \\\n",
       "0             8         0                   38              0           4370   \n",
       "1             0         0                   39              0            318   \n",
       "2            10         0                   37              0           2453   \n",
       "3            10         0                   38              0           4198   \n",
       "4             3         0                   38              0           2393   \n",
       "5            11         0                   38              1           3775   \n",
       "6             4         0                   38              0           2360   \n",
       "7            13         0                   37              2           9115   \n",
       "8             7         0                   38              0          13773   \n",
       "9             7         0                   38              1           4515   \n",
       "\n",
       "  Frequency of use Frequency of SMS Distinct Called Numbers Age Group  \\\n",
       "0               71                5                      17         3   \n",
       "1                5                7                       4         2   \n",
       "2               60              359                      24         3   \n",
       "3               66                1                      35         1   \n",
       "4               58                2                      33         1   \n",
       "5               82               32                      28         3   \n",
       "6               39              285                      18         3   \n",
       "7              121              144                      43         3   \n",
       "8              169                0                      44         3   \n",
       "9               83                2                      25         3   \n",
       "\n",
       "  Tariff Plan Status Age Customer Value Churn  \n",
       "0           1      1  30         197.64     0  \n",
       "1           1      2  25         46.035     0  \n",
       "2           1      1  30        1536.52     0  \n",
       "3           1      1  15         240.02     0  \n",
       "4           1      1  15        145.805     0  \n",
       "5           1      1  30         282.28     0  \n",
       "6           1      1  30        1235.96     0  \n",
       "7           1      1  30         945.44     0  \n",
       "8           1      1  30         557.68     0  \n",
       "9           1      1  30         191.92     0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "042b4909",
   "metadata": {},
   "source": [
    "ANN vs RNN (Recurrent neural networks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a067d0e2",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b1370d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Call  Failure',\n",
       " 'Complains',\n",
       " 'Subscription  Length',\n",
       " 'Charge  Amount',\n",
       " 'Seconds of Use',\n",
       " 'Frequency of use',\n",
       " 'Frequency of SMS',\n",
       " 'Distinct Called Numbers',\n",
       " 'Age Group',\n",
       " 'Tariff Plan',\n",
       " 'Status',\n",
       " 'Age',\n",
       " 'Customer Value',\n",
       " 'Churn']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d7607e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3150"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1bb8289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+-------------------+--------------------+------------------+------------------+------------------+------------------+-----------------------+------------------+-------------------+-------------------+------------------+------------------+-------------------+\n",
      "|summary|    Call  Failure|          Complains|Subscription  Length|    Charge  Amount|    Seconds of Use|  Frequency of use|  Frequency of SMS|Distinct Called Numbers|         Age Group|        Tariff Plan|             Status|               Age|    Customer Value|              Churn|\n",
      "+-------+-----------------+-------------------+--------------------+------------------+------------------+------------------+------------------+-----------------------+------------------+-------------------+-------------------+------------------+------------------+-------------------+\n",
      "|  count|             3150|               3150|                3150|              3150|              3150|              3150|              3150|                   3150|              3150|               3150|               3150|              3150|              3150|               3150|\n",
      "|   mean|7.627936507936508|0.07650793650793651|   32.54190476190476|0.9428571428571428| 4472.459682539683| 69.46063492063492| 73.17492063492064|      23.50984126984127| 2.826031746031746| 1.0777777777777777| 1.2482539682539682|30.998412698412697|470.97291587301663|0.15714285714285714|\n",
      "| stddev|7.263885566996695| 0.2658512916524746|    8.57348206132722|1.5210718803527452|4197.9086865043355|57.413307750632974|112.23755969319922|     17.217337437991915|0.8925551072658298|0.26786409466734173|0.43206851309493083| 8.831095499304958| 517.0154327987635|  0.363993187078456|\n",
      "|    min|                0|                  0|                  10|                 0|                 0|                 0|                 0|                      0|                 1|                  1|                  1|                15|                 0|                  0|\n",
      "|    max|                9|                  1|                   9|                 9|              9950|                99|                99|                     97|                 5|                  2|                  2|                55|            999.32|                  1|\n",
      "+-------+-----------------+-------------------+--------------------+------------------+------------------+------------------+------------------+-----------------------+------------------+-------------------+-------------------+------------------+------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b41b5e5e",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e1469d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Call  Failure</th>\n",
       "      <th>Complains</th>\n",
       "      <th>Subscription  Length</th>\n",
       "      <th>Charge  Amount</th>\n",
       "      <th>Seconds of Use</th>\n",
       "      <th>Frequency of use</th>\n",
       "      <th>Frequency of SMS</th>\n",
       "      <th>Distinct Called Numbers</th>\n",
       "      <th>Age Group</th>\n",
       "      <th>Tariff Plan</th>\n",
       "      <th>Status</th>\n",
       "      <th>Age</th>\n",
       "      <th>Customer Value</th>\n",
       "      <th>Churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>4370</td>\n",
       "      <td>71</td>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>197.64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>318</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>46.035</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>2453</td>\n",
       "      <td>60</td>\n",
       "      <td>359</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>1536.52</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>4198</td>\n",
       "      <td>66</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>240.02</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>2393</td>\n",
       "      <td>58</td>\n",
       "      <td>2</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>145.805</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3145</th>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>6697</td>\n",
       "      <td>147</td>\n",
       "      <td>92</td>\n",
       "      <td>44</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>721.98</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3146</th>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>9237</td>\n",
       "      <td>177</td>\n",
       "      <td>80</td>\n",
       "      <td>42</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "      <td>261.21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3147</th>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>3157</td>\n",
       "      <td>51</td>\n",
       "      <td>38</td>\n",
       "      <td>21</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>280.32</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3148</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>4695</td>\n",
       "      <td>46</td>\n",
       "      <td>222</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>1077.64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3149</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>1792</td>\n",
       "      <td>25</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>100.68</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3150 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Call  Failure Complains Subscription  Length Charge  Amount  \\\n",
       "0                8         0                   38              0   \n",
       "1                0         0                   39              0   \n",
       "2               10         0                   37              0   \n",
       "3               10         0                   38              0   \n",
       "4                3         0                   38              0   \n",
       "...            ...       ...                  ...            ...   \n",
       "3145            21         0                   19              2   \n",
       "3146            17         0                   17              1   \n",
       "3147            13         0                   18              4   \n",
       "3148             7         0                   11              2   \n",
       "3149             8         1                   11              2   \n",
       "\n",
       "     Seconds of Use Frequency of use Frequency of SMS Distinct Called Numbers  \\\n",
       "0              4370               71                5                      17   \n",
       "1               318                5                7                       4   \n",
       "2              2453               60              359                      24   \n",
       "3              4198               66                1                      35   \n",
       "4              2393               58                2                      33   \n",
       "...             ...              ...              ...                     ...   \n",
       "3145           6697              147               92                      44   \n",
       "3146           9237              177               80                      42   \n",
       "3147           3157               51               38                      21   \n",
       "3148           4695               46              222                      12   \n",
       "3149           1792               25                7                       9   \n",
       "\n",
       "     Age Group Tariff Plan Status Age Customer Value Churn  \n",
       "0            3           1      1  30         197.64     0  \n",
       "1            2           1      2  25         46.035     0  \n",
       "2            3           1      1  30        1536.52     0  \n",
       "3            1           1      1  15         240.02     0  \n",
       "4            1           1      1  15        145.805     0  \n",
       "...        ...         ...    ...  ..            ...   ...  \n",
       "3145         2           2      1  25         721.98     0  \n",
       "3146         5           1      1  55         261.21     0  \n",
       "3147         3           1      1  30         280.32     0  \n",
       "3148         3           1      1  30        1077.64     0  \n",
       "3149         3           1      1  30         100.68     1  \n",
       "\n",
       "[3150 rows x 14 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.toPandas()\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bcdb4e61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3150 entries, 0 to 3149\n",
      "Data columns (total 14 columns):\n",
      " #   Column                   Non-Null Count  Dtype \n",
      "---  ------                   --------------  ----- \n",
      " 0   Call  Failure            3150 non-null   object\n",
      " 1   Complains                3150 non-null   object\n",
      " 2   Subscription  Length     3150 non-null   object\n",
      " 3   Charge  Amount           3150 non-null   object\n",
      " 4   Seconds of Use           3150 non-null   object\n",
      " 5   Frequency of use         3150 non-null   object\n",
      " 6   Frequency of SMS         3150 non-null   object\n",
      " 7   Distinct Called Numbers  3150 non-null   object\n",
      " 8   Age Group                3150 non-null   object\n",
      " 9   Tariff Plan              3150 non-null   object\n",
      " 10  Status                   3150 non-null   object\n",
      " 11  Age                      3150 non-null   object\n",
      " 12  Customer Value           3150 non-null   object\n",
      " 13  Churn                    3150 non-null   object\n",
      "dtypes: object(14)\n",
      "memory usage: 344.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e50177ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert from string object to float\n",
    "df[df.columns.tolist()] = df[df.columns.tolist()].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3cbe36df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Call  Failure</th>\n",
       "      <th>Complains</th>\n",
       "      <th>Subscription  Length</th>\n",
       "      <th>Charge  Amount</th>\n",
       "      <th>Seconds of Use</th>\n",
       "      <th>Frequency of use</th>\n",
       "      <th>Frequency of SMS</th>\n",
       "      <th>Distinct Called Numbers</th>\n",
       "      <th>Age Group</th>\n",
       "      <th>Tariff Plan</th>\n",
       "      <th>Status</th>\n",
       "      <th>Age</th>\n",
       "      <th>Customer Value</th>\n",
       "      <th>Churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3150.000000</td>\n",
       "      <td>3150.000000</td>\n",
       "      <td>3150.000000</td>\n",
       "      <td>3150.000000</td>\n",
       "      <td>3150.000000</td>\n",
       "      <td>3150.000000</td>\n",
       "      <td>3150.000000</td>\n",
       "      <td>3150.000000</td>\n",
       "      <td>3150.000000</td>\n",
       "      <td>3150.000000</td>\n",
       "      <td>3150.000000</td>\n",
       "      <td>3150.000000</td>\n",
       "      <td>3150.000000</td>\n",
       "      <td>3150.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>7.627937</td>\n",
       "      <td>0.076508</td>\n",
       "      <td>32.541905</td>\n",
       "      <td>0.942857</td>\n",
       "      <td>4472.459683</td>\n",
       "      <td>69.460635</td>\n",
       "      <td>73.174921</td>\n",
       "      <td>23.509841</td>\n",
       "      <td>2.826032</td>\n",
       "      <td>1.077778</td>\n",
       "      <td>1.248254</td>\n",
       "      <td>30.998413</td>\n",
       "      <td>470.972916</td>\n",
       "      <td>0.157143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>7.263886</td>\n",
       "      <td>0.265851</td>\n",
       "      <td>8.573482</td>\n",
       "      <td>1.521072</td>\n",
       "      <td>4197.908687</td>\n",
       "      <td>57.413308</td>\n",
       "      <td>112.237560</td>\n",
       "      <td>17.217337</td>\n",
       "      <td>0.892555</td>\n",
       "      <td>0.267864</td>\n",
       "      <td>0.432069</td>\n",
       "      <td>8.831095</td>\n",
       "      <td>517.015433</td>\n",
       "      <td>0.363993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1391.250000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>113.801250</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2990.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>228.480000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6478.250000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>788.388750</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>36.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>17090.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>522.000000</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>2165.280000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Call  Failure    Complains  Subscription  Length  Charge  Amount  \\\n",
       "count    3150.000000  3150.000000           3150.000000     3150.000000   \n",
       "mean        7.627937     0.076508             32.541905        0.942857   \n",
       "std         7.263886     0.265851              8.573482        1.521072   \n",
       "min         0.000000     0.000000              3.000000        0.000000   \n",
       "25%         1.000000     0.000000             30.000000        0.000000   \n",
       "50%         6.000000     0.000000             35.000000        0.000000   \n",
       "75%        12.000000     0.000000             38.000000        1.000000   \n",
       "max        36.000000     1.000000             47.000000       10.000000   \n",
       "\n",
       "       Seconds of Use  Frequency of use  Frequency of SMS  \\\n",
       "count     3150.000000       3150.000000       3150.000000   \n",
       "mean      4472.459683         69.460635         73.174921   \n",
       "std       4197.908687         57.413308        112.237560   \n",
       "min          0.000000          0.000000          0.000000   \n",
       "25%       1391.250000         27.000000          6.000000   \n",
       "50%       2990.000000         54.000000         21.000000   \n",
       "75%       6478.250000         95.000000         87.000000   \n",
       "max      17090.000000        255.000000        522.000000   \n",
       "\n",
       "       Distinct Called Numbers    Age Group  Tariff Plan       Status  \\\n",
       "count              3150.000000  3150.000000  3150.000000  3150.000000   \n",
       "mean                 23.509841     2.826032     1.077778     1.248254   \n",
       "std                  17.217337     0.892555     0.267864     0.432069   \n",
       "min                   0.000000     1.000000     1.000000     1.000000   \n",
       "25%                  10.000000     2.000000     1.000000     1.000000   \n",
       "50%                  21.000000     3.000000     1.000000     1.000000   \n",
       "75%                  34.000000     3.000000     1.000000     1.000000   \n",
       "max                  97.000000     5.000000     2.000000     2.000000   \n",
       "\n",
       "               Age  Customer Value        Churn  \n",
       "count  3150.000000     3150.000000  3150.000000  \n",
       "mean     30.998413      470.972916     0.157143  \n",
       "std       8.831095      517.015433     0.363993  \n",
       "min      15.000000        0.000000     0.000000  \n",
       "25%      25.000000      113.801250     0.000000  \n",
       "50%      30.000000      228.480000     0.000000  \n",
       "75%      30.000000      788.388750     0.000000  \n",
       "max      55.000000     2165.280000     1.000000  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "df.describe(include = 'all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "17f903db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Call  Failure              0\n",
       "Complains                  0\n",
       "Subscription  Length       0\n",
       "Charge  Amount             0\n",
       "Seconds of Use             0\n",
       "Frequency of use           0\n",
       "Frequency of SMS           0\n",
       "Distinct Called Numbers    0\n",
       "Age Group                  0\n",
       "Tariff Plan                0\n",
       "Status                     0\n",
       "Age                        0\n",
       "Customer Value             0\n",
       "Churn                      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "20dc4963",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    2655\n",
       "1.0     495\n",
       "Name: Churn, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(df['Churn'].unique(), df['Churn'].value_counts())\n",
    "df.Churn.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4b6b97",
   "metadata": {},
   "source": [
    "## Correlation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fc0b042c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_2b5a9_row0_col0, #T_2b5a9_row0_col1, #T_2b5a9_row0_col2, #T_2b5a9_row0_col3, #T_2b5a9_row0_col4, #T_2b5a9_row0_col5, #T_2b5a9_row0_col6, #T_2b5a9_row0_col7, #T_2b5a9_row0_col8, #T_2b5a9_row0_col9, #T_2b5a9_row0_col10, #T_2b5a9_row0_col11, #T_2b5a9_row0_col12, #T_2b5a9_row0_col13, #T_2b5a9_row1_col1, #T_2b5a9_row1_col2, #T_2b5a9_row1_col3, #T_2b5a9_row1_col4, #T_2b5a9_row1_col5, #T_2b5a9_row1_col6, #T_2b5a9_row1_col7, #T_2b5a9_row1_col8, #T_2b5a9_row1_col9, #T_2b5a9_row1_col10, #T_2b5a9_row1_col11, #T_2b5a9_row1_col12, #T_2b5a9_row1_col13, #T_2b5a9_row2_col2, #T_2b5a9_row2_col3, #T_2b5a9_row2_col4, #T_2b5a9_row2_col5, #T_2b5a9_row2_col6, #T_2b5a9_row2_col7, #T_2b5a9_row2_col8, #T_2b5a9_row2_col9, #T_2b5a9_row2_col10, #T_2b5a9_row2_col11, #T_2b5a9_row2_col12, #T_2b5a9_row2_col13, #T_2b5a9_row3_col3, #T_2b5a9_row3_col4, #T_2b5a9_row3_col5, #T_2b5a9_row3_col6, #T_2b5a9_row3_col7, #T_2b5a9_row3_col8, #T_2b5a9_row3_col9, #T_2b5a9_row3_col10, #T_2b5a9_row3_col11, #T_2b5a9_row3_col12, #T_2b5a9_row3_col13, #T_2b5a9_row4_col4, #T_2b5a9_row4_col5, #T_2b5a9_row4_col6, #T_2b5a9_row4_col7, #T_2b5a9_row4_col8, #T_2b5a9_row4_col9, #T_2b5a9_row4_col10, #T_2b5a9_row4_col11, #T_2b5a9_row4_col12, #T_2b5a9_row4_col13, #T_2b5a9_row5_col5, #T_2b5a9_row5_col6, #T_2b5a9_row5_col7, #T_2b5a9_row5_col8, #T_2b5a9_row5_col9, #T_2b5a9_row5_col10, #T_2b5a9_row5_col11, #T_2b5a9_row5_col12, #T_2b5a9_row5_col13, #T_2b5a9_row6_col6, #T_2b5a9_row6_col7, #T_2b5a9_row6_col8, #T_2b5a9_row6_col9, #T_2b5a9_row6_col10, #T_2b5a9_row6_col11, #T_2b5a9_row6_col12, #T_2b5a9_row6_col13, #T_2b5a9_row7_col7, #T_2b5a9_row7_col8, #T_2b5a9_row7_col9, #T_2b5a9_row7_col10, #T_2b5a9_row7_col11, #T_2b5a9_row7_col12, #T_2b5a9_row7_col13, #T_2b5a9_row8_col8, #T_2b5a9_row8_col9, #T_2b5a9_row8_col10, #T_2b5a9_row8_col11, #T_2b5a9_row8_col12, #T_2b5a9_row8_col13, #T_2b5a9_row9_col9, #T_2b5a9_row9_col10, #T_2b5a9_row9_col11, #T_2b5a9_row9_col12, #T_2b5a9_row9_col13, #T_2b5a9_row10_col10, #T_2b5a9_row10_col11, #T_2b5a9_row10_col12, #T_2b5a9_row10_col13, #T_2b5a9_row11_col11, #T_2b5a9_row11_col12, #T_2b5a9_row11_col13, #T_2b5a9_row12_col12, #T_2b5a9_row12_col13, #T_2b5a9_row13_col13 {\n",
       "  background-color: #000000;\n",
       "  color: #f1f1f1;\n",
       "  background-color: #f1f1f1;\n",
       "}\n",
       "#T_2b5a9_row1_col0 {\n",
       "  background-color: #eed0c0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_2b5a9_row2_col0, #T_2b5a9_row12_col3 {\n",
       "  background-color: #efcebd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_2b5a9_row2_col1, #T_2b5a9_row6_col0, #T_2b5a9_row13_col11 {\n",
       "  background-color: #dadce0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_2b5a9_row3_col0 {\n",
       "  background-color: #ee8669;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_2b5a9_row3_col1, #T_2b5a9_row8_col5, #T_2b5a9_row13_col2 {\n",
       "  background-color: #d8dce2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_2b5a9_row3_col2, #T_2b5a9_row7_col6 {\n",
       "  background-color: #e7d7ce;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_2b5a9_row4_col0, #T_2b5a9_row7_col0 {\n",
       "  background-color: #f4987a;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_2b5a9_row4_col1, #T_2b5a9_row13_col9 {\n",
       "  background-color: #cedaeb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_2b5a9_row4_col2, #T_2b5a9_row12_col0 {\n",
       "  background-color: #ebd3c6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_2b5a9_row4_col3 {\n",
       "  background-color: #f6a385;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_2b5a9_row5_col0 {\n",
       "  background-color: #f08a6c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_2b5a9_row5_col1, #T_2b5a9_row11_col6 {\n",
       "  background-color: #d1dae9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_2b5a9_row5_col2, #T_2b5a9_row6_col4 {\n",
       "  background-color: #ead5c9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_2b5a9_row5_col3 {\n",
       "  background-color: #f7b093;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_2b5a9_row5_col4 {\n",
       "  background-color: #bd1f2d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_2b5a9_row6_col1, #T_2b5a9_row10_col0 {\n",
       "  background-color: #cdd9ec;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_2b5a9_row6_col2 {\n",
       "  background-color: #e6d7cf;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_2b5a9_row6_col3, #T_2b5a9_row7_col2 {\n",
       "  background-color: #e8d6cc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_2b5a9_row6_col5 {\n",
       "  background-color: #e9d5cb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_2b5a9_row7_col1 {\n",
       "  background-color: #d5dbe5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_2b5a9_row7_col3, #T_2b5a9_row12_col4 {\n",
       "  background-color: #f7a98b;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_2b5a9_row7_col4 {\n",
       "  background-color: #e67259;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_2b5a9_row7_col5 {\n",
       "  background-color: #df634e;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_2b5a9_row8_col0, #T_2b5a9_row11_col7 {\n",
       "  background-color: #e3d9d3;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_2b5a9_row8_col1, #T_2b5a9_row8_col2, #T_2b5a9_row8_col4, #T_2b5a9_row8_col7, #T_2b5a9_row11_col4 {\n",
       "  background-color: #dfdbd9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_2b5a9_row8_col3, #T_2b5a9_row11_col3 {\n",
       "  background-color: #f5c0a7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_2b5a9_row8_col6 {\n",
       "  background-color: #d6dce4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_2b5a9_row9_col0 {\n",
       "  background-color: #f1ccb8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_2b5a9_row9_col1, #T_2b5a9_row10_col8, #T_2b5a9_row11_col1 {\n",
       "  background-color: #dddcdc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_2b5a9_row9_col2 {\n",
       "  background-color: #c6d6f1;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_2b5a9_row9_col3 {\n",
       "  background-color: #f7b99e;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_2b5a9_row9_col4 {\n",
       "  background-color: #edd2c3;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_2b5a9_row9_col5 {\n",
       "  background-color: #f2cab5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_2b5a9_row9_col6 {\n",
       "  background-color: #f2cbb7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_2b5a9_row9_col7 {\n",
       "  background-color: #f0cdbb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_2b5a9_row9_col8 {\n",
       "  background-color: #c7d7f0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_2b5a9_row10_col1 {\n",
       "  background-color: #f5c1a9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_2b5a9_row10_col2 {\n",
       "  background-color: #edd1c2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_2b5a9_row10_col3 {\n",
       "  background-color: #a6c4fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_2b5a9_row10_col4, #T_2b5a9_row10_col5 {\n",
       "  background-color: #94b6ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_2b5a9_row10_col6, #T_2b5a9_row13_col12 {\n",
       "  background-color: #b1cbfc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_2b5a9_row10_col7, #T_2b5a9_row12_col10 {\n",
       "  background-color: #9dbdff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_2b5a9_row10_col9 {\n",
       "  background-color: #c5d6f2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_2b5a9_row11_col0 {\n",
       "  background-color: #e2dad5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_2b5a9_row11_col2, #T_2b5a9_row11_col10 {\n",
       "  background-color: #dcdddd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_2b5a9_row11_col5 {\n",
       "  background-color: #d9dce1;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_2b5a9_row11_col8 {\n",
       "  background-color: #bb1b2c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_2b5a9_row11_col9 {\n",
       "  background-color: #ccd9ed;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_2b5a9_row12_col1 {\n",
       "  background-color: #cad8ef;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_2b5a9_row12_col2 {\n",
       "  background-color: #ead4c8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_2b5a9_row12_col5 {\n",
       "  background-color: #f7ac8e;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_2b5a9_row12_col6 {\n",
       "  background-color: #c12b30;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_2b5a9_row12_col7 {\n",
       "  background-color: #f6bfa6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_2b5a9_row12_col8 {\n",
       "  background-color: #c3d5f4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_2b5a9_row12_col9 {\n",
       "  background-color: #f5c4ac;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_2b5a9_row12_col11, #T_2b5a9_row13_col6 {\n",
       "  background-color: #bcd2f7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_2b5a9_row13_col0, #T_2b5a9_row13_col8 {\n",
       "  background-color: #dbdcde;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_2b5a9_row13_col1 {\n",
       "  background-color: #f29274;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_2b5a9_row13_col3 {\n",
       "  background-color: #c0d4f5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_2b5a9_row13_col4, #T_2b5a9_row13_col5 {\n",
       "  background-color: #afcafc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_2b5a9_row13_col7 {\n",
       "  background-color: #b3cdfb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_2b5a9_row13_col10 {\n",
       "  background-color: #f49a7b;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_2b5a9\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_2b5a9_level0_col0\" class=\"col_heading level0 col0\" >Call  Failure</th>\n",
       "      <th id=\"T_2b5a9_level0_col1\" class=\"col_heading level0 col1\" >Complains</th>\n",
       "      <th id=\"T_2b5a9_level0_col2\" class=\"col_heading level0 col2\" >Subscription  Length</th>\n",
       "      <th id=\"T_2b5a9_level0_col3\" class=\"col_heading level0 col3\" >Charge  Amount</th>\n",
       "      <th id=\"T_2b5a9_level0_col4\" class=\"col_heading level0 col4\" >Seconds of Use</th>\n",
       "      <th id=\"T_2b5a9_level0_col5\" class=\"col_heading level0 col5\" >Frequency of use</th>\n",
       "      <th id=\"T_2b5a9_level0_col6\" class=\"col_heading level0 col6\" >Frequency of SMS</th>\n",
       "      <th id=\"T_2b5a9_level0_col7\" class=\"col_heading level0 col7\" >Distinct Called Numbers</th>\n",
       "      <th id=\"T_2b5a9_level0_col8\" class=\"col_heading level0 col8\" >Age Group</th>\n",
       "      <th id=\"T_2b5a9_level0_col9\" class=\"col_heading level0 col9\" >Tariff Plan</th>\n",
       "      <th id=\"T_2b5a9_level0_col10\" class=\"col_heading level0 col10\" >Status</th>\n",
       "      <th id=\"T_2b5a9_level0_col11\" class=\"col_heading level0 col11\" >Age</th>\n",
       "      <th id=\"T_2b5a9_level0_col12\" class=\"col_heading level0 col12\" >Customer Value</th>\n",
       "      <th id=\"T_2b5a9_level0_col13\" class=\"col_heading level0 col13\" >Churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_2b5a9_level0_row0\" class=\"row_heading level0 row0\" >Call  Failure</th>\n",
       "      <td id=\"T_2b5a9_row0_col0\" class=\"data row0 col0\" >nan</td>\n",
       "      <td id=\"T_2b5a9_row0_col1\" class=\"data row0 col1\" >nan</td>\n",
       "      <td id=\"T_2b5a9_row0_col2\" class=\"data row0 col2\" >nan</td>\n",
       "      <td id=\"T_2b5a9_row0_col3\" class=\"data row0 col3\" >nan</td>\n",
       "      <td id=\"T_2b5a9_row0_col4\" class=\"data row0 col4\" >nan</td>\n",
       "      <td id=\"T_2b5a9_row0_col5\" class=\"data row0 col5\" >nan</td>\n",
       "      <td id=\"T_2b5a9_row0_col6\" class=\"data row0 col6\" >nan</td>\n",
       "      <td id=\"T_2b5a9_row0_col7\" class=\"data row0 col7\" >nan</td>\n",
       "      <td id=\"T_2b5a9_row0_col8\" class=\"data row0 col8\" >nan</td>\n",
       "      <td id=\"T_2b5a9_row0_col9\" class=\"data row0 col9\" >nan</td>\n",
       "      <td id=\"T_2b5a9_row0_col10\" class=\"data row0 col10\" >nan</td>\n",
       "      <td id=\"T_2b5a9_row0_col11\" class=\"data row0 col11\" >nan</td>\n",
       "      <td id=\"T_2b5a9_row0_col12\" class=\"data row0 col12\" >nan</td>\n",
       "      <td id=\"T_2b5a9_row0_col13\" class=\"data row0 col13\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2b5a9_level0_row1\" class=\"row_heading level0 row1\" >Complains</th>\n",
       "      <td id=\"T_2b5a9_row1_col0\" class=\"data row1 col0\" >0.15</td>\n",
       "      <td id=\"T_2b5a9_row1_col1\" class=\"data row1 col1\" >nan</td>\n",
       "      <td id=\"T_2b5a9_row1_col2\" class=\"data row1 col2\" >nan</td>\n",
       "      <td id=\"T_2b5a9_row1_col3\" class=\"data row1 col3\" >nan</td>\n",
       "      <td id=\"T_2b5a9_row1_col4\" class=\"data row1 col4\" >nan</td>\n",
       "      <td id=\"T_2b5a9_row1_col5\" class=\"data row1 col5\" >nan</td>\n",
       "      <td id=\"T_2b5a9_row1_col6\" class=\"data row1 col6\" >nan</td>\n",
       "      <td id=\"T_2b5a9_row1_col7\" class=\"data row1 col7\" >nan</td>\n",
       "      <td id=\"T_2b5a9_row1_col8\" class=\"data row1 col8\" >nan</td>\n",
       "      <td id=\"T_2b5a9_row1_col9\" class=\"data row1 col9\" >nan</td>\n",
       "      <td id=\"T_2b5a9_row1_col10\" class=\"data row1 col10\" >nan</td>\n",
       "      <td id=\"T_2b5a9_row1_col11\" class=\"data row1 col11\" >nan</td>\n",
       "      <td id=\"T_2b5a9_row1_col12\" class=\"data row1 col12\" >nan</td>\n",
       "      <td id=\"T_2b5a9_row1_col13\" class=\"data row1 col13\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2b5a9_level0_row2\" class=\"row_heading level0 row2\" >Subscription  Length</th>\n",
       "      <td id=\"T_2b5a9_row2_col0\" class=\"data row2 col0\" >0.17</td>\n",
       "      <td id=\"T_2b5a9_row2_col1\" class=\"data row2 col1\" >-0.02</td>\n",
       "      <td id=\"T_2b5a9_row2_col2\" class=\"data row2 col2\" >nan</td>\n",
       "      <td id=\"T_2b5a9_row2_col3\" class=\"data row2 col3\" >nan</td>\n",
       "      <td id=\"T_2b5a9_row2_col4\" class=\"data row2 col4\" >nan</td>\n",
       "      <td id=\"T_2b5a9_row2_col5\" class=\"data row2 col5\" >nan</td>\n",
       "      <td id=\"T_2b5a9_row2_col6\" class=\"data row2 col6\" >nan</td>\n",
       "      <td id=\"T_2b5a9_row2_col7\" class=\"data row2 col7\" >nan</td>\n",
       "      <td id=\"T_2b5a9_row2_col8\" class=\"data row2 col8\" >nan</td>\n",
       "      <td id=\"T_2b5a9_row2_col9\" class=\"data row2 col9\" >nan</td>\n",
       "      <td id=\"T_2b5a9_row2_col10\" class=\"data row2 col10\" >nan</td>\n",
       "      <td id=\"T_2b5a9_row2_col11\" class=\"data row2 col11\" >nan</td>\n",
       "      <td id=\"T_2b5a9_row2_col12\" class=\"data row2 col12\" >nan</td>\n",
       "      <td id=\"T_2b5a9_row2_col13\" class=\"data row2 col13\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2b5a9_level0_row3\" class=\"row_heading level0 row3\" >Charge  Amount</th>\n",
       "      <td id=\"T_2b5a9_row3_col0\" class=\"data row3 col0\" >0.59</td>\n",
       "      <td id=\"T_2b5a9_row3_col1\" class=\"data row3 col1\" >-0.03</td>\n",
       "      <td id=\"T_2b5a9_row3_col2\" class=\"data row3 col2\" >0.08</td>\n",
       "      <td id=\"T_2b5a9_row3_col3\" class=\"data row3 col3\" >nan</td>\n",
       "      <td id=\"T_2b5a9_row3_col4\" class=\"data row3 col4\" >nan</td>\n",
       "      <td id=\"T_2b5a9_row3_col5\" class=\"data row3 col5\" >nan</td>\n",
       "      <td id=\"T_2b5a9_row3_col6\" class=\"data row3 col6\" >nan</td>\n",
       "      <td id=\"T_2b5a9_row3_col7\" class=\"data row3 col7\" >nan</td>\n",
       "      <td id=\"T_2b5a9_row3_col8\" class=\"data row3 col8\" >nan</td>\n",
       "      <td id=\"T_2b5a9_row3_col9\" class=\"data row3 col9\" >nan</td>\n",
       "      <td id=\"T_2b5a9_row3_col10\" class=\"data row3 col10\" >nan</td>\n",
       "      <td id=\"T_2b5a9_row3_col11\" class=\"data row3 col11\" >nan</td>\n",
       "      <td id=\"T_2b5a9_row3_col12\" class=\"data row3 col12\" >nan</td>\n",
       "      <td id=\"T_2b5a9_row3_col13\" class=\"data row3 col13\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2b5a9_level0_row4\" class=\"row_heading level0 row4\" >Seconds of Use</th>\n",
       "      <td id=\"T_2b5a9_row4_col0\" class=\"data row4 col0\" >0.50</td>\n",
       "      <td id=\"T_2b5a9_row4_col1\" class=\"data row4 col1\" >-0.10</td>\n",
       "      <td id=\"T_2b5a9_row4_col2\" class=\"data row4 col2\" >0.12</td>\n",
       "      <td id=\"T_2b5a9_row4_col3\" class=\"data row4 col3\" >0.45</td>\n",
       "      <td id=\"T_2b5a9_row4_col4\" class=\"data row4 col4\" >nan</td>\n",
       "      <td id=\"T_2b5a9_row4_col5\" class=\"data row4 col5\" >nan</td>\n",
       "      <td id=\"T_2b5a9_row4_col6\" class=\"data row4 col6\" >nan</td>\n",
       "      <td id=\"T_2b5a9_row4_col7\" class=\"data row4 col7\" >nan</td>\n",
       "      <td id=\"T_2b5a9_row4_col8\" class=\"data row4 col8\" >nan</td>\n",
       "      <td id=\"T_2b5a9_row4_col9\" class=\"data row4 col9\" >nan</td>\n",
       "      <td id=\"T_2b5a9_row4_col10\" class=\"data row4 col10\" >nan</td>\n",
       "      <td id=\"T_2b5a9_row4_col11\" class=\"data row4 col11\" >nan</td>\n",
       "      <td id=\"T_2b5a9_row4_col12\" class=\"data row4 col12\" >nan</td>\n",
       "      <td id=\"T_2b5a9_row4_col13\" class=\"data row4 col13\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2b5a9_level0_row5\" class=\"row_heading level0 row5\" >Frequency of use</th>\n",
       "      <td id=\"T_2b5a9_row5_col0\" class=\"data row5 col0\" >0.57</td>\n",
       "      <td id=\"T_2b5a9_row5_col1\" class=\"data row5 col1\" >-0.09</td>\n",
       "      <td id=\"T_2b5a9_row5_col2\" class=\"data row5 col2\" >0.11</td>\n",
       "      <td id=\"T_2b5a9_row5_col3\" class=\"data row5 col3\" >0.38</td>\n",
       "      <td id=\"T_2b5a9_row5_col4\" class=\"data row5 col4\" >0.95</td>\n",
       "      <td id=\"T_2b5a9_row5_col5\" class=\"data row5 col5\" >nan</td>\n",
       "      <td id=\"T_2b5a9_row5_col6\" class=\"data row5 col6\" >nan</td>\n",
       "      <td id=\"T_2b5a9_row5_col7\" class=\"data row5 col7\" >nan</td>\n",
       "      <td id=\"T_2b5a9_row5_col8\" class=\"data row5 col8\" >nan</td>\n",
       "      <td id=\"T_2b5a9_row5_col9\" class=\"data row5 col9\" >nan</td>\n",
       "      <td id=\"T_2b5a9_row5_col10\" class=\"data row5 col10\" >nan</td>\n",
       "      <td id=\"T_2b5a9_row5_col11\" class=\"data row5 col11\" >nan</td>\n",
       "      <td id=\"T_2b5a9_row5_col12\" class=\"data row5 col12\" >nan</td>\n",
       "      <td id=\"T_2b5a9_row5_col13\" class=\"data row5 col13\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2b5a9_level0_row6\" class=\"row_heading level0 row6\" >Frequency of SMS</th>\n",
       "      <td id=\"T_2b5a9_row6_col0\" class=\"data row6 col0\" >-0.02</td>\n",
       "      <td id=\"T_2b5a9_row6_col1\" class=\"data row6 col1\" >-0.11</td>\n",
       "      <td id=\"T_2b5a9_row6_col2\" class=\"data row6 col2\" >0.08</td>\n",
       "      <td id=\"T_2b5a9_row6_col3\" class=\"data row6 col3\" >0.09</td>\n",
       "      <td id=\"T_2b5a9_row6_col4\" class=\"data row6 col4\" >0.10</td>\n",
       "      <td id=\"T_2b5a9_row6_col5\" class=\"data row6 col5\" >0.10</td>\n",
       "      <td id=\"T_2b5a9_row6_col6\" class=\"data row6 col6\" >nan</td>\n",
       "      <td id=\"T_2b5a9_row6_col7\" class=\"data row6 col7\" >nan</td>\n",
       "      <td id=\"T_2b5a9_row6_col8\" class=\"data row6 col8\" >nan</td>\n",
       "      <td id=\"T_2b5a9_row6_col9\" class=\"data row6 col9\" >nan</td>\n",
       "      <td id=\"T_2b5a9_row6_col10\" class=\"data row6 col10\" >nan</td>\n",
       "      <td id=\"T_2b5a9_row6_col11\" class=\"data row6 col11\" >nan</td>\n",
       "      <td id=\"T_2b5a9_row6_col12\" class=\"data row6 col12\" >nan</td>\n",
       "      <td id=\"T_2b5a9_row6_col13\" class=\"data row6 col13\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2b5a9_level0_row7\" class=\"row_heading level0 row7\" >Distinct Called Numbers</th>\n",
       "      <td id=\"T_2b5a9_row7_col0\" class=\"data row7 col0\" >0.50</td>\n",
       "      <td id=\"T_2b5a9_row7_col1\" class=\"data row7 col1\" >-0.06</td>\n",
       "      <td id=\"T_2b5a9_row7_col2\" class=\"data row7 col2\" >0.09</td>\n",
       "      <td id=\"T_2b5a9_row7_col3\" class=\"data row7 col3\" >0.42</td>\n",
       "      <td id=\"T_2b5a9_row7_col4\" class=\"data row7 col4\" >0.68</td>\n",
       "      <td id=\"T_2b5a9_row7_col5\" class=\"data row7 col5\" >0.74</td>\n",
       "      <td id=\"T_2b5a9_row7_col6\" class=\"data row7 col6\" >0.08</td>\n",
       "      <td id=\"T_2b5a9_row7_col7\" class=\"data row7 col7\" >nan</td>\n",
       "      <td id=\"T_2b5a9_row7_col8\" class=\"data row7 col8\" >nan</td>\n",
       "      <td id=\"T_2b5a9_row7_col9\" class=\"data row7 col9\" >nan</td>\n",
       "      <td id=\"T_2b5a9_row7_col10\" class=\"data row7 col10\" >nan</td>\n",
       "      <td id=\"T_2b5a9_row7_col11\" class=\"data row7 col11\" >nan</td>\n",
       "      <td id=\"T_2b5a9_row7_col12\" class=\"data row7 col12\" >nan</td>\n",
       "      <td id=\"T_2b5a9_row7_col13\" class=\"data row7 col13\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2b5a9_level0_row8\" class=\"row_heading level0 row8\" >Age Group</th>\n",
       "      <td id=\"T_2b5a9_row8_col0\" class=\"data row8 col0\" >0.05</td>\n",
       "      <td id=\"T_2b5a9_row8_col1\" class=\"data row8 col1\" >0.02</td>\n",
       "      <td id=\"T_2b5a9_row8_col2\" class=\"data row8 col2\" >0.02</td>\n",
       "      <td id=\"T_2b5a9_row8_col3\" class=\"data row8 col3\" >0.28</td>\n",
       "      <td id=\"T_2b5a9_row8_col4\" class=\"data row8 col4\" >0.02</td>\n",
       "      <td id=\"T_2b5a9_row8_col5\" class=\"data row8 col5\" >-0.03</td>\n",
       "      <td id=\"T_2b5a9_row8_col6\" class=\"data row8 col6\" >-0.05</td>\n",
       "      <td id=\"T_2b5a9_row8_col7\" class=\"data row8 col7\" >0.02</td>\n",
       "      <td id=\"T_2b5a9_row8_col8\" class=\"data row8 col8\" >nan</td>\n",
       "      <td id=\"T_2b5a9_row8_col9\" class=\"data row8 col9\" >nan</td>\n",
       "      <td id=\"T_2b5a9_row8_col10\" class=\"data row8 col10\" >nan</td>\n",
       "      <td id=\"T_2b5a9_row8_col11\" class=\"data row8 col11\" >nan</td>\n",
       "      <td id=\"T_2b5a9_row8_col12\" class=\"data row8 col12\" >nan</td>\n",
       "      <td id=\"T_2b5a9_row8_col13\" class=\"data row8 col13\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2b5a9_level0_row9\" class=\"row_heading level0 row9\" >Tariff Plan</th>\n",
       "      <td id=\"T_2b5a9_row9_col0\" class=\"data row9 col0\" >0.19</td>\n",
       "      <td id=\"T_2b5a9_row9_col1\" class=\"data row9 col1\" >0.00</td>\n",
       "      <td id=\"T_2b5a9_row9_col2\" class=\"data row9 col2\" >-0.16</td>\n",
       "      <td id=\"T_2b5a9_row9_col3\" class=\"data row9 col3\" >0.32</td>\n",
       "      <td id=\"T_2b5a9_row9_col4\" class=\"data row9 col4\" >0.13</td>\n",
       "      <td id=\"T_2b5a9_row9_col5\" class=\"data row9 col5\" >0.21</td>\n",
       "      <td id=\"T_2b5a9_row9_col6\" class=\"data row9 col6\" >0.20</td>\n",
       "      <td id=\"T_2b5a9_row9_col7\" class=\"data row9 col7\" >0.17</td>\n",
       "      <td id=\"T_2b5a9_row9_col8\" class=\"data row9 col8\" >-0.15</td>\n",
       "      <td id=\"T_2b5a9_row9_col9\" class=\"data row9 col9\" >nan</td>\n",
       "      <td id=\"T_2b5a9_row9_col10\" class=\"data row9 col10\" >nan</td>\n",
       "      <td id=\"T_2b5a9_row9_col11\" class=\"data row9 col11\" >nan</td>\n",
       "      <td id=\"T_2b5a9_row9_col12\" class=\"data row9 col12\" >nan</td>\n",
       "      <td id=\"T_2b5a9_row9_col13\" class=\"data row9 col13\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2b5a9_level0_row10\" class=\"row_heading level0 row10\" >Status</th>\n",
       "      <td id=\"T_2b5a9_row10_col0\" class=\"data row10 col0\" >-0.11</td>\n",
       "      <td id=\"T_2b5a9_row10_col1\" class=\"data row10 col1\" >0.27</td>\n",
       "      <td id=\"T_2b5a9_row10_col2\" class=\"data row10 col2\" >0.14</td>\n",
       "      <td id=\"T_2b5a9_row10_col3\" class=\"data row10 col3\" >-0.36</td>\n",
       "      <td id=\"T_2b5a9_row10_col4\" class=\"data row10 col4\" >-0.46</td>\n",
       "      <td id=\"T_2b5a9_row10_col5\" class=\"data row10 col5\" >-0.45</td>\n",
       "      <td id=\"T_2b5a9_row10_col6\" class=\"data row10 col6\" >-0.30</td>\n",
       "      <td id=\"T_2b5a9_row10_col7\" class=\"data row10 col7\" >-0.41</td>\n",
       "      <td id=\"T_2b5a9_row10_col8\" class=\"data row10 col8\" >0.00</td>\n",
       "      <td id=\"T_2b5a9_row10_col9\" class=\"data row10 col9\" >-0.16</td>\n",
       "      <td id=\"T_2b5a9_row10_col10\" class=\"data row10 col10\" >nan</td>\n",
       "      <td id=\"T_2b5a9_row10_col11\" class=\"data row10 col11\" >nan</td>\n",
       "      <td id=\"T_2b5a9_row10_col12\" class=\"data row10 col12\" >nan</td>\n",
       "      <td id=\"T_2b5a9_row10_col13\" class=\"data row10 col13\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2b5a9_level0_row11\" class=\"row_heading level0 row11\" >Age</th>\n",
       "      <td id=\"T_2b5a9_row11_col0\" class=\"data row11 col0\" >0.04</td>\n",
       "      <td id=\"T_2b5a9_row11_col1\" class=\"data row11 col1\" >0.00</td>\n",
       "      <td id=\"T_2b5a9_row11_col2\" class=\"data row11 col2\" >-0.00</td>\n",
       "      <td id=\"T_2b5a9_row11_col3\" class=\"data row11 col3\" >0.28</td>\n",
       "      <td id=\"T_2b5a9_row11_col4\" class=\"data row11 col4\" >0.02</td>\n",
       "      <td id=\"T_2b5a9_row11_col5\" class=\"data row11 col5\" >-0.03</td>\n",
       "      <td id=\"T_2b5a9_row11_col6\" class=\"data row11 col6\" >-0.09</td>\n",
       "      <td id=\"T_2b5a9_row11_col7\" class=\"data row11 col7\" >0.05</td>\n",
       "      <td id=\"T_2b5a9_row11_col8\" class=\"data row11 col8\" >0.96</td>\n",
       "      <td id=\"T_2b5a9_row11_col9\" class=\"data row11 col9\" >-0.12</td>\n",
       "      <td id=\"T_2b5a9_row11_col10\" class=\"data row11 col10\" >-0.00</td>\n",
       "      <td id=\"T_2b5a9_row11_col11\" class=\"data row11 col11\" >nan</td>\n",
       "      <td id=\"T_2b5a9_row11_col12\" class=\"data row11 col12\" >nan</td>\n",
       "      <td id=\"T_2b5a9_row11_col13\" class=\"data row11 col13\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2b5a9_level0_row12\" class=\"row_heading level0 row12\" >Customer Value</th>\n",
       "      <td id=\"T_2b5a9_row12_col0\" class=\"data row12 col0\" >0.12</td>\n",
       "      <td id=\"T_2b5a9_row12_col1\" class=\"data row12 col1\" >-0.13</td>\n",
       "      <td id=\"T_2b5a9_row12_col2\" class=\"data row12 col2\" >0.11</td>\n",
       "      <td id=\"T_2b5a9_row12_col3\" class=\"data row12 col3\" >0.17</td>\n",
       "      <td id=\"T_2b5a9_row12_col4\" class=\"data row12 col4\" >0.42</td>\n",
       "      <td id=\"T_2b5a9_row12_col5\" class=\"data row12 col5\" >0.40</td>\n",
       "      <td id=\"T_2b5a9_row12_col6\" class=\"data row12 col6\" >0.92</td>\n",
       "      <td id=\"T_2b5a9_row12_col7\" class=\"data row12 col7\" >0.28</td>\n",
       "      <td id=\"T_2b5a9_row12_col8\" class=\"data row12 col8\" >-0.18</td>\n",
       "      <td id=\"T_2b5a9_row12_col9\" class=\"data row12 col9\" >0.25</td>\n",
       "      <td id=\"T_2b5a9_row12_col10\" class=\"data row12 col10\" >-0.41</td>\n",
       "      <td id=\"T_2b5a9_row12_col11\" class=\"data row12 col11\" >-0.22</td>\n",
       "      <td id=\"T_2b5a9_row12_col12\" class=\"data row12 col12\" >nan</td>\n",
       "      <td id=\"T_2b5a9_row12_col13\" class=\"data row12 col13\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2b5a9_level0_row13\" class=\"row_heading level0 row13\" >Churn</th>\n",
       "      <td id=\"T_2b5a9_row13_col0\" class=\"data row13 col0\" >-0.01</td>\n",
       "      <td id=\"T_2b5a9_row13_col1\" class=\"data row13 col1\" >0.53</td>\n",
       "      <td id=\"T_2b5a9_row13_col2\" class=\"data row13 col2\" >-0.03</td>\n",
       "      <td id=\"T_2b5a9_row13_col3\" class=\"data row13 col3\" >-0.20</td>\n",
       "      <td id=\"T_2b5a9_row13_col4\" class=\"data row13 col4\" >-0.30</td>\n",
       "      <td id=\"T_2b5a9_row13_col5\" class=\"data row13 col5\" >-0.30</td>\n",
       "      <td id=\"T_2b5a9_row13_col6\" class=\"data row13 col6\" >-0.22</td>\n",
       "      <td id=\"T_2b5a9_row13_col7\" class=\"data row13 col7\" >-0.28</td>\n",
       "      <td id=\"T_2b5a9_row13_col8\" class=\"data row13 col8\" >-0.01</td>\n",
       "      <td id=\"T_2b5a9_row13_col9\" class=\"data row13 col9\" >-0.11</td>\n",
       "      <td id=\"T_2b5a9_row13_col10\" class=\"data row13 col10\" >0.50</td>\n",
       "      <td id=\"T_2b5a9_row13_col11\" class=\"data row13 col11\" >-0.02</td>\n",
       "      <td id=\"T_2b5a9_row13_col12\" class=\"data row13 col12\" >-0.29</td>\n",
       "      <td id=\"T_2b5a9_row13_col13\" class=\"data row13 col13\" >nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x780430c17d00>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr = df.corr() \n",
    "cm = sns.diverging_palette(220, 20, sep=20, as_cmap=True) \n",
    "corr.style.background_gradient(cmap=cm , axis=None).set_precision(2)\n",
    "\n",
    "# Fill diagonal and upper half with NaNs\n",
    "mask = np.zeros_like(corr, dtype=bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "corr[mask] = np.nan\n",
    "(corr\n",
    " .style\n",
    " .background_gradient(cmap='coolwarm', axis=None, vmin=-1, vmax=1)\n",
    " .highlight_null('#f1f1f1')  # Color NaNs grey\n",
    " .format(precision=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fc9a3e38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x1152 with 14 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.plot(kind='box', subplots=True, layout= (7,2), sharex=False, sharey=False, figsize=(16,16), title='Box Plot for each input variable')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "349b9e82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Subscription  Length', ylabel='Density'>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.kdeplot(data=df, x='Subscription  Length', color='b', shade=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "de6b76f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Charge  Amount', ylabel='Density'>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.kdeplot(data=df, x='Charge  Amount', color='r', shade=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "183d8b66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Customer Value', ylabel='Density'>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.kdeplot(data=df, x='Customer Value', color='y', shade=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "28822902",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Complains', ylabel='Density'>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.kdeplot(data=df, x='Complains', color='r', shade=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "753eab45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Status', ylabel='Density'>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.kdeplot(data=df, x='Status', color='r', shade=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0ec946e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    3150.000000\n",
       "mean        1.248254\n",
       "std         0.432069\n",
       "min         1.000000\n",
       "25%         1.000000\n",
       "50%         1.000000\n",
       "75%         1.000000\n",
       "max         2.000000\n",
       "Name: Status, dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Status.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "878dbb74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    3150.000000\n",
       "mean        0.076508\n",
       "std         0.265851\n",
       "min         0.000000\n",
       "25%         0.000000\n",
       "50%         0.000000\n",
       "75%         0.000000\n",
       "max         1.000000\n",
       "Name: Complains, dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Complains.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0100a3ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Call  Failure</th>\n",
       "      <th>Complains</th>\n",
       "      <th>Subscription  Length</th>\n",
       "      <th>Charge  Amount</th>\n",
       "      <th>Seconds of Use</th>\n",
       "      <th>Frequency of use</th>\n",
       "      <th>Frequency of SMS</th>\n",
       "      <th>Distinct Called Numbers</th>\n",
       "      <th>Age Group</th>\n",
       "      <th>Tariff Plan</th>\n",
       "      <th>Status</th>\n",
       "      <th>Age</th>\n",
       "      <th>Customer Value</th>\n",
       "      <th>Churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>955.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>117.090</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2268.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>228.480</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>628.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>38.375</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2178.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>101.160</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2208.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>205.960</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3076</th>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3295.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>197.680</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3122</th>\n",
       "      <td>28.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1260.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>144.520</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3126</th>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3295.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>197.680</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3127</th>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2573.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>168.075</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3131</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>933.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>63.650</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>158 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Call  Failure  Complains  Subscription  Length  Charge  Amount  \\\n",
       "22             23.0        1.0                  33.0             0.0   \n",
       "27              9.0        1.0                  36.0             0.0   \n",
       "31              0.0        1.0                  36.0             0.0   \n",
       "111             6.0        1.0                  36.0             0.0   \n",
       "127             6.0        1.0                  34.0             0.0   \n",
       "...             ...        ...                   ...             ...   \n",
       "3076           14.0        1.0                  37.0             0.0   \n",
       "3122           28.0        1.0                  35.0             0.0   \n",
       "3126           14.0        1.0                  37.0             0.0   \n",
       "3127           14.0        1.0                  38.0             0.0   \n",
       "3131            5.0        1.0                  38.0             0.0   \n",
       "\n",
       "      Seconds of Use  Frequency of use  Frequency of SMS  \\\n",
       "22             955.0              47.0              16.0   \n",
       "27            2268.0              44.0              34.0   \n",
       "31             628.0               7.0               9.0   \n",
       "111           2178.0              51.0               3.0   \n",
       "127           2208.0              41.0              29.0   \n",
       "...              ...               ...               ...   \n",
       "3076          3295.0              47.0              16.0   \n",
       "3122          1260.0              53.0              23.0   \n",
       "3126          3295.0              47.0              16.0   \n",
       "3127          2573.0              50.0              41.0   \n",
       "3131           933.0              13.0              16.0   \n",
       "\n",
       "      Distinct Called Numbers  Age Group  Tariff Plan  Status   Age  \\\n",
       "22                       17.0        2.0          1.0     2.0  25.0   \n",
       "27                       31.0        3.0          1.0     2.0  30.0   \n",
       "31                        4.0        4.0          1.0     2.0  45.0   \n",
       "111                      15.0        3.0          1.0     2.0  30.0   \n",
       "127                      29.0        3.0          1.0     2.0  30.0   \n",
       "...                       ...        ...          ...     ...   ...   \n",
       "3076                     18.0        3.0          1.0     2.0  30.0   \n",
       "3122                     19.0        3.0          1.0     2.0  30.0   \n",
       "3126                     18.0        3.0          1.0     2.0  30.0   \n",
       "3127                     33.0        4.0          1.0     2.0  45.0   \n",
       "3131                      6.0        4.0          1.0     2.0  45.0   \n",
       "\n",
       "      Customer Value  Churn  \n",
       "22           117.090    1.0  \n",
       "27           228.480    1.0  \n",
       "31            38.375    1.0  \n",
       "111          101.160    0.0  \n",
       "127          205.960    1.0  \n",
       "...              ...    ...  \n",
       "3076         197.680    1.0  \n",
       "3122         144.520    1.0  \n",
       "3126         197.680    1.0  \n",
       "3127         168.075    1.0  \n",
       "3131          63.650    1.0  \n",
       "\n",
       "[158 rows x 14 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_stat = df[(df['Status'] >= 1.8) & (df['Complains'] >= 0.8)]\n",
    "df_stat "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2330aeb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    141\n",
       "0.0     17\n",
       "Name: Churn, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(df_stat['Churn'].unique(), df_stat['Churn'].value_counts())\n",
    "df_stat.Churn.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f77c332f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28.484848484848484"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(141/495 ) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e6514d",
   "metadata": {},
   "source": [
    "### 28.5% of All churn is linked to a customer complaint. Addressing the causes of the complaints would retain these customer. As there is no narrative data on the complaint it is uncertain at this stage what are the causes. The scope of using spark will allow for the scaling of the analytics platform to accomodate narrative data in the future and be able to integrate NLP to address the reasons for the complaints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "70972c51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Call  Failure</th>\n",
       "      <th>Complains</th>\n",
       "      <th>Subscription  Length</th>\n",
       "      <th>Charge  Amount</th>\n",
       "      <th>Seconds of Use</th>\n",
       "      <th>Frequency of use</th>\n",
       "      <th>Frequency of SMS</th>\n",
       "      <th>Distinct Called Numbers</th>\n",
       "      <th>Age Group</th>\n",
       "      <th>Tariff Plan</th>\n",
       "      <th>Status</th>\n",
       "      <th>Age</th>\n",
       "      <th>Customer Value</th>\n",
       "      <th>Churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>955.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>117.090</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2268.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>228.480</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>628.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>38.375</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2208.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>205.960</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3076</th>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3295.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>197.680</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3122</th>\n",
       "      <td>28.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1260.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>144.520</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3126</th>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3295.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>197.680</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3127</th>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2573.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>168.075</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3131</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>933.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>63.650</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>141 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Call  Failure  Complains  Subscription  Length  Charge  Amount  \\\n",
       "22             23.0        1.0                  33.0             0.0   \n",
       "27              9.0        1.0                  36.0             0.0   \n",
       "31              0.0        1.0                  36.0             0.0   \n",
       "127             6.0        1.0                  34.0             0.0   \n",
       "128             0.0        1.0                  34.0             0.0   \n",
       "...             ...        ...                   ...             ...   \n",
       "3076           14.0        1.0                  37.0             0.0   \n",
       "3122           28.0        1.0                  35.0             0.0   \n",
       "3126           14.0        1.0                  37.0             0.0   \n",
       "3127           14.0        1.0                  38.0             0.0   \n",
       "3131            5.0        1.0                  38.0             0.0   \n",
       "\n",
       "      Seconds of Use  Frequency of use  Frequency of SMS  \\\n",
       "22             955.0              47.0              16.0   \n",
       "27            2268.0              44.0              34.0   \n",
       "31             628.0               7.0               9.0   \n",
       "127           2208.0              41.0              29.0   \n",
       "128              0.0               0.0               0.0   \n",
       "...              ...               ...               ...   \n",
       "3076          3295.0              47.0              16.0   \n",
       "3122          1260.0              53.0              23.0   \n",
       "3126          3295.0              47.0              16.0   \n",
       "3127          2573.0              50.0              41.0   \n",
       "3131           933.0              13.0              16.0   \n",
       "\n",
       "      Distinct Called Numbers  Age Group  Tariff Plan  Status   Age  \\\n",
       "22                       17.0        2.0          1.0     2.0  25.0   \n",
       "27                       31.0        3.0          1.0     2.0  30.0   \n",
       "31                        4.0        4.0          1.0     2.0  45.0   \n",
       "127                      29.0        3.0          1.0     2.0  30.0   \n",
       "128                       0.0        3.0          1.0     2.0  30.0   \n",
       "...                       ...        ...          ...     ...   ...   \n",
       "3076                     18.0        3.0          1.0     2.0  30.0   \n",
       "3122                     19.0        3.0          1.0     2.0  30.0   \n",
       "3126                     18.0        3.0          1.0     2.0  30.0   \n",
       "3127                     33.0        4.0          1.0     2.0  45.0   \n",
       "3131                      6.0        4.0          1.0     2.0  45.0   \n",
       "\n",
       "      Customer Value  Churn  \n",
       "22           117.090    1.0  \n",
       "27           228.480    1.0  \n",
       "31            38.375    1.0  \n",
       "127          205.960    1.0  \n",
       "128            0.000    1.0  \n",
       "...              ...    ...  \n",
       "3076         197.680    1.0  \n",
       "3122         144.520    1.0  \n",
       "3126         197.680    1.0  \n",
       "3127         168.075    1.0  \n",
       "3131          63.650    1.0  \n",
       "\n",
       "[141 rows x 14 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_stat = df[(df['Status'] >= 1.8) & (df_stat['Complains'] >= 0.8) & (df_stat['Churn'] == 1)]\n",
    "df_stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "afb0dafa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Call  Failure</th>\n",
       "      <th>Complains</th>\n",
       "      <th>Subscription  Length</th>\n",
       "      <th>Charge  Amount</th>\n",
       "      <th>Seconds of Use</th>\n",
       "      <th>Frequency of use</th>\n",
       "      <th>Frequency of SMS</th>\n",
       "      <th>Distinct Called Numbers</th>\n",
       "      <th>Age Group</th>\n",
       "      <th>Tariff Plan</th>\n",
       "      <th>Status</th>\n",
       "      <th>Age</th>\n",
       "      <th>Customer Value</th>\n",
       "      <th>Churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>141.000000</td>\n",
       "      <td>141.0</td>\n",
       "      <td>141.000000</td>\n",
       "      <td>141.0</td>\n",
       "      <td>141.000000</td>\n",
       "      <td>141.000000</td>\n",
       "      <td>141.000000</td>\n",
       "      <td>141.000000</td>\n",
       "      <td>141.000000</td>\n",
       "      <td>141.000000</td>\n",
       "      <td>141.0</td>\n",
       "      <td>141.000000</td>\n",
       "      <td>141.000000</td>\n",
       "      <td>141.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>11.595745</td>\n",
       "      <td>1.0</td>\n",
       "      <td>34.900709</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1783.886525</td>\n",
       "      <td>36.517730</td>\n",
       "      <td>20.843972</td>\n",
       "      <td>17.943262</td>\n",
       "      <td>2.921986</td>\n",
       "      <td>1.007092</td>\n",
       "      <td>2.0</td>\n",
       "      <td>31.453901</td>\n",
       "      <td>145.909894</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.546861</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.208928</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1122.282541</td>\n",
       "      <td>19.496008</td>\n",
       "      <td>17.476631</td>\n",
       "      <td>11.387821</td>\n",
       "      <td>0.666236</td>\n",
       "      <td>0.084215</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.801759</td>\n",
       "      <td>86.846298</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>910.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>79.640000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1960.000000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>154.160000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2685.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>206.100000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>34.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4005.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>336.880000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Call  Failure  Complains  Subscription  Length  Charge  Amount  \\\n",
       "count     141.000000      141.0            141.000000           141.0   \n",
       "mean       11.595745        1.0             34.900709             0.0   \n",
       "std         9.546861        0.0              5.208928             0.0   \n",
       "min         0.000000        1.0              5.000000             0.0   \n",
       "25%         4.000000        1.0             33.000000             0.0   \n",
       "50%        10.000000        1.0             35.000000             0.0   \n",
       "75%        18.000000        1.0             38.000000             0.0   \n",
       "max        34.000000        1.0             44.000000             0.0   \n",
       "\n",
       "       Seconds of Use  Frequency of use  Frequency of SMS  \\\n",
       "count      141.000000        141.000000        141.000000   \n",
       "mean      1783.886525         36.517730         20.843972   \n",
       "std       1122.282541         19.496008         17.476631   \n",
       "min          0.000000          0.000000          0.000000   \n",
       "25%        910.000000         25.000000          7.000000   \n",
       "50%       1960.000000         42.000000         18.000000   \n",
       "75%       2685.000000         51.000000         31.000000   \n",
       "max       4005.000000         64.000000         73.000000   \n",
       "\n",
       "       Distinct Called Numbers   Age Group  Tariff Plan  Status         Age  \\\n",
       "count               141.000000  141.000000   141.000000   141.0  141.000000   \n",
       "mean                 17.943262    2.921986     1.007092     2.0   31.453901   \n",
       "std                  11.387821    0.666236     0.084215     0.0    6.801759   \n",
       "min                   0.000000    2.000000     1.000000     2.0   25.000000   \n",
       "25%                  10.000000    2.000000     1.000000     2.0   25.000000   \n",
       "50%                  18.000000    3.000000     1.000000     2.0   30.000000   \n",
       "75%                  25.000000    3.000000     1.000000     2.0   30.000000   \n",
       "max                  46.000000    4.000000     2.000000     2.0   45.000000   \n",
       "\n",
       "       Customer Value  Churn  \n",
       "count      141.000000  141.0  \n",
       "mean       145.909894    1.0  \n",
       "std         86.846298    0.0  \n",
       "min          0.000000    1.0  \n",
       "25%         79.640000    1.0  \n",
       "50%        154.160000    1.0  \n",
       "75%        206.100000    1.0  \n",
       "max        336.880000    1.0  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_stat.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6b73e96e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Call  Failure</th>\n",
       "      <th>Complains</th>\n",
       "      <th>Subscription  Length</th>\n",
       "      <th>Charge  Amount</th>\n",
       "      <th>Seconds of Use</th>\n",
       "      <th>Frequency of use</th>\n",
       "      <th>Frequency of SMS</th>\n",
       "      <th>Distinct Called Numbers</th>\n",
       "      <th>Age Group</th>\n",
       "      <th>Tariff Plan</th>\n",
       "      <th>Status</th>\n",
       "      <th>Age</th>\n",
       "      <th>Customer Value</th>\n",
       "      <th>Churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3150.000000</td>\n",
       "      <td>3150.000000</td>\n",
       "      <td>3150.000000</td>\n",
       "      <td>3150.000000</td>\n",
       "      <td>3150.000000</td>\n",
       "      <td>3150.000000</td>\n",
       "      <td>3150.000000</td>\n",
       "      <td>3150.000000</td>\n",
       "      <td>3150.000000</td>\n",
       "      <td>3150.000000</td>\n",
       "      <td>3150.000000</td>\n",
       "      <td>3150.000000</td>\n",
       "      <td>3150.000000</td>\n",
       "      <td>3150.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>7.627937</td>\n",
       "      <td>0.076508</td>\n",
       "      <td>32.541905</td>\n",
       "      <td>0.942857</td>\n",
       "      <td>4472.459683</td>\n",
       "      <td>69.460635</td>\n",
       "      <td>73.174921</td>\n",
       "      <td>23.509841</td>\n",
       "      <td>2.826032</td>\n",
       "      <td>1.077778</td>\n",
       "      <td>1.248254</td>\n",
       "      <td>30.998413</td>\n",
       "      <td>470.972916</td>\n",
       "      <td>0.157143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>7.263886</td>\n",
       "      <td>0.265851</td>\n",
       "      <td>8.573482</td>\n",
       "      <td>1.521072</td>\n",
       "      <td>4197.908687</td>\n",
       "      <td>57.413308</td>\n",
       "      <td>112.237560</td>\n",
       "      <td>17.217337</td>\n",
       "      <td>0.892555</td>\n",
       "      <td>0.267864</td>\n",
       "      <td>0.432069</td>\n",
       "      <td>8.831095</td>\n",
       "      <td>517.015433</td>\n",
       "      <td>0.363993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1391.250000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>113.801250</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2990.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>228.480000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6478.250000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>788.388750</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>36.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>17090.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>522.000000</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>2165.280000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Call  Failure    Complains  Subscription  Length  Charge  Amount  \\\n",
       "count    3150.000000  3150.000000           3150.000000     3150.000000   \n",
       "mean        7.627937     0.076508             32.541905        0.942857   \n",
       "std         7.263886     0.265851              8.573482        1.521072   \n",
       "min         0.000000     0.000000              3.000000        0.000000   \n",
       "25%         1.000000     0.000000             30.000000        0.000000   \n",
       "50%         6.000000     0.000000             35.000000        0.000000   \n",
       "75%        12.000000     0.000000             38.000000        1.000000   \n",
       "max        36.000000     1.000000             47.000000       10.000000   \n",
       "\n",
       "       Seconds of Use  Frequency of use  Frequency of SMS  \\\n",
       "count     3150.000000       3150.000000       3150.000000   \n",
       "mean      4472.459683         69.460635         73.174921   \n",
       "std       4197.908687         57.413308        112.237560   \n",
       "min          0.000000          0.000000          0.000000   \n",
       "25%       1391.250000         27.000000          6.000000   \n",
       "50%       2990.000000         54.000000         21.000000   \n",
       "75%       6478.250000         95.000000         87.000000   \n",
       "max      17090.000000        255.000000        522.000000   \n",
       "\n",
       "       Distinct Called Numbers    Age Group  Tariff Plan       Status  \\\n",
       "count              3150.000000  3150.000000  3150.000000  3150.000000   \n",
       "mean                 23.509841     2.826032     1.077778     1.248254   \n",
       "std                  17.217337     0.892555     0.267864     0.432069   \n",
       "min                   0.000000     1.000000     1.000000     1.000000   \n",
       "25%                  10.000000     2.000000     1.000000     1.000000   \n",
       "50%                  21.000000     3.000000     1.000000     1.000000   \n",
       "75%                  34.000000     3.000000     1.000000     1.000000   \n",
       "max                  97.000000     5.000000     2.000000     2.000000   \n",
       "\n",
       "               Age  Customer Value        Churn  \n",
       "count  3150.000000     3150.000000  3150.000000  \n",
       "mean     30.998413      470.972916     0.157143  \n",
       "std       8.831095      517.015433     0.363993  \n",
       "min      15.000000        0.000000     0.000000  \n",
       "25%      25.000000      113.801250     0.000000  \n",
       "50%      30.000000      228.480000     0.000000  \n",
       "75%      30.000000      788.388750     0.000000  \n",
       "max      55.000000     2165.280000     1.000000  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "820035e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30.0    78\n",
       "25.0    37\n",
       "45.0    26\n",
       "Name: Age, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_stat.Age.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c3838f00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    140\n",
       "2.0      1\n",
       "Name: Tariff Plan, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_stat['Tariff Plan'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a6b859",
   "metadata": {},
   "source": [
    "### While we do not have access to narrative data from which to draw insights. We can get an understanding of the nature of the complains fromt he existing data.\n",
    "\n",
    "- Age Group: 25-45 years old (81.5% of complains come from 25-35 year old age category)\n",
    "- Tarrif Plan: 99% of complaints exist on Pay-as-you-go plan\n",
    "- Subscription Lenght: On average 35 months.\n",
    "- Customer Value: Customers churned who were associated with a complaint were had an average Customer Value of 146 compared to the whole dataset average score of 470. This may seem like a low number, but when compared to the total churn data which has an average customer value score of 125, we can see that at the 50 percentile range the custoemr value score is 97 and jumps to 181 at the 75 percentile. In terms of capturing churned customers, those customer associated with a complaint actually represent the higher end of customer value.\n",
    "- Frequency of SMS is the highest predictor of customer value, this is presuming that SMS carries the highest network charge and as a result drives up the company bottom line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "37918a4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Call  Failure</th>\n",
       "      <th>Complains</th>\n",
       "      <th>Subscription  Length</th>\n",
       "      <th>Charge  Amount</th>\n",
       "      <th>Seconds of Use</th>\n",
       "      <th>Frequency of use</th>\n",
       "      <th>Frequency of SMS</th>\n",
       "      <th>Distinct Called Numbers</th>\n",
       "      <th>Age Group</th>\n",
       "      <th>Tariff Plan</th>\n",
       "      <th>Status</th>\n",
       "      <th>Age</th>\n",
       "      <th>Customer Value</th>\n",
       "      <th>Churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>875.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>40.005</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>955.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>117.090</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5818.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>383.220</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2990.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>157.240</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3126</th>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3295.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>197.680</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3127</th>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2573.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>168.075</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3128</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>438.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>45.840</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3131</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>933.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>63.650</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3149</th>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1792.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>100.680</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>495 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Call  Failure  Complains  Subscription  Length  Charge  Amount  \\\n",
       "16              0.0        0.0                  37.0             0.0   \n",
       "18              0.0        0.0                  37.0             0.0   \n",
       "22             23.0        1.0                  33.0             0.0   \n",
       "24             13.0        1.0                  36.0             1.0   \n",
       "26              9.0        0.0                  35.0             0.0   \n",
       "...             ...        ...                   ...             ...   \n",
       "3126           14.0        1.0                  37.0             0.0   \n",
       "3127           14.0        1.0                  38.0             0.0   \n",
       "3128            5.0        0.0                  38.0             0.0   \n",
       "3131            5.0        1.0                  38.0             0.0   \n",
       "3149            8.0        1.0                  11.0             2.0   \n",
       "\n",
       "      Seconds of Use  Frequency of use  Frequency of SMS  \\\n",
       "16             875.0              14.0               0.0   \n",
       "18               0.0               0.0               0.0   \n",
       "22             955.0              47.0              16.0   \n",
       "24            5818.0              98.0              26.0   \n",
       "26            2990.0              41.0               9.0   \n",
       "...              ...               ...               ...   \n",
       "3126          3295.0              47.0              16.0   \n",
       "3127          2573.0              50.0              41.0   \n",
       "3128           438.0               8.0               7.0   \n",
       "3131           933.0              13.0              16.0   \n",
       "3149          1792.0              25.0               7.0   \n",
       "\n",
       "      Distinct Called Numbers  Age Group  Tariff Plan  Status   Age  \\\n",
       "16                       11.0        2.0          1.0     2.0  25.0   \n",
       "18                        0.0        2.0          1.0     2.0  25.0   \n",
       "22                       17.0        2.0          1.0     2.0  25.0   \n",
       "24                       24.0        2.0          1.0     1.0  25.0   \n",
       "26                       16.0        3.0          1.0     2.0  30.0   \n",
       "...                       ...        ...          ...     ...   ...   \n",
       "3126                     18.0        3.0          1.0     2.0  30.0   \n",
       "3127                     33.0        4.0          1.0     2.0  45.0   \n",
       "3128                      4.0        3.0          1.0     2.0  30.0   \n",
       "3131                      6.0        4.0          1.0     2.0  45.0   \n",
       "3149                      9.0        3.0          1.0     1.0  30.0   \n",
       "\n",
       "      Customer Value  Churn  \n",
       "16            40.005    1.0  \n",
       "18             0.000    1.0  \n",
       "22           117.090    1.0  \n",
       "24           383.220    1.0  \n",
       "26           157.240    1.0  \n",
       "...              ...    ...  \n",
       "3126         197.680    1.0  \n",
       "3127         168.075    1.0  \n",
       "3128          45.840    1.0  \n",
       "3131          63.650    1.0  \n",
       "3149         100.680    1.0  \n",
       "\n",
       "[495 rows x 14 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_maxVal = df[df['Churn'] == 1]\n",
    "df_maxVal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "765fd2d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Call  Failure</th>\n",
       "      <th>Complains</th>\n",
       "      <th>Subscription  Length</th>\n",
       "      <th>Charge  Amount</th>\n",
       "      <th>Seconds of Use</th>\n",
       "      <th>Frequency of use</th>\n",
       "      <th>Frequency of SMS</th>\n",
       "      <th>Distinct Called Numbers</th>\n",
       "      <th>Age Group</th>\n",
       "      <th>Tariff Plan</th>\n",
       "      <th>Status</th>\n",
       "      <th>Age</th>\n",
       "      <th>Customer Value</th>\n",
       "      <th>Churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>495.000000</td>\n",
       "      <td>495.000000</td>\n",
       "      <td>495.000000</td>\n",
       "      <td>495.000000</td>\n",
       "      <td>495.000000</td>\n",
       "      <td>495.000000</td>\n",
       "      <td>495.000000</td>\n",
       "      <td>495.000000</td>\n",
       "      <td>495.000000</td>\n",
       "      <td>495.000000</td>\n",
       "      <td>495.000000</td>\n",
       "      <td>495.000000</td>\n",
       "      <td>495.000000</td>\n",
       "      <td>495.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>7.476768</td>\n",
       "      <td>0.404040</td>\n",
       "      <td>31.894949</td>\n",
       "      <td>0.230303</td>\n",
       "      <td>1566.632323</td>\n",
       "      <td>29.133333</td>\n",
       "      <td>15.802020</td>\n",
       "      <td>12.391919</td>\n",
       "      <td>2.795960</td>\n",
       "      <td>1.012121</td>\n",
       "      <td>1.747475</td>\n",
       "      <td>30.636364</td>\n",
       "      <td>124.811414</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>7.831407</td>\n",
       "      <td>0.491202</td>\n",
       "      <td>9.469163</td>\n",
       "      <td>0.616483</td>\n",
       "      <td>1539.203365</td>\n",
       "      <td>26.323478</td>\n",
       "      <td>23.515289</td>\n",
       "      <td>10.867622</td>\n",
       "      <td>0.711945</td>\n",
       "      <td>0.109538</td>\n",
       "      <td>0.434900</td>\n",
       "      <td>6.886081</td>\n",
       "      <td>129.429850</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>318.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>38.375000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1182.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>96.840000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>11.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2391.500000</td>\n",
       "      <td>45.500000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>181.322500</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>34.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>6123.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>204.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>987.255000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Call  Failure   Complains  Subscription  Length  Charge  Amount  \\\n",
       "count     495.000000  495.000000            495.000000      495.000000   \n",
       "mean        7.476768    0.404040             31.894949        0.230303   \n",
       "std         7.831407    0.491202              9.469163        0.616483   \n",
       "min         0.000000    0.000000              3.000000        0.000000   \n",
       "25%         0.000000    0.000000             31.000000        0.000000   \n",
       "50%         5.000000    0.000000             35.000000        0.000000   \n",
       "75%        11.000000    1.000000             37.000000        0.000000   \n",
       "max        34.000000    1.000000             45.000000        4.000000   \n",
       "\n",
       "       Seconds of Use  Frequency of use  Frequency of SMS  \\\n",
       "count      495.000000        495.000000        495.000000   \n",
       "mean      1566.632323         29.133333         15.802020   \n",
       "std       1539.203365         26.323478         23.515289   \n",
       "min          0.000000          0.000000          0.000000   \n",
       "25%        318.000000          6.000000          0.000000   \n",
       "50%       1182.000000         25.000000          9.000000   \n",
       "75%       2391.500000         45.500000         23.000000   \n",
       "max       6123.000000        100.000000        204.000000   \n",
       "\n",
       "       Distinct Called Numbers   Age Group  Tariff Plan      Status  \\\n",
       "count               495.000000  495.000000   495.000000  495.000000   \n",
       "mean                 12.391919    2.795960     1.012121    1.747475   \n",
       "std                  10.867622    0.711945     0.109538    0.434900   \n",
       "min                   0.000000    2.000000     1.000000    1.000000   \n",
       "25%                   2.000000    2.000000     1.000000    1.000000   \n",
       "50%                  10.000000    3.000000     1.000000    2.000000   \n",
       "75%                  20.000000    3.000000     1.000000    2.000000   \n",
       "max                  48.000000    5.000000     2.000000    2.000000   \n",
       "\n",
       "              Age  Customer Value  Churn  \n",
       "count  495.000000      495.000000  495.0  \n",
       "mean    30.636364      124.811414    1.0  \n",
       "std      6.886081      129.429850    0.0  \n",
       "min     25.000000        0.000000    1.0  \n",
       "25%     25.000000       38.375000    1.0  \n",
       "50%     30.000000       96.840000    1.0  \n",
       "75%     30.000000      181.322500    1.0  \n",
       "max     55.000000      987.255000    1.0  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_maxVal.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dd6c547a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Call  Failure</th>\n",
       "      <th>Complains</th>\n",
       "      <th>Subscription  Length</th>\n",
       "      <th>Charge  Amount</th>\n",
       "      <th>Seconds of Use</th>\n",
       "      <th>Frequency of use</th>\n",
       "      <th>Frequency of SMS</th>\n",
       "      <th>Distinct Called Numbers</th>\n",
       "      <th>Age Group</th>\n",
       "      <th>Tariff Plan</th>\n",
       "      <th>Status</th>\n",
       "      <th>Age</th>\n",
       "      <th>Customer Value</th>\n",
       "      <th>Churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1495.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>987.255</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688</th>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1505.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>202.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>978.390</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1315.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>929.295</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1088</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1010.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>883.800</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>838</th>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1315.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>201.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>858.280</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1624</th>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5628.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>487.170</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>674</th>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6008.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>432.315</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5898.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>431.910</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1424</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5693.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>395.685</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2874</th>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6123.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>392.445</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1724</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5703.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>386.820</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1224</th>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5593.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>386.415</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>974</th>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5818.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>383.220</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5818.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>383.220</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1024</th>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5818.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>383.220</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1874</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5513.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>373.995</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2524</th>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5943.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>370.755</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1124</th>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5573.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>363.060</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5758.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>357.885</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2424</th>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5863.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>349.065</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>774</th>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5818.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>346.950</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2074</th>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5513.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>337.725</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024</th>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5513.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>337.725</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1074</th>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5513.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>337.725</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2868.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>336.880</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Call  Failure  Complains  Subscription  Length  Charge  Amount  \\\n",
       "388             6.0        1.0                  30.0             1.0   \n",
       "688             6.0        1.0                  27.0             1.0   \n",
       "988             4.0        1.0                  27.0             1.0   \n",
       "1088            0.0        1.0                  25.0             0.0   \n",
       "838             6.0        1.0                  32.0             2.0   \n",
       "1624            8.0        1.0                  35.0             1.0   \n",
       "674            15.0        0.0                  36.0             1.0   \n",
       "174            14.0        0.0                  40.0             2.0   \n",
       "1424           10.0        0.0                  37.0             0.0   \n",
       "2874           16.0        0.0                  33.0             1.0   \n",
       "1724           10.0        0.0                  34.0             0.0   \n",
       "1224            9.0        0.0                  38.0             1.0   \n",
       "974            13.0        0.0                  36.0             1.0   \n",
       "24             13.0        1.0                  36.0             1.0   \n",
       "1024           13.0        1.0                  36.0             1.0   \n",
       "1874           10.0        0.0                  39.0             1.0   \n",
       "2524           16.0        0.0                  35.0             2.0   \n",
       "1124           11.0        1.0                  36.0             1.0   \n",
       "124            10.0        0.0                  34.0             0.0   \n",
       "2424           13.0        0.0                  32.0             1.0   \n",
       "774            11.0        0.0                  31.0             0.0   \n",
       "2074            8.0        0.0                  34.0             0.0   \n",
       "2024            8.0        0.0                  34.0             0.0   \n",
       "1074            8.0        1.0                  34.0             0.0   \n",
       "477            13.0        1.0                  36.0             0.0   \n",
       "\n",
       "      Seconds of Use  Frequency of use  Frequency of SMS  \\\n",
       "388           1495.0              44.0             204.0   \n",
       "688           1505.0              37.0             202.0   \n",
       "988           1315.0              36.0             193.0   \n",
       "1088          1010.0              30.0             186.0   \n",
       "838           1315.0              42.0             201.0   \n",
       "1624          5628.0              98.0              51.0   \n",
       "674           6008.0              99.0              35.0   \n",
       "174           5898.0             100.0              36.0   \n",
       "1424          5693.0             100.0              30.0   \n",
       "2874          6123.0              98.0              25.0   \n",
       "1724          5703.0              93.0              28.0   \n",
       "1224          5593.0              94.0              29.0   \n",
       "974           5818.0              98.0              26.0   \n",
       "24            5818.0              98.0              26.0   \n",
       "1024          5818.0              98.0              26.0   \n",
       "1874          5513.0              98.0              27.0   \n",
       "2524          5943.0              96.0              22.0   \n",
       "1124          5573.0              95.0              24.0   \n",
       "124           5758.0              95.0              21.0   \n",
       "2424          5863.0              94.0              18.0   \n",
       "774           5818.0              92.0              18.0   \n",
       "2074          5513.0              92.0              19.0   \n",
       "2024          5513.0              92.0              19.0   \n",
       "1074          5513.0              92.0              19.0   \n",
       "477           2868.0              54.0              55.0   \n",
       "\n",
       "      Distinct Called Numbers  Age Group  Tariff Plan  Status   Age  \\\n",
       "388                      16.0        2.0          2.0     1.0  25.0   \n",
       "688                      14.0        2.0          2.0     1.0  25.0   \n",
       "988                      11.0        2.0          2.0     1.0  25.0   \n",
       "1088                      9.0        2.0          2.0     1.0  25.0   \n",
       "838                      12.0        3.0          2.0     1.0  30.0   \n",
       "1624                     26.0        2.0          1.0     1.0  25.0   \n",
       "674                      27.0        2.0          1.0     1.0  25.0   \n",
       "174                      28.0        2.0          1.0     1.0  25.0   \n",
       "1424                     27.0        2.0          1.0     1.0  25.0   \n",
       "2874                     25.0        2.0          1.0     1.0  25.0   \n",
       "1724                     25.0        2.0          1.0     1.0  25.0   \n",
       "1224                     26.0        2.0          1.0     1.0  25.0   \n",
       "974                      24.0        2.0          1.0     1.0  25.0   \n",
       "24                       24.0        2.0          1.0     1.0  25.0   \n",
       "1024                     24.0        2.0          1.0     1.0  25.0   \n",
       "1874                     23.0        2.0          1.0     1.0  25.0   \n",
       "2524                     21.0        2.0          1.0     1.0  25.0   \n",
       "1124                     24.0        2.0          1.0     1.0  25.0   \n",
       "124                      22.0        2.0          1.0     1.0  25.0   \n",
       "2424                     20.0        2.0          1.0     1.0  25.0   \n",
       "774                      23.0        2.0          1.0     1.0  25.0   \n",
       "2074                     22.0        2.0          1.0     1.0  25.0   \n",
       "2024                     22.0        2.0          1.0     1.0  25.0   \n",
       "1074                     22.0        2.0          1.0     1.0  25.0   \n",
       "477                      46.0        3.0          1.0     2.0  30.0   \n",
       "\n",
       "      Customer Value  Churn  \n",
       "388          987.255    1.0  \n",
       "688          978.390    1.0  \n",
       "988          929.295    1.0  \n",
       "1088         883.800    1.0  \n",
       "838          858.280    1.0  \n",
       "1624         487.170    1.0  \n",
       "674          432.315    1.0  \n",
       "174          431.910    1.0  \n",
       "1424         395.685    1.0  \n",
       "2874         392.445    1.0  \n",
       "1724         386.820    1.0  \n",
       "1224         386.415    1.0  \n",
       "974          383.220    1.0  \n",
       "24           383.220    1.0  \n",
       "1024         383.220    1.0  \n",
       "1874         373.995    1.0  \n",
       "2524         370.755    1.0  \n",
       "1124         363.060    1.0  \n",
       "124          357.885    1.0  \n",
       "2424         349.065    1.0  \n",
       "774          346.950    1.0  \n",
       "2074         337.725    1.0  \n",
       "2024         337.725    1.0  \n",
       "1074         337.725    1.0  \n",
       "477          336.880    1.0  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_maxVal.sort_values('Customer Value',ascending=False).head(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "355c7702",
   "metadata": {},
   "source": [
    "## Data Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d7b110e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-03 18:24:45.701992: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-04-03 18:24:46.012312: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-04-03 18:24:46.012402: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-04-03 18:24:46.089076: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-04-03 18:24:46.242885: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-04-03 18:24:46.244333: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-03 18:24:47.651124: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "be532f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['Churn']\n",
    "X = df.drop('Churn',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "dadb2e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "8d9a3be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "3a5850d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train Shape :  (2520, 13)\n",
      "X_test Shape :  (630, 13)\n",
      "y_train Shape :  (2520,)\n",
      "y_test Shape :  (630,)\n"
     ]
    }
   ],
   "source": [
    "# check the shape of X_train & X_test, y_train & y_test\n",
    "print(\"X_train Shape : \", X_train.shape)\n",
    "print(\"X_test Shape : \", X_test.shape)\n",
    "print(\"y_train Shape : \", y_train.shape)\n",
    "print(\"y_test Shape : \", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac62d4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "best - 0.9634920634920635 <keras.src.optimizers.adagrad.Adagrad object at 0x79b65e5248e0> 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7bdca48",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_acc = 0\n",
    "best_opt = None\n",
    "best_mid_layer = None\n",
    "\n",
    "for i in range(13):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=13, activation='relu', input_dim=13))\n",
    "    model.add(Dense(units=i+1, activation='relu', input_dim=i+1))\n",
    "    model.add(Dense(units=1, activation='sigmoid'))\n",
    "    \n",
    "    optimizers = [keras.optimizers.RMSprop(),\n",
    "                  'adam',\n",
    "                  keras.optimizers.AdamW(),\n",
    "                  keras.optimizers.Nadam(),\n",
    "                  keras.optimizers.Adamax(), \n",
    "                  keras.optimizers.Adagrad(), \n",
    "                  keras.optimizers.Adadelta(), \n",
    "                  keras.optimizers.Adafactor(), \n",
    "                  keras.optimizers.Ftrl(), \n",
    "                  keras.optimizers.Lion(),\n",
    "                  keras.optimizers.SGD()]\n",
    "    for k in range(len(optimizers)):\n",
    "        model.compile(loss='binary_crossentropy', optimizer= optimizers[k] , metrics=['accuracy'])\n",
    "        model.fit(X_train_scaled, y_train, epochs = 100, validation_split=0.2)\n",
    "        y_log = model.predict(X_test_scaled)\n",
    "        y_pred = np.where(y_log > 0.5, 1, 0)\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        \n",
    "        if acc > best_acc:\n",
    "            best_mid_layer = i\n",
    "            best_opt = optimizers[k]\n",
    "            best_acc = acc\n",
    "            \n",
    "print(best_acc , best_opt, best_mid_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "14a78a3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.8028 - accuracy: 0.2912 - val_loss: 0.8061 - val_accuracy: 0.2679\n",
      "Epoch 2/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.7769 - accuracy: 0.3204 - val_loss: 0.7843 - val_accuracy: 0.3036\n",
      "Epoch 3/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.7587 - accuracy: 0.3502 - val_loss: 0.7676 - val_accuracy: 0.3254\n",
      "Epoch 4/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.7441 - accuracy: 0.3760 - val_loss: 0.7538 - val_accuracy: 0.3452\n",
      "Epoch 5/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.7316 - accuracy: 0.4048 - val_loss: 0.7420 - val_accuracy: 0.3810\n",
      "Epoch 6/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.7207 - accuracy: 0.4325 - val_loss: 0.7316 - val_accuracy: 0.3968\n",
      "Epoch 7/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.7110 - accuracy: 0.4524 - val_loss: 0.7223 - val_accuracy: 0.4325\n",
      "Epoch 8/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.7023 - accuracy: 0.4732 - val_loss: 0.7138 - val_accuracy: 0.4663\n",
      "Epoch 9/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6942 - accuracy: 0.4985 - val_loss: 0.7060 - val_accuracy: 0.4960\n",
      "Epoch 10/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6868 - accuracy: 0.5188 - val_loss: 0.6987 - val_accuracy: 0.5258\n",
      "Epoch 11/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6798 - accuracy: 0.5511 - val_loss: 0.6919 - val_accuracy: 0.5536\n",
      "Epoch 12/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6733 - accuracy: 0.5789 - val_loss: 0.6854 - val_accuracy: 0.5774\n",
      "Epoch 13/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6671 - accuracy: 0.6007 - val_loss: 0.6793 - val_accuracy: 0.5833\n",
      "Epoch 14/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6613 - accuracy: 0.6205 - val_loss: 0.6735 - val_accuracy: 0.6012\n",
      "Epoch 15/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6558 - accuracy: 0.6399 - val_loss: 0.6681 - val_accuracy: 0.6310\n",
      "Epoch 16/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6506 - accuracy: 0.6553 - val_loss: 0.6629 - val_accuracy: 0.6349\n",
      "Epoch 17/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6456 - accuracy: 0.6761 - val_loss: 0.6580 - val_accuracy: 0.6409\n",
      "Epoch 18/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6409 - accuracy: 0.6939 - val_loss: 0.6533 - val_accuracy: 0.6488\n",
      "Epoch 19/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6364 - accuracy: 0.7044 - val_loss: 0.6489 - val_accuracy: 0.6786\n",
      "Epoch 20/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6321 - accuracy: 0.7237 - val_loss: 0.6446 - val_accuracy: 0.6944\n",
      "Epoch 21/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6280 - accuracy: 0.7312 - val_loss: 0.6406 - val_accuracy: 0.7024\n",
      "Epoch 22/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6240 - accuracy: 0.7381 - val_loss: 0.6367 - val_accuracy: 0.7143\n",
      "Epoch 23/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6202 - accuracy: 0.7470 - val_loss: 0.6329 - val_accuracy: 0.7262\n",
      "Epoch 24/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6165 - accuracy: 0.7540 - val_loss: 0.6292 - val_accuracy: 0.7341\n",
      "Epoch 25/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6129 - accuracy: 0.7584 - val_loss: 0.6257 - val_accuracy: 0.7361\n",
      "Epoch 26/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6095 - accuracy: 0.7649 - val_loss: 0.6222 - val_accuracy: 0.7520\n",
      "Epoch 27/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6061 - accuracy: 0.7817 - val_loss: 0.6189 - val_accuracy: 0.7698\n",
      "Epoch 28/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6029 - accuracy: 0.8021 - val_loss: 0.6157 - val_accuracy: 0.7837\n",
      "Epoch 29/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5997 - accuracy: 0.8140 - val_loss: 0.6125 - val_accuracy: 0.7937\n",
      "Epoch 30/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5966 - accuracy: 0.8214 - val_loss: 0.6095 - val_accuracy: 0.8075\n",
      "Epoch 31/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5937 - accuracy: 0.8343 - val_loss: 0.6065 - val_accuracy: 0.8234\n",
      "Epoch 32/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5908 - accuracy: 0.8447 - val_loss: 0.6036 - val_accuracy: 0.8294\n",
      "Epoch 33/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.5879 - accuracy: 0.8487 - val_loss: 0.6008 - val_accuracy: 0.8333\n",
      "Epoch 34/100\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.5852 - accuracy: 0.8512 - val_loss: 0.5981 - val_accuracy: 0.8353\n",
      "Epoch 35/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.5825 - accuracy: 0.8537 - val_loss: 0.5954 - val_accuracy: 0.8472\n",
      "Epoch 36/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.5799 - accuracy: 0.8547 - val_loss: 0.5928 - val_accuracy: 0.8512\n",
      "Epoch 37/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.5773 - accuracy: 0.8596 - val_loss: 0.5902 - val_accuracy: 0.8532\n",
      "Epoch 38/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.5747 - accuracy: 0.8636 - val_loss: 0.5877 - val_accuracy: 0.8591\n",
      "Epoch 39/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5723 - accuracy: 0.8661 - val_loss: 0.5852 - val_accuracy: 0.8591\n",
      "Epoch 40/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5698 - accuracy: 0.8715 - val_loss: 0.5828 - val_accuracy: 0.8591\n",
      "Epoch 41/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.5674 - accuracy: 0.8750 - val_loss: 0.5804 - val_accuracy: 0.8611\n",
      "Epoch 42/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.5651 - accuracy: 0.8775 - val_loss: 0.5780 - val_accuracy: 0.8631\n",
      "Epoch 43/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.5628 - accuracy: 0.8790 - val_loss: 0.5757 - val_accuracy: 0.8671\n",
      "Epoch 44/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5605 - accuracy: 0.8800 - val_loss: 0.5734 - val_accuracy: 0.8671\n",
      "Epoch 45/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5582 - accuracy: 0.8819 - val_loss: 0.5712 - val_accuracy: 0.8730\n",
      "Epoch 46/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.5561 - accuracy: 0.8834 - val_loss: 0.5690 - val_accuracy: 0.8730\n",
      "Epoch 47/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5539 - accuracy: 0.8864 - val_loss: 0.5668 - val_accuracy: 0.8770\n",
      "Epoch 48/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5518 - accuracy: 0.8894 - val_loss: 0.5647 - val_accuracy: 0.8790\n",
      "Epoch 49/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5497 - accuracy: 0.8899 - val_loss: 0.5626 - val_accuracy: 0.8790\n",
      "Epoch 50/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5476 - accuracy: 0.8909 - val_loss: 0.5606 - val_accuracy: 0.8770\n",
      "Epoch 51/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5456 - accuracy: 0.8914 - val_loss: 0.5586 - val_accuracy: 0.8770\n",
      "Epoch 52/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5436 - accuracy: 0.8914 - val_loss: 0.5566 - val_accuracy: 0.8790\n",
      "Epoch 53/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5416 - accuracy: 0.8929 - val_loss: 0.5546 - val_accuracy: 0.8790\n",
      "Epoch 54/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5396 - accuracy: 0.8938 - val_loss: 0.5526 - val_accuracy: 0.8810\n",
      "Epoch 55/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5377 - accuracy: 0.8943 - val_loss: 0.5507 - val_accuracy: 0.8829\n",
      "Epoch 56/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5358 - accuracy: 0.8943 - val_loss: 0.5488 - val_accuracy: 0.8829\n",
      "Epoch 57/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5339 - accuracy: 0.8948 - val_loss: 0.5469 - val_accuracy: 0.8849\n",
      "Epoch 58/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5321 - accuracy: 0.8953 - val_loss: 0.5450 - val_accuracy: 0.8849\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5302 - accuracy: 0.8958 - val_loss: 0.5432 - val_accuracy: 0.8869\n",
      "Epoch 60/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5284 - accuracy: 0.8963 - val_loss: 0.5414 - val_accuracy: 0.8889\n",
      "Epoch 61/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5266 - accuracy: 0.8973 - val_loss: 0.5396 - val_accuracy: 0.8909\n",
      "Epoch 62/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5248 - accuracy: 0.8983 - val_loss: 0.5378 - val_accuracy: 0.8909\n",
      "Epoch 63/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5230 - accuracy: 0.8993 - val_loss: 0.5361 - val_accuracy: 0.8909\n",
      "Epoch 64/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5213 - accuracy: 0.9003 - val_loss: 0.5343 - val_accuracy: 0.8889\n",
      "Epoch 65/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5196 - accuracy: 0.9008 - val_loss: 0.5326 - val_accuracy: 0.8889\n",
      "Epoch 66/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5179 - accuracy: 0.9013 - val_loss: 0.5309 - val_accuracy: 0.8889\n",
      "Epoch 67/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5162 - accuracy: 0.9013 - val_loss: 0.5292 - val_accuracy: 0.8889\n",
      "Epoch 68/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5145 - accuracy: 0.9013 - val_loss: 0.5276 - val_accuracy: 0.8909\n",
      "Epoch 69/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5128 - accuracy: 0.9008 - val_loss: 0.5259 - val_accuracy: 0.8909\n",
      "Epoch 70/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5112 - accuracy: 0.9013 - val_loss: 0.5243 - val_accuracy: 0.8909\n",
      "Epoch 71/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5096 - accuracy: 0.9013 - val_loss: 0.5227 - val_accuracy: 0.8909\n",
      "Epoch 72/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5079 - accuracy: 0.9013 - val_loss: 0.5211 - val_accuracy: 0.8909\n",
      "Epoch 73/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5063 - accuracy: 0.9008 - val_loss: 0.5195 - val_accuracy: 0.8909\n",
      "Epoch 74/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5048 - accuracy: 0.9008 - val_loss: 0.5179 - val_accuracy: 0.8929\n",
      "Epoch 75/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5032 - accuracy: 0.9008 - val_loss: 0.5164 - val_accuracy: 0.8929\n",
      "Epoch 76/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5016 - accuracy: 0.9003 - val_loss: 0.5148 - val_accuracy: 0.8929\n",
      "Epoch 77/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5001 - accuracy: 0.9008 - val_loss: 0.5133 - val_accuracy: 0.8929\n",
      "Epoch 78/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4986 - accuracy: 0.9013 - val_loss: 0.5118 - val_accuracy: 0.8929\n",
      "Epoch 79/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4970 - accuracy: 0.9013 - val_loss: 0.5103 - val_accuracy: 0.8929\n",
      "Epoch 80/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4955 - accuracy: 0.9013 - val_loss: 0.5088 - val_accuracy: 0.8929\n",
      "Epoch 81/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4941 - accuracy: 0.9018 - val_loss: 0.5073 - val_accuracy: 0.8929\n",
      "Epoch 82/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4926 - accuracy: 0.9018 - val_loss: 0.5058 - val_accuracy: 0.8929\n",
      "Epoch 83/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4911 - accuracy: 0.9018 - val_loss: 0.5044 - val_accuracy: 0.8929\n",
      "Epoch 84/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4897 - accuracy: 0.9018 - val_loss: 0.5029 - val_accuracy: 0.8929\n",
      "Epoch 85/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4882 - accuracy: 0.9018 - val_loss: 0.5015 - val_accuracy: 0.8929\n",
      "Epoch 86/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4868 - accuracy: 0.9023 - val_loss: 0.5001 - val_accuracy: 0.8929\n",
      "Epoch 87/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4854 - accuracy: 0.9023 - val_loss: 0.4987 - val_accuracy: 0.8929\n",
      "Epoch 88/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4840 - accuracy: 0.9023 - val_loss: 0.4973 - val_accuracy: 0.8929\n",
      "Epoch 89/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4826 - accuracy: 0.9023 - val_loss: 0.4959 - val_accuracy: 0.8929\n",
      "Epoch 90/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4812 - accuracy: 0.9023 - val_loss: 0.4945 - val_accuracy: 0.8929\n",
      "Epoch 91/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4798 - accuracy: 0.9023 - val_loss: 0.4932 - val_accuracy: 0.8929\n",
      "Epoch 92/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4785 - accuracy: 0.9023 - val_loss: 0.4918 - val_accuracy: 0.8929\n",
      "Epoch 93/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4771 - accuracy: 0.9023 - val_loss: 0.4905 - val_accuracy: 0.8929\n",
      "Epoch 94/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4758 - accuracy: 0.9023 - val_loss: 0.4891 - val_accuracy: 0.8929\n",
      "Epoch 95/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4745 - accuracy: 0.9023 - val_loss: 0.4878 - val_accuracy: 0.8929\n",
      "Epoch 96/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4732 - accuracy: 0.9023 - val_loss: 0.4865 - val_accuracy: 0.8929\n",
      "Epoch 97/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4719 - accuracy: 0.9023 - val_loss: 0.4852 - val_accuracy: 0.8929\n",
      "Epoch 98/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4706 - accuracy: 0.9023 - val_loss: 0.4839 - val_accuracy: 0.8929\n",
      "Epoch 99/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4693 - accuracy: 0.9023 - val_loss: 0.4827 - val_accuracy: 0.8929\n",
      "Epoch 100/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4680 - accuracy: 0.9023 - val_loss: 0.4814 - val_accuracy: 0.8929\n",
      "20/20 [==============================] - 0s 887us/step\n",
      "Epoch 1/250\n",
      "63/63 [==============================] - 1s 4ms/step - loss: 0.4601 - accuracy: 0.9028 - val_loss: 0.4687 - val_accuracy: 0.8929\n",
      "Epoch 2/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.4510 - accuracy: 0.9028 - val_loss: 0.4613 - val_accuracy: 0.8929\n",
      "Epoch 3/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4444 - accuracy: 0.9028 - val_loss: 0.4553 - val_accuracy: 0.8929\n",
      "Epoch 4/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4389 - accuracy: 0.9028 - val_loss: 0.4502 - val_accuracy: 0.8929\n",
      "Epoch 5/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4340 - accuracy: 0.9028 - val_loss: 0.4456 - val_accuracy: 0.8929\n",
      "Epoch 6/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4297 - accuracy: 0.9028 - val_loss: 0.4414 - val_accuracy: 0.8929\n",
      "Epoch 7/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4258 - accuracy: 0.9028 - val_loss: 0.4376 - val_accuracy: 0.8929\n",
      "Epoch 8/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4221 - accuracy: 0.9033 - val_loss: 0.4341 - val_accuracy: 0.8929\n",
      "Epoch 9/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4187 - accuracy: 0.9033 - val_loss: 0.4308 - val_accuracy: 0.8929\n",
      "Epoch 10/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4156 - accuracy: 0.9033 - val_loss: 0.4277 - val_accuracy: 0.8948\n",
      "Epoch 11/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4126 - accuracy: 0.9033 - val_loss: 0.4247 - val_accuracy: 0.8948\n",
      "Epoch 12/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4097 - accuracy: 0.9033 - val_loss: 0.4219 - val_accuracy: 0.8948\n",
      "Epoch 13/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4070 - accuracy: 0.9033 - val_loss: 0.4193 - val_accuracy: 0.8948\n",
      "Epoch 14/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4044 - accuracy: 0.9033 - val_loss: 0.4167 - val_accuracy: 0.8948\n",
      "Epoch 15/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4019 - accuracy: 0.9033 - val_loss: 0.4143 - val_accuracy: 0.8948\n",
      "Epoch 16/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3996 - accuracy: 0.9033 - val_loss: 0.4120 - val_accuracy: 0.8948\n",
      "Epoch 17/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3973 - accuracy: 0.9033 - val_loss: 0.4097 - val_accuracy: 0.8948\n",
      "Epoch 18/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3951 - accuracy: 0.9033 - val_loss: 0.4076 - val_accuracy: 0.8948\n",
      "Epoch 19/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3930 - accuracy: 0.9033 - val_loss: 0.4055 - val_accuracy: 0.8948\n",
      "Epoch 20/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3909 - accuracy: 0.9033 - val_loss: 0.4034 - val_accuracy: 0.8948\n",
      "Epoch 21/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3889 - accuracy: 0.9033 - val_loss: 0.4015 - val_accuracy: 0.8948\n",
      "Epoch 22/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3870 - accuracy: 0.9033 - val_loss: 0.3996 - val_accuracy: 0.8948\n",
      "Epoch 23/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3852 - accuracy: 0.9033 - val_loss: 0.3978 - val_accuracy: 0.8948\n",
      "Epoch 24/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3834 - accuracy: 0.9033 - val_loss: 0.3960 - val_accuracy: 0.8948\n",
      "Epoch 25/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3816 - accuracy: 0.9033 - val_loss: 0.3942 - val_accuracy: 0.8948\n",
      "Epoch 26/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3799 - accuracy: 0.9033 - val_loss: 0.3925 - val_accuracy: 0.8948\n",
      "Epoch 27/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3783 - accuracy: 0.9033 - val_loss: 0.3909 - val_accuracy: 0.8929\n",
      "Epoch 28/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3767 - accuracy: 0.9033 - val_loss: 0.3893 - val_accuracy: 0.8929\n",
      "Epoch 29/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3751 - accuracy: 0.9033 - val_loss: 0.3877 - val_accuracy: 0.8929\n",
      "Epoch 30/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3736 - accuracy: 0.9033 - val_loss: 0.3862 - val_accuracy: 0.8929\n",
      "Epoch 31/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3721 - accuracy: 0.9033 - val_loss: 0.3847 - val_accuracy: 0.8929\n",
      "Epoch 32/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3706 - accuracy: 0.9033 - val_loss: 0.3833 - val_accuracy: 0.8929\n",
      "Epoch 33/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3692 - accuracy: 0.9033 - val_loss: 0.3818 - val_accuracy: 0.8929\n",
      "Epoch 34/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3678 - accuracy: 0.9028 - val_loss: 0.3805 - val_accuracy: 0.8929\n",
      "Epoch 35/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3665 - accuracy: 0.9028 - val_loss: 0.3791 - val_accuracy: 0.8929\n",
      "Epoch 36/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3651 - accuracy: 0.9023 - val_loss: 0.3778 - val_accuracy: 0.8929\n",
      "Epoch 37/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3638 - accuracy: 0.9023 - val_loss: 0.3765 - val_accuracy: 0.8929\n",
      "Epoch 38/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3625 - accuracy: 0.9023 - val_loss: 0.3752 - val_accuracy: 0.8929\n",
      "Epoch 39/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3613 - accuracy: 0.9023 - val_loss: 0.3739 - val_accuracy: 0.8929\n",
      "Epoch 40/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3601 - accuracy: 0.9023 - val_loss: 0.3727 - val_accuracy: 0.8929\n",
      "Epoch 41/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3589 - accuracy: 0.9023 - val_loss: 0.3715 - val_accuracy: 0.8929\n",
      "Epoch 42/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3577 - accuracy: 0.9023 - val_loss: 0.3703 - val_accuracy: 0.8929\n",
      "Epoch 43/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3566 - accuracy: 0.9023 - val_loss: 0.3692 - val_accuracy: 0.8929\n",
      "Epoch 44/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3554 - accuracy: 0.9023 - val_loss: 0.3680 - val_accuracy: 0.8929\n",
      "Epoch 45/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3543 - accuracy: 0.9023 - val_loss: 0.3669 - val_accuracy: 0.8929\n",
      "Epoch 46/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3532 - accuracy: 0.9023 - val_loss: 0.3658 - val_accuracy: 0.8929\n",
      "Epoch 47/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3522 - accuracy: 0.9023 - val_loss: 0.3648 - val_accuracy: 0.8929\n",
      "Epoch 48/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3511 - accuracy: 0.9023 - val_loss: 0.3637 - val_accuracy: 0.8929\n",
      "Epoch 49/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3501 - accuracy: 0.9023 - val_loss: 0.3627 - val_accuracy: 0.8929\n",
      "Epoch 50/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3490 - accuracy: 0.9023 - val_loss: 0.3616 - val_accuracy: 0.8929\n",
      "Epoch 51/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3480 - accuracy: 0.9023 - val_loss: 0.3606 - val_accuracy: 0.8929\n",
      "Epoch 52/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3471 - accuracy: 0.9023 - val_loss: 0.3596 - val_accuracy: 0.8929\n",
      "Epoch 53/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3461 - accuracy: 0.9023 - val_loss: 0.3587 - val_accuracy: 0.8929\n",
      "Epoch 54/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3451 - accuracy: 0.9023 - val_loss: 0.3577 - val_accuracy: 0.8929\n",
      "Epoch 55/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3442 - accuracy: 0.9023 - val_loss: 0.3568 - val_accuracy: 0.8929\n",
      "Epoch 56/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3433 - accuracy: 0.9023 - val_loss: 0.3558 - val_accuracy: 0.8929\n",
      "Epoch 57/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3424 - accuracy: 0.9023 - val_loss: 0.3549 - val_accuracy: 0.8929\n",
      "Epoch 58/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3415 - accuracy: 0.9023 - val_loss: 0.3540 - val_accuracy: 0.8929\n",
      "Epoch 59/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3406 - accuracy: 0.9023 - val_loss: 0.3531 - val_accuracy: 0.8929\n",
      "Epoch 60/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3397 - accuracy: 0.9023 - val_loss: 0.3523 - val_accuracy: 0.8929\n",
      "Epoch 61/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3389 - accuracy: 0.9023 - val_loss: 0.3514 - val_accuracy: 0.8929\n",
      "Epoch 62/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3380 - accuracy: 0.9023 - val_loss: 0.3505 - val_accuracy: 0.8929\n",
      "Epoch 63/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3372 - accuracy: 0.9023 - val_loss: 0.3497 - val_accuracy: 0.8929\n",
      "Epoch 64/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3364 - accuracy: 0.9023 - val_loss: 0.3489 - val_accuracy: 0.8929\n",
      "Epoch 65/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3356 - accuracy: 0.9023 - val_loss: 0.3481 - val_accuracy: 0.8929\n",
      "Epoch 66/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3348 - accuracy: 0.9023 - val_loss: 0.3473 - val_accuracy: 0.8929\n",
      "Epoch 67/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3340 - accuracy: 0.9023 - val_loss: 0.3465 - val_accuracy: 0.8929\n",
      "Epoch 68/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3332 - accuracy: 0.9023 - val_loss: 0.3457 - val_accuracy: 0.8929\n",
      "Epoch 69/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3324 - accuracy: 0.9028 - val_loss: 0.3449 - val_accuracy: 0.8929\n",
      "Epoch 70/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3317 - accuracy: 0.9028 - val_loss: 0.3441 - val_accuracy: 0.8929\n",
      "Epoch 71/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3309 - accuracy: 0.9028 - val_loss: 0.3434 - val_accuracy: 0.8929\n",
      "Epoch 72/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3302 - accuracy: 0.9028 - val_loss: 0.3426 - val_accuracy: 0.8929\n",
      "Epoch 73/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3295 - accuracy: 0.9028 - val_loss: 0.3419 - val_accuracy: 0.8929\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3287 - accuracy: 0.9028 - val_loss: 0.3412 - val_accuracy: 0.8929\n",
      "Epoch 75/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3280 - accuracy: 0.9028 - val_loss: 0.3405 - val_accuracy: 0.8929\n",
      "Epoch 76/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3273 - accuracy: 0.9028 - val_loss: 0.3398 - val_accuracy: 0.8929\n",
      "Epoch 77/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3266 - accuracy: 0.9028 - val_loss: 0.3391 - val_accuracy: 0.8929\n",
      "Epoch 78/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3260 - accuracy: 0.9028 - val_loss: 0.3384 - val_accuracy: 0.8929\n",
      "Epoch 79/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3253 - accuracy: 0.9028 - val_loss: 0.3377 - val_accuracy: 0.8929\n",
      "Epoch 80/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3246 - accuracy: 0.9028 - val_loss: 0.3370 - val_accuracy: 0.8929\n",
      "Epoch 81/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3240 - accuracy: 0.9028 - val_loss: 0.3363 - val_accuracy: 0.8929\n",
      "Epoch 82/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3233 - accuracy: 0.9028 - val_loss: 0.3357 - val_accuracy: 0.8929\n",
      "Epoch 83/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3227 - accuracy: 0.9028 - val_loss: 0.3350 - val_accuracy: 0.8929\n",
      "Epoch 84/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3220 - accuracy: 0.9028 - val_loss: 0.3344 - val_accuracy: 0.8929\n",
      "Epoch 85/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3214 - accuracy: 0.9028 - val_loss: 0.3338 - val_accuracy: 0.8929\n",
      "Epoch 86/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3208 - accuracy: 0.9028 - val_loss: 0.3331 - val_accuracy: 0.8929\n",
      "Epoch 87/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3202 - accuracy: 0.9028 - val_loss: 0.3325 - val_accuracy: 0.8929\n",
      "Epoch 88/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3196 - accuracy: 0.9028 - val_loss: 0.3319 - val_accuracy: 0.8929\n",
      "Epoch 89/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3190 - accuracy: 0.9028 - val_loss: 0.3313 - val_accuracy: 0.8929\n",
      "Epoch 90/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3184 - accuracy: 0.9028 - val_loss: 0.3307 - val_accuracy: 0.8929\n",
      "Epoch 91/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3178 - accuracy: 0.9028 - val_loss: 0.3301 - val_accuracy: 0.8929\n",
      "Epoch 92/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3172 - accuracy: 0.9028 - val_loss: 0.3295 - val_accuracy: 0.8929\n",
      "Epoch 93/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.3166 - accuracy: 0.9028 - val_loss: 0.3289 - val_accuracy: 0.8929\n",
      "Epoch 94/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.3160 - accuracy: 0.9028 - val_loss: 0.3283 - val_accuracy: 0.8929\n",
      "Epoch 95/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3155 - accuracy: 0.9028 - val_loss: 0.3278 - val_accuracy: 0.8929\n",
      "Epoch 96/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.3149 - accuracy: 0.9028 - val_loss: 0.3272 - val_accuracy: 0.8929\n",
      "Epoch 97/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.3144 - accuracy: 0.9028 - val_loss: 0.3267 - val_accuracy: 0.8929\n",
      "Epoch 98/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.3138 - accuracy: 0.9028 - val_loss: 0.3261 - val_accuracy: 0.8929\n",
      "Epoch 99/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.3133 - accuracy: 0.9028 - val_loss: 0.3256 - val_accuracy: 0.8929\n",
      "Epoch 100/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.3128 - accuracy: 0.9028 - val_loss: 0.3250 - val_accuracy: 0.8929\n",
      "Epoch 101/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3122 - accuracy: 0.9028 - val_loss: 0.3245 - val_accuracy: 0.8929\n",
      "Epoch 102/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.3117 - accuracy: 0.9028 - val_loss: 0.3239 - val_accuracy: 0.8929\n",
      "Epoch 103/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3112 - accuracy: 0.9028 - val_loss: 0.3234 - val_accuracy: 0.8929\n",
      "Epoch 104/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3107 - accuracy: 0.9028 - val_loss: 0.3229 - val_accuracy: 0.8929\n",
      "Epoch 105/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3102 - accuracy: 0.9028 - val_loss: 0.3224 - val_accuracy: 0.8929\n",
      "Epoch 106/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3097 - accuracy: 0.9028 - val_loss: 0.3219 - val_accuracy: 0.8929\n",
      "Epoch 107/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3092 - accuracy: 0.9028 - val_loss: 0.3214 - val_accuracy: 0.8929\n",
      "Epoch 108/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3087 - accuracy: 0.9028 - val_loss: 0.3209 - val_accuracy: 0.8929\n",
      "Epoch 109/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3082 - accuracy: 0.9028 - val_loss: 0.3204 - val_accuracy: 0.8929\n",
      "Epoch 110/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3077 - accuracy: 0.9028 - val_loss: 0.3199 - val_accuracy: 0.8929\n",
      "Epoch 111/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3072 - accuracy: 0.9028 - val_loss: 0.3194 - val_accuracy: 0.8929\n",
      "Epoch 112/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3067 - accuracy: 0.9028 - val_loss: 0.3189 - val_accuracy: 0.8929\n",
      "Epoch 113/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3063 - accuracy: 0.9028 - val_loss: 0.3184 - val_accuracy: 0.8929\n",
      "Epoch 114/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3058 - accuracy: 0.9028 - val_loss: 0.3179 - val_accuracy: 0.8929\n",
      "Epoch 115/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3053 - accuracy: 0.9028 - val_loss: 0.3175 - val_accuracy: 0.8929\n",
      "Epoch 116/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3049 - accuracy: 0.9028 - val_loss: 0.3170 - val_accuracy: 0.8929\n",
      "Epoch 117/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3044 - accuracy: 0.9028 - val_loss: 0.3165 - val_accuracy: 0.8929\n",
      "Epoch 118/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3040 - accuracy: 0.9028 - val_loss: 0.3161 - val_accuracy: 0.8929\n",
      "Epoch 119/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3035 - accuracy: 0.9028 - val_loss: 0.3156 - val_accuracy: 0.8929\n",
      "Epoch 120/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3031 - accuracy: 0.9028 - val_loss: 0.3152 - val_accuracy: 0.8929\n",
      "Epoch 121/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3027 - accuracy: 0.9028 - val_loss: 0.3147 - val_accuracy: 0.8929\n",
      "Epoch 122/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3022 - accuracy: 0.9028 - val_loss: 0.3143 - val_accuracy: 0.8929\n",
      "Epoch 123/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3018 - accuracy: 0.9028 - val_loss: 0.3138 - val_accuracy: 0.8929\n",
      "Epoch 124/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3014 - accuracy: 0.9028 - val_loss: 0.3134 - val_accuracy: 0.8929\n",
      "Epoch 125/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3009 - accuracy: 0.9028 - val_loss: 0.3130 - val_accuracy: 0.8929\n",
      "Epoch 126/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3005 - accuracy: 0.9028 - val_loss: 0.3125 - val_accuracy: 0.8929\n",
      "Epoch 127/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3001 - accuracy: 0.9028 - val_loss: 0.3121 - val_accuracy: 0.8929\n",
      "Epoch 128/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2997 - accuracy: 0.9028 - val_loss: 0.3117 - val_accuracy: 0.8929\n",
      "Epoch 129/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2993 - accuracy: 0.9028 - val_loss: 0.3113 - val_accuracy: 0.8929\n",
      "Epoch 130/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2989 - accuracy: 0.9028 - val_loss: 0.3109 - val_accuracy: 0.8929\n",
      "Epoch 131/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2985 - accuracy: 0.9028 - val_loss: 0.3105 - val_accuracy: 0.8929\n",
      "Epoch 132/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2981 - accuracy: 0.9028 - val_loss: 0.3101 - val_accuracy: 0.8929\n",
      "Epoch 133/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2977 - accuracy: 0.9028 - val_loss: 0.3097 - val_accuracy: 0.8929\n",
      "Epoch 134/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2973 - accuracy: 0.9028 - val_loss: 0.3093 - val_accuracy: 0.8929\n",
      "Epoch 135/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2969 - accuracy: 0.9028 - val_loss: 0.3089 - val_accuracy: 0.8929\n",
      "Epoch 136/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2965 - accuracy: 0.9028 - val_loss: 0.3085 - val_accuracy: 0.8929\n",
      "Epoch 137/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2961 - accuracy: 0.9028 - val_loss: 0.3081 - val_accuracy: 0.8929\n",
      "Epoch 138/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2958 - accuracy: 0.9028 - val_loss: 0.3077 - val_accuracy: 0.8929\n",
      "Epoch 139/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2954 - accuracy: 0.9028 - val_loss: 0.3073 - val_accuracy: 0.8929\n",
      "Epoch 140/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2950 - accuracy: 0.9028 - val_loss: 0.3069 - val_accuracy: 0.8929\n",
      "Epoch 141/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2946 - accuracy: 0.9028 - val_loss: 0.3066 - val_accuracy: 0.8929\n",
      "Epoch 142/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2943 - accuracy: 0.9028 - val_loss: 0.3062 - val_accuracy: 0.8929\n",
      "Epoch 143/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2939 - accuracy: 0.9028 - val_loss: 0.3058 - val_accuracy: 0.8929\n",
      "Epoch 144/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2935 - accuracy: 0.9028 - val_loss: 0.3054 - val_accuracy: 0.8929\n",
      "Epoch 145/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2932 - accuracy: 0.9028 - val_loss: 0.3051 - val_accuracy: 0.8929\n",
      "Epoch 146/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2928 - accuracy: 0.9028 - val_loss: 0.3047 - val_accuracy: 0.8929\n",
      "Epoch 147/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2925 - accuracy: 0.9028 - val_loss: 0.3044 - val_accuracy: 0.8929\n",
      "Epoch 148/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2921 - accuracy: 0.9028 - val_loss: 0.3040 - val_accuracy: 0.8929\n",
      "Epoch 149/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2918 - accuracy: 0.9028 - val_loss: 0.3037 - val_accuracy: 0.8929\n",
      "Epoch 150/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2914 - accuracy: 0.9028 - val_loss: 0.3033 - val_accuracy: 0.8929\n",
      "Epoch 151/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2911 - accuracy: 0.9028 - val_loss: 0.3030 - val_accuracy: 0.8929\n",
      "Epoch 152/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2907 - accuracy: 0.9028 - val_loss: 0.3026 - val_accuracy: 0.8929\n",
      "Epoch 153/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2904 - accuracy: 0.9028 - val_loss: 0.3023 - val_accuracy: 0.8929\n",
      "Epoch 154/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2901 - accuracy: 0.9028 - val_loss: 0.3019 - val_accuracy: 0.8929\n",
      "Epoch 155/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2897 - accuracy: 0.9028 - val_loss: 0.3016 - val_accuracy: 0.8929\n",
      "Epoch 156/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2894 - accuracy: 0.9028 - val_loss: 0.3013 - val_accuracy: 0.8929\n",
      "Epoch 157/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2891 - accuracy: 0.9028 - val_loss: 0.3009 - val_accuracy: 0.8929\n",
      "Epoch 158/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2888 - accuracy: 0.9028 - val_loss: 0.3006 - val_accuracy: 0.8929\n",
      "Epoch 159/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2884 - accuracy: 0.9028 - val_loss: 0.3003 - val_accuracy: 0.8929\n",
      "Epoch 160/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2881 - accuracy: 0.9028 - val_loss: 0.3000 - val_accuracy: 0.8929\n",
      "Epoch 161/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2878 - accuracy: 0.9028 - val_loss: 0.2996 - val_accuracy: 0.8929\n",
      "Epoch 162/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2875 - accuracy: 0.9028 - val_loss: 0.2993 - val_accuracy: 0.8929\n",
      "Epoch 163/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2872 - accuracy: 0.9028 - val_loss: 0.2990 - val_accuracy: 0.8929\n",
      "Epoch 164/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2869 - accuracy: 0.9028 - val_loss: 0.2987 - val_accuracy: 0.8929\n",
      "Epoch 165/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2865 - accuracy: 0.9028 - val_loss: 0.2984 - val_accuracy: 0.8929\n",
      "Epoch 166/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2862 - accuracy: 0.9028 - val_loss: 0.2981 - val_accuracy: 0.8929\n",
      "Epoch 167/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2859 - accuracy: 0.9028 - val_loss: 0.2977 - val_accuracy: 0.8929\n",
      "Epoch 168/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2856 - accuracy: 0.9028 - val_loss: 0.2974 - val_accuracy: 0.8929\n",
      "Epoch 169/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2853 - accuracy: 0.9028 - val_loss: 0.2971 - val_accuracy: 0.8929\n",
      "Epoch 170/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2850 - accuracy: 0.9033 - val_loss: 0.2968 - val_accuracy: 0.8929\n",
      "Epoch 171/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2847 - accuracy: 0.9033 - val_loss: 0.2965 - val_accuracy: 0.8929\n",
      "Epoch 172/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2844 - accuracy: 0.9033 - val_loss: 0.2962 - val_accuracy: 0.8929\n",
      "Epoch 173/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2842 - accuracy: 0.9033 - val_loss: 0.2959 - val_accuracy: 0.8929\n",
      "Epoch 174/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2839 - accuracy: 0.9033 - val_loss: 0.2957 - val_accuracy: 0.8929\n",
      "Epoch 175/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2836 - accuracy: 0.9033 - val_loss: 0.2954 - val_accuracy: 0.8929\n",
      "Epoch 176/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2833 - accuracy: 0.9033 - val_loss: 0.2951 - val_accuracy: 0.8929\n",
      "Epoch 177/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2830 - accuracy: 0.9033 - val_loss: 0.2948 - val_accuracy: 0.8929\n",
      "Epoch 178/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2827 - accuracy: 0.9033 - val_loss: 0.2945 - val_accuracy: 0.8929\n",
      "Epoch 179/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2824 - accuracy: 0.9033 - val_loss: 0.2942 - val_accuracy: 0.8929\n",
      "Epoch 180/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2822 - accuracy: 0.9033 - val_loss: 0.2939 - val_accuracy: 0.8929\n",
      "Epoch 181/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2819 - accuracy: 0.9033 - val_loss: 0.2937 - val_accuracy: 0.8929\n",
      "Epoch 182/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2816 - accuracy: 0.9033 - val_loss: 0.2934 - val_accuracy: 0.8929\n",
      "Epoch 183/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2813 - accuracy: 0.9033 - val_loss: 0.2931 - val_accuracy: 0.8929\n",
      "Epoch 184/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2811 - accuracy: 0.9033 - val_loss: 0.2928 - val_accuracy: 0.8929\n",
      "Epoch 185/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2808 - accuracy: 0.9033 - val_loss: 0.2926 - val_accuracy: 0.8929\n",
      "Epoch 186/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2805 - accuracy: 0.9033 - val_loss: 0.2923 - val_accuracy: 0.8929\n",
      "Epoch 187/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2803 - accuracy: 0.9033 - val_loss: 0.2920 - val_accuracy: 0.8929\n",
      "Epoch 188/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2800 - accuracy: 0.9033 - val_loss: 0.2918 - val_accuracy: 0.8929\n",
      "Epoch 189/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2797 - accuracy: 0.9033 - val_loss: 0.2915 - val_accuracy: 0.8929\n",
      "Epoch 190/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2795 - accuracy: 0.9033 - val_loss: 0.2912 - val_accuracy: 0.8929\n",
      "Epoch 191/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2792 - accuracy: 0.9033 - val_loss: 0.2910 - val_accuracy: 0.8929\n",
      "Epoch 192/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2790 - accuracy: 0.9033 - val_loss: 0.2907 - val_accuracy: 0.8929\n",
      "Epoch 193/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2787 - accuracy: 0.9033 - val_loss: 0.2904 - val_accuracy: 0.8929\n",
      "Epoch 194/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2784 - accuracy: 0.9033 - val_loss: 0.2902 - val_accuracy: 0.8929\n",
      "Epoch 195/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2782 - accuracy: 0.9033 - val_loss: 0.2899 - val_accuracy: 0.8929\n",
      "Epoch 196/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2779 - accuracy: 0.9033 - val_loss: 0.2897 - val_accuracy: 0.8929\n",
      "Epoch 197/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2777 - accuracy: 0.9033 - val_loss: 0.2894 - val_accuracy: 0.8929\n",
      "Epoch 198/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2774 - accuracy: 0.9033 - val_loss: 0.2892 - val_accuracy: 0.8929\n",
      "Epoch 199/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2772 - accuracy: 0.9033 - val_loss: 0.2889 - val_accuracy: 0.8929\n",
      "Epoch 200/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2770 - accuracy: 0.9033 - val_loss: 0.2887 - val_accuracy: 0.8929\n",
      "Epoch 201/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2767 - accuracy: 0.9033 - val_loss: 0.2884 - val_accuracy: 0.8929\n",
      "Epoch 202/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2765 - accuracy: 0.9033 - val_loss: 0.2882 - val_accuracy: 0.8929\n",
      "Epoch 203/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2762 - accuracy: 0.9033 - val_loss: 0.2879 - val_accuracy: 0.8929\n",
      "Epoch 204/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2760 - accuracy: 0.9033 - val_loss: 0.2877 - val_accuracy: 0.8929\n",
      "Epoch 205/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2758 - accuracy: 0.9033 - val_loss: 0.2875 - val_accuracy: 0.8929\n",
      "Epoch 206/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2755 - accuracy: 0.9033 - val_loss: 0.2872 - val_accuracy: 0.8929\n",
      "Epoch 207/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2753 - accuracy: 0.9033 - val_loss: 0.2870 - val_accuracy: 0.8929\n",
      "Epoch 208/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2751 - accuracy: 0.9033 - val_loss: 0.2868 - val_accuracy: 0.8929\n",
      "Epoch 209/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2748 - accuracy: 0.9033 - val_loss: 0.2865 - val_accuracy: 0.8929\n",
      "Epoch 210/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2746 - accuracy: 0.9033 - val_loss: 0.2863 - val_accuracy: 0.8929\n",
      "Epoch 211/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2744 - accuracy: 0.9033 - val_loss: 0.2861 - val_accuracy: 0.8929\n",
      "Epoch 212/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2742 - accuracy: 0.9033 - val_loss: 0.2858 - val_accuracy: 0.8929\n",
      "Epoch 213/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2739 - accuracy: 0.9033 - val_loss: 0.2856 - val_accuracy: 0.8929\n",
      "Epoch 214/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2737 - accuracy: 0.9038 - val_loss: 0.2854 - val_accuracy: 0.8948\n",
      "Epoch 215/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2735 - accuracy: 0.9038 - val_loss: 0.2852 - val_accuracy: 0.8948\n",
      "Epoch 216/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2733 - accuracy: 0.9038 - val_loss: 0.2849 - val_accuracy: 0.8948\n",
      "Epoch 217/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2730 - accuracy: 0.9038 - val_loss: 0.2847 - val_accuracy: 0.8948\n",
      "Epoch 218/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2728 - accuracy: 0.9038 - val_loss: 0.2845 - val_accuracy: 0.8948\n",
      "Epoch 219/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2726 - accuracy: 0.9038 - val_loss: 0.2843 - val_accuracy: 0.8948\n",
      "Epoch 220/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2724 - accuracy: 0.9038 - val_loss: 0.2840 - val_accuracy: 0.8948\n",
      "Epoch 221/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2722 - accuracy: 0.9038 - val_loss: 0.2838 - val_accuracy: 0.8948\n",
      "Epoch 222/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2720 - accuracy: 0.9038 - val_loss: 0.2836 - val_accuracy: 0.8948\n",
      "Epoch 223/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2718 - accuracy: 0.9038 - val_loss: 0.2834 - val_accuracy: 0.8948\n",
      "Epoch 224/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2715 - accuracy: 0.9038 - val_loss: 0.2832 - val_accuracy: 0.8948\n",
      "Epoch 225/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2713 - accuracy: 0.9038 - val_loss: 0.2830 - val_accuracy: 0.8948\n",
      "Epoch 226/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2711 - accuracy: 0.9038 - val_loss: 0.2828 - val_accuracy: 0.8948\n",
      "Epoch 227/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2709 - accuracy: 0.9038 - val_loss: 0.2826 - val_accuracy: 0.8948\n",
      "Epoch 228/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2707 - accuracy: 0.9038 - val_loss: 0.2823 - val_accuracy: 0.8948\n",
      "Epoch 229/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2705 - accuracy: 0.9038 - val_loss: 0.2821 - val_accuracy: 0.8948\n",
      "Epoch 230/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2703 - accuracy: 0.9038 - val_loss: 0.2819 - val_accuracy: 0.8948\n",
      "Epoch 231/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2701 - accuracy: 0.9038 - val_loss: 0.2817 - val_accuracy: 0.8948\n",
      "Epoch 232/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2699 - accuracy: 0.9038 - val_loss: 0.2815 - val_accuracy: 0.8948\n",
      "Epoch 233/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2697 - accuracy: 0.9038 - val_loss: 0.2813 - val_accuracy: 0.8948\n",
      "Epoch 234/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2695 - accuracy: 0.9038 - val_loss: 0.2811 - val_accuracy: 0.8948\n",
      "Epoch 235/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2693 - accuracy: 0.9038 - val_loss: 0.2809 - val_accuracy: 0.8948\n",
      "Epoch 236/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2691 - accuracy: 0.9038 - val_loss: 0.2807 - val_accuracy: 0.8948\n",
      "Epoch 237/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2689 - accuracy: 0.9038 - val_loss: 0.2805 - val_accuracy: 0.8948\n",
      "Epoch 238/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2687 - accuracy: 0.9038 - val_loss: 0.2803 - val_accuracy: 0.8948\n",
      "Epoch 239/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2685 - accuracy: 0.9038 - val_loss: 0.2801 - val_accuracy: 0.8948\n",
      "Epoch 240/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2684 - accuracy: 0.9038 - val_loss: 0.2799 - val_accuracy: 0.8948\n",
      "Epoch 241/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2682 - accuracy: 0.9038 - val_loss: 0.2797 - val_accuracy: 0.8948\n",
      "Epoch 242/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2680 - accuracy: 0.9038 - val_loss: 0.2795 - val_accuracy: 0.8948\n",
      "Epoch 243/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2678 - accuracy: 0.9038 - val_loss: 0.2793 - val_accuracy: 0.8948\n",
      "Epoch 244/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2676 - accuracy: 0.9038 - val_loss: 0.2791 - val_accuracy: 0.8948\n",
      "Epoch 245/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2674 - accuracy: 0.9038 - val_loss: 0.2789 - val_accuracy: 0.8948\n",
      "Epoch 246/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2672 - accuracy: 0.9038 - val_loss: 0.2787 - val_accuracy: 0.8948\n",
      "Epoch 247/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2671 - accuracy: 0.9038 - val_loss: 0.2785 - val_accuracy: 0.8948\n",
      "Epoch 248/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2669 - accuracy: 0.9038 - val_loss: 0.2784 - val_accuracy: 0.8948\n",
      "Epoch 249/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2667 - accuracy: 0.9038 - val_loss: 0.2782 - val_accuracy: 0.8948\n",
      "Epoch 250/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2665 - accuracy: 0.9038 - val_loss: 0.2780 - val_accuracy: 0.8948\n",
      "20/20 [==============================] - 0s 840us/step\n",
      "Epoch 1/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2654 - accuracy: 0.9038 - val_loss: 0.2760 - val_accuracy: 0.8948\n",
      "Epoch 2/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2637 - accuracy: 0.9038 - val_loss: 0.2746 - val_accuracy: 0.8948\n",
      "Epoch 3/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2625 - accuracy: 0.9038 - val_loss: 0.2734 - val_accuracy: 0.8948\n",
      "Epoch 4/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2614 - accuracy: 0.9038 - val_loss: 0.2724 - val_accuracy: 0.8948\n",
      "Epoch 5/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2604 - accuracy: 0.9038 - val_loss: 0.2714 - val_accuracy: 0.8948\n",
      "Epoch 6/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2596 - accuracy: 0.9038 - val_loss: 0.2706 - val_accuracy: 0.8948\n",
      "Epoch 7/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2588 - accuracy: 0.9038 - val_loss: 0.2698 - val_accuracy: 0.8948\n",
      "Epoch 8/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2581 - accuracy: 0.9038 - val_loss: 0.2691 - val_accuracy: 0.8948\n",
      "Epoch 9/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2574 - accuracy: 0.9038 - val_loss: 0.2684 - val_accuracy: 0.8948\n",
      "Epoch 10/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2568 - accuracy: 0.9038 - val_loss: 0.2678 - val_accuracy: 0.8948\n",
      "Epoch 11/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2562 - accuracy: 0.9038 - val_loss: 0.2672 - val_accuracy: 0.8948\n",
      "Epoch 12/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2557 - accuracy: 0.9038 - val_loss: 0.2666 - val_accuracy: 0.8948\n",
      "Epoch 13/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2552 - accuracy: 0.9038 - val_loss: 0.2661 - val_accuracy: 0.8948\n",
      "Epoch 14/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2547 - accuracy: 0.9038 - val_loss: 0.2656 - val_accuracy: 0.8948\n",
      "Epoch 15/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2542 - accuracy: 0.9038 - val_loss: 0.2651 - val_accuracy: 0.8948\n",
      "Epoch 16/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2537 - accuracy: 0.9038 - val_loss: 0.2646 - val_accuracy: 0.8948\n",
      "Epoch 17/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2533 - accuracy: 0.9038 - val_loss: 0.2641 - val_accuracy: 0.8948\n",
      "Epoch 18/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2529 - accuracy: 0.9038 - val_loss: 0.2637 - val_accuracy: 0.8948\n",
      "Epoch 19/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2525 - accuracy: 0.9038 - val_loss: 0.2633 - val_accuracy: 0.8948\n",
      "Epoch 20/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2521 - accuracy: 0.9038 - val_loss: 0.2629 - val_accuracy: 0.8948\n",
      "Epoch 21/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2517 - accuracy: 0.9038 - val_loss: 0.2625 - val_accuracy: 0.8948\n",
      "Epoch 22/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2513 - accuracy: 0.9038 - val_loss: 0.2621 - val_accuracy: 0.8948\n",
      "Epoch 23/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2510 - accuracy: 0.9038 - val_loss: 0.2617 - val_accuracy: 0.8948\n",
      "Epoch 24/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2507 - accuracy: 0.9038 - val_loss: 0.2614 - val_accuracy: 0.8948\n",
      "Epoch 25/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2503 - accuracy: 0.9038 - val_loss: 0.2610 - val_accuracy: 0.8948\n",
      "Epoch 26/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2500 - accuracy: 0.9038 - val_loss: 0.2607 - val_accuracy: 0.8948\n",
      "Epoch 27/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2497 - accuracy: 0.9038 - val_loss: 0.2604 - val_accuracy: 0.8948\n",
      "Epoch 28/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2494 - accuracy: 0.9038 - val_loss: 0.2600 - val_accuracy: 0.8948\n",
      "Epoch 29/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2491 - accuracy: 0.9038 - val_loss: 0.2597 - val_accuracy: 0.8948\n",
      "Epoch 30/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2488 - accuracy: 0.9038 - val_loss: 0.2594 - val_accuracy: 0.8948\n",
      "Epoch 31/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2485 - accuracy: 0.9038 - val_loss: 0.2591 - val_accuracy: 0.8948\n",
      "Epoch 32/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2483 - accuracy: 0.9038 - val_loss: 0.2589 - val_accuracy: 0.8948\n",
      "Epoch 33/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2480 - accuracy: 0.9038 - val_loss: 0.2586 - val_accuracy: 0.8948\n",
      "Epoch 34/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2477 - accuracy: 0.9038 - val_loss: 0.2583 - val_accuracy: 0.8948\n",
      "Epoch 35/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2475 - accuracy: 0.9038 - val_loss: 0.2580 - val_accuracy: 0.8948\n",
      "Epoch 36/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2472 - accuracy: 0.9038 - val_loss: 0.2578 - val_accuracy: 0.8948\n",
      "Epoch 37/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2470 - accuracy: 0.9038 - val_loss: 0.2575 - val_accuracy: 0.8948\n",
      "Epoch 38/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2467 - accuracy: 0.9038 - val_loss: 0.2573 - val_accuracy: 0.8948\n",
      "Epoch 39/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2465 - accuracy: 0.9038 - val_loss: 0.2570 - val_accuracy: 0.8948\n",
      "Epoch 40/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2463 - accuracy: 0.9038 - val_loss: 0.2568 - val_accuracy: 0.8948\n",
      "Epoch 41/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2461 - accuracy: 0.9038 - val_loss: 0.2566 - val_accuracy: 0.8948\n",
      "Epoch 42/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2458 - accuracy: 0.9038 - val_loss: 0.2563 - val_accuracy: 0.8948\n",
      "Epoch 43/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2456 - accuracy: 0.9038 - val_loss: 0.2561 - val_accuracy: 0.8948\n",
      "Epoch 44/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2454 - accuracy: 0.9038 - val_loss: 0.2559 - val_accuracy: 0.8948\n",
      "Epoch 45/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2452 - accuracy: 0.9038 - val_loss: 0.2557 - val_accuracy: 0.8948\n",
      "Epoch 46/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2450 - accuracy: 0.9038 - val_loss: 0.2555 - val_accuracy: 0.8948\n",
      "Epoch 47/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2448 - accuracy: 0.9038 - val_loss: 0.2553 - val_accuracy: 0.8948\n",
      "Epoch 48/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2446 - accuracy: 0.9038 - val_loss: 0.2551 - val_accuracy: 0.8948\n",
      "Epoch 49/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2444 - accuracy: 0.9038 - val_loss: 0.2549 - val_accuracy: 0.8948\n",
      "Epoch 50/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2443 - accuracy: 0.9038 - val_loss: 0.2547 - val_accuracy: 0.8948\n",
      "Epoch 51/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2441 - accuracy: 0.9038 - val_loss: 0.2545 - val_accuracy: 0.8948\n",
      "Epoch 52/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2439 - accuracy: 0.9038 - val_loss: 0.2543 - val_accuracy: 0.8948\n",
      "Epoch 53/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2437 - accuracy: 0.9038 - val_loss: 0.2541 - val_accuracy: 0.8948\n",
      "Epoch 54/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2435 - accuracy: 0.9038 - val_loss: 0.2539 - val_accuracy: 0.8948\n",
      "Epoch 55/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2434 - accuracy: 0.9038 - val_loss: 0.2537 - val_accuracy: 0.8948\n",
      "Epoch 56/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2432 - accuracy: 0.9038 - val_loss: 0.2535 - val_accuracy: 0.8948\n",
      "Epoch 57/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2430 - accuracy: 0.9038 - val_loss: 0.2534 - val_accuracy: 0.8948\n",
      "Epoch 58/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2429 - accuracy: 0.9038 - val_loss: 0.2532 - val_accuracy: 0.8948\n",
      "Epoch 59/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2427 - accuracy: 0.9038 - val_loss: 0.2530 - val_accuracy: 0.8948\n",
      "Epoch 60/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2425 - accuracy: 0.9038 - val_loss: 0.2529 - val_accuracy: 0.8948\n",
      "Epoch 61/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2424 - accuracy: 0.9038 - val_loss: 0.2527 - val_accuracy: 0.8948\n",
      "Epoch 62/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2422 - accuracy: 0.9038 - val_loss: 0.2525 - val_accuracy: 0.8948\n",
      "Epoch 63/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2421 - accuracy: 0.9038 - val_loss: 0.2524 - val_accuracy: 0.8948\n",
      "Epoch 64/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2419 - accuracy: 0.9038 - val_loss: 0.2522 - val_accuracy: 0.8948\n",
      "Epoch 65/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2418 - accuracy: 0.9038 - val_loss: 0.2521 - val_accuracy: 0.8948\n",
      "Epoch 66/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2416 - accuracy: 0.9038 - val_loss: 0.2519 - val_accuracy: 0.8948\n",
      "Epoch 67/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2415 - accuracy: 0.9038 - val_loss: 0.2518 - val_accuracy: 0.8948\n",
      "Epoch 68/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2414 - accuracy: 0.9038 - val_loss: 0.2516 - val_accuracy: 0.8948\n",
      "Epoch 69/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2412 - accuracy: 0.9038 - val_loss: 0.2515 - val_accuracy: 0.8948\n",
      "Epoch 70/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2411 - accuracy: 0.9038 - val_loss: 0.2513 - val_accuracy: 0.8948\n",
      "Epoch 71/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2409 - accuracy: 0.9038 - val_loss: 0.2512 - val_accuracy: 0.8948\n",
      "Epoch 72/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2408 - accuracy: 0.9038 - val_loss: 0.2511 - val_accuracy: 0.8948\n",
      "Epoch 73/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2407 - accuracy: 0.9038 - val_loss: 0.2509 - val_accuracy: 0.8948\n",
      "Epoch 74/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2405 - accuracy: 0.9038 - val_loss: 0.2508 - val_accuracy: 0.8948\n",
      "Epoch 75/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2404 - accuracy: 0.9038 - val_loss: 0.2507 - val_accuracy: 0.8948\n",
      "Epoch 76/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2403 - accuracy: 0.9038 - val_loss: 0.2505 - val_accuracy: 0.8948\n",
      "Epoch 77/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2402 - accuracy: 0.9038 - val_loss: 0.2504 - val_accuracy: 0.8948\n",
      "Epoch 78/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2400 - accuracy: 0.9038 - val_loss: 0.2503 - val_accuracy: 0.8948\n",
      "Epoch 79/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2399 - accuracy: 0.9038 - val_loss: 0.2501 - val_accuracy: 0.8948\n",
      "Epoch 80/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2398 - accuracy: 0.9038 - val_loss: 0.2500 - val_accuracy: 0.8948\n",
      "Epoch 81/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2397 - accuracy: 0.9038 - val_loss: 0.2499 - val_accuracy: 0.8948\n",
      "Epoch 82/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2396 - accuracy: 0.9038 - val_loss: 0.2498 - val_accuracy: 0.8948\n",
      "Epoch 83/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2394 - accuracy: 0.9038 - val_loss: 0.2496 - val_accuracy: 0.8948\n",
      "Epoch 84/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2393 - accuracy: 0.9038 - val_loss: 0.2495 - val_accuracy: 0.8948\n",
      "Epoch 85/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2392 - accuracy: 0.9038 - val_loss: 0.2494 - val_accuracy: 0.8948\n",
      "Epoch 86/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2391 - accuracy: 0.9038 - val_loss: 0.2493 - val_accuracy: 0.8948\n",
      "Epoch 87/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2390 - accuracy: 0.9038 - val_loss: 0.2491 - val_accuracy: 0.8948\n",
      "Epoch 88/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2389 - accuracy: 0.9038 - val_loss: 0.2490 - val_accuracy: 0.8948\n",
      "Epoch 89/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2387 - accuracy: 0.9038 - val_loss: 0.2489 - val_accuracy: 0.8948\n",
      "Epoch 90/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2386 - accuracy: 0.9038 - val_loss: 0.2488 - val_accuracy: 0.8948\n",
      "Epoch 91/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2385 - accuracy: 0.9038 - val_loss: 0.2487 - val_accuracy: 0.8948\n",
      "Epoch 92/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2384 - accuracy: 0.9038 - val_loss: 0.2486 - val_accuracy: 0.8948\n",
      "Epoch 93/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2383 - accuracy: 0.9038 - val_loss: 0.2485 - val_accuracy: 0.8948\n",
      "Epoch 94/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2382 - accuracy: 0.9038 - val_loss: 0.2483 - val_accuracy: 0.8948\n",
      "Epoch 95/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2381 - accuracy: 0.9038 - val_loss: 0.2482 - val_accuracy: 0.8948\n",
      "Epoch 96/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2380 - accuracy: 0.9038 - val_loss: 0.2481 - val_accuracy: 0.8948\n",
      "Epoch 97/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2379 - accuracy: 0.9038 - val_loss: 0.2480 - val_accuracy: 0.8948\n",
      "Epoch 98/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2378 - accuracy: 0.9038 - val_loss: 0.2479 - val_accuracy: 0.8948\n",
      "Epoch 99/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2377 - accuracy: 0.9038 - val_loss: 0.2478 - val_accuracy: 0.8948\n",
      "Epoch 100/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2376 - accuracy: 0.9038 - val_loss: 0.2477 - val_accuracy: 0.8948\n",
      "Epoch 101/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2375 - accuracy: 0.9038 - val_loss: 0.2476 - val_accuracy: 0.8948\n",
      "Epoch 102/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2374 - accuracy: 0.9038 - val_loss: 0.2475 - val_accuracy: 0.8948\n",
      "Epoch 103/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2373 - accuracy: 0.9038 - val_loss: 0.2474 - val_accuracy: 0.8948\n",
      "Epoch 104/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2372 - accuracy: 0.9038 - val_loss: 0.2473 - val_accuracy: 0.8948\n",
      "Epoch 105/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2371 - accuracy: 0.9038 - val_loss: 0.2472 - val_accuracy: 0.8948\n",
      "Epoch 106/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2370 - accuracy: 0.9038 - val_loss: 0.2471 - val_accuracy: 0.8948\n",
      "Epoch 107/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2369 - accuracy: 0.9038 - val_loss: 0.2470 - val_accuracy: 0.8948\n",
      "Epoch 108/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2368 - accuracy: 0.9038 - val_loss: 0.2469 - val_accuracy: 0.8948\n",
      "Epoch 109/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2367 - accuracy: 0.9038 - val_loss: 0.2468 - val_accuracy: 0.8948\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 110/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2366 - accuracy: 0.9038 - val_loss: 0.2467 - val_accuracy: 0.8948\n",
      "Epoch 111/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2365 - accuracy: 0.9038 - val_loss: 0.2466 - val_accuracy: 0.8948\n",
      "Epoch 112/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2364 - accuracy: 0.9038 - val_loss: 0.2465 - val_accuracy: 0.8948\n",
      "Epoch 113/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2363 - accuracy: 0.9038 - val_loss: 0.2464 - val_accuracy: 0.8948\n",
      "Epoch 114/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2362 - accuracy: 0.9038 - val_loss: 0.2463 - val_accuracy: 0.8948\n",
      "Epoch 115/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2361 - accuracy: 0.9038 - val_loss: 0.2462 - val_accuracy: 0.8948\n",
      "Epoch 116/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2361 - accuracy: 0.9038 - val_loss: 0.2461 - val_accuracy: 0.8948\n",
      "Epoch 117/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2360 - accuracy: 0.9038 - val_loss: 0.2460 - val_accuracy: 0.8948\n",
      "Epoch 118/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2359 - accuracy: 0.9038 - val_loss: 0.2459 - val_accuracy: 0.8948\n",
      "Epoch 119/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2358 - accuracy: 0.9038 - val_loss: 0.2458 - val_accuracy: 0.8948\n",
      "Epoch 120/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2357 - accuracy: 0.9038 - val_loss: 0.2457 - val_accuracy: 0.8948\n",
      "Epoch 121/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2356 - accuracy: 0.9038 - val_loss: 0.2456 - val_accuracy: 0.8948\n",
      "Epoch 122/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2355 - accuracy: 0.9038 - val_loss: 0.2455 - val_accuracy: 0.8948\n",
      "Epoch 123/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2355 - accuracy: 0.9038 - val_loss: 0.2454 - val_accuracy: 0.8948\n",
      "Epoch 124/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2354 - accuracy: 0.9038 - val_loss: 0.2453 - val_accuracy: 0.8948\n",
      "Epoch 125/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2353 - accuracy: 0.9038 - val_loss: 0.2453 - val_accuracy: 0.8948\n",
      "Epoch 126/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2352 - accuracy: 0.9038 - val_loss: 0.2452 - val_accuracy: 0.8948\n",
      "Epoch 127/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2351 - accuracy: 0.9038 - val_loss: 0.2451 - val_accuracy: 0.8948\n",
      "Epoch 128/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2350 - accuracy: 0.9038 - val_loss: 0.2450 - val_accuracy: 0.8948\n",
      "Epoch 129/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2350 - accuracy: 0.9038 - val_loss: 0.2449 - val_accuracy: 0.8948\n",
      "Epoch 130/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2349 - accuracy: 0.9038 - val_loss: 0.2448 - val_accuracy: 0.8948\n",
      "Epoch 131/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2348 - accuracy: 0.9038 - val_loss: 0.2448 - val_accuracy: 0.8948\n",
      "Epoch 132/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2347 - accuracy: 0.9038 - val_loss: 0.2447 - val_accuracy: 0.8948\n",
      "Epoch 133/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2346 - accuracy: 0.9038 - val_loss: 0.2446 - val_accuracy: 0.8948\n",
      "Epoch 134/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2346 - accuracy: 0.9038 - val_loss: 0.2445 - val_accuracy: 0.8948\n",
      "Epoch 135/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2345 - accuracy: 0.9038 - val_loss: 0.2445 - val_accuracy: 0.8948\n",
      "Epoch 136/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2344 - accuracy: 0.9038 - val_loss: 0.2444 - val_accuracy: 0.8948\n",
      "Epoch 137/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2343 - accuracy: 0.9038 - val_loss: 0.2443 - val_accuracy: 0.8948\n",
      "Epoch 138/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2343 - accuracy: 0.9038 - val_loss: 0.2442 - val_accuracy: 0.8948\n",
      "Epoch 139/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2342 - accuracy: 0.9038 - val_loss: 0.2442 - val_accuracy: 0.8948\n",
      "Epoch 140/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2341 - accuracy: 0.9038 - val_loss: 0.2441 - val_accuracy: 0.8948\n",
      "Epoch 141/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2341 - accuracy: 0.9038 - val_loss: 0.2440 - val_accuracy: 0.8948\n",
      "Epoch 142/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2340 - accuracy: 0.9038 - val_loss: 0.2439 - val_accuracy: 0.8948\n",
      "Epoch 143/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2339 - accuracy: 0.9038 - val_loss: 0.2439 - val_accuracy: 0.8948\n",
      "Epoch 144/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2339 - accuracy: 0.9038 - val_loss: 0.2438 - val_accuracy: 0.8948\n",
      "Epoch 145/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2338 - accuracy: 0.9038 - val_loss: 0.2437 - val_accuracy: 0.8948\n",
      "Epoch 146/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2337 - accuracy: 0.9038 - val_loss: 0.2437 - val_accuracy: 0.8948\n",
      "Epoch 147/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2337 - accuracy: 0.9038 - val_loss: 0.2436 - val_accuracy: 0.8948\n",
      "Epoch 148/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2336 - accuracy: 0.9038 - val_loss: 0.2435 - val_accuracy: 0.8948\n",
      "Epoch 149/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2335 - accuracy: 0.9038 - val_loss: 0.2435 - val_accuracy: 0.8948\n",
      "Epoch 150/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2335 - accuracy: 0.9038 - val_loss: 0.2434 - val_accuracy: 0.8948\n",
      "Epoch 151/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2334 - accuracy: 0.9038 - val_loss: 0.2433 - val_accuracy: 0.8948\n",
      "Epoch 152/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2333 - accuracy: 0.9038 - val_loss: 0.2433 - val_accuracy: 0.8948\n",
      "Epoch 153/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2333 - accuracy: 0.9038 - val_loss: 0.2432 - val_accuracy: 0.8948\n",
      "Epoch 154/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2332 - accuracy: 0.9038 - val_loss: 0.2432 - val_accuracy: 0.8948\n",
      "Epoch 155/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2331 - accuracy: 0.9038 - val_loss: 0.2431 - val_accuracy: 0.8948\n",
      "Epoch 156/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2331 - accuracy: 0.9038 - val_loss: 0.2430 - val_accuracy: 0.8948\n",
      "Epoch 157/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2330 - accuracy: 0.9038 - val_loss: 0.2430 - val_accuracy: 0.8948\n",
      "Epoch 158/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2329 - accuracy: 0.9038 - val_loss: 0.2429 - val_accuracy: 0.8948\n",
      "Epoch 159/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2329 - accuracy: 0.9043 - val_loss: 0.2428 - val_accuracy: 0.8948\n",
      "Epoch 160/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2328 - accuracy: 0.9043 - val_loss: 0.2428 - val_accuracy: 0.8948\n",
      "Epoch 161/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2328 - accuracy: 0.9043 - val_loss: 0.2427 - val_accuracy: 0.8948\n",
      "Epoch 162/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2327 - accuracy: 0.9043 - val_loss: 0.2427 - val_accuracy: 0.8948\n",
      "Epoch 163/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2326 - accuracy: 0.9048 - val_loss: 0.2426 - val_accuracy: 0.8948\n",
      "Epoch 164/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2326 - accuracy: 0.9048 - val_loss: 0.2426 - val_accuracy: 0.8948\n",
      "Epoch 165/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2325 - accuracy: 0.9048 - val_loss: 0.2425 - val_accuracy: 0.8948\n",
      "Epoch 166/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2325 - accuracy: 0.9048 - val_loss: 0.2424 - val_accuracy: 0.8948\n",
      "Epoch 167/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2324 - accuracy: 0.9048 - val_loss: 0.2424 - val_accuracy: 0.8948\n",
      "Epoch 168/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2323 - accuracy: 0.9048 - val_loss: 0.2423 - val_accuracy: 0.8948\n",
      "Epoch 169/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2323 - accuracy: 0.9048 - val_loss: 0.2423 - val_accuracy: 0.8968\n",
      "Epoch 170/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2322 - accuracy: 0.9048 - val_loss: 0.2422 - val_accuracy: 0.8968\n",
      "Epoch 171/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2322 - accuracy: 0.9048 - val_loss: 0.2422 - val_accuracy: 0.8968\n",
      "Epoch 172/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2321 - accuracy: 0.9048 - val_loss: 0.2421 - val_accuracy: 0.8968\n",
      "Epoch 173/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2321 - accuracy: 0.9048 - val_loss: 0.2421 - val_accuracy: 0.8968\n",
      "Epoch 174/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2320 - accuracy: 0.9048 - val_loss: 0.2420 - val_accuracy: 0.8968\n",
      "Epoch 175/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2319 - accuracy: 0.9048 - val_loss: 0.2419 - val_accuracy: 0.8968\n",
      "Epoch 176/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2319 - accuracy: 0.9048 - val_loss: 0.2419 - val_accuracy: 0.8968\n",
      "Epoch 177/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2318 - accuracy: 0.9048 - val_loss: 0.2418 - val_accuracy: 0.8968\n",
      "Epoch 178/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2318 - accuracy: 0.9048 - val_loss: 0.2418 - val_accuracy: 0.8968\n",
      "Epoch 179/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2317 - accuracy: 0.9048 - val_loss: 0.2417 - val_accuracy: 0.8968\n",
      "Epoch 180/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2317 - accuracy: 0.9048 - val_loss: 0.2417 - val_accuracy: 0.8968\n",
      "Epoch 181/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2316 - accuracy: 0.9048 - val_loss: 0.2416 - val_accuracy: 0.8968\n",
      "Epoch 182/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2316 - accuracy: 0.9048 - val_loss: 0.2416 - val_accuracy: 0.8968\n",
      "Epoch 183/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2315 - accuracy: 0.9048 - val_loss: 0.2415 - val_accuracy: 0.8968\n",
      "Epoch 184/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2315 - accuracy: 0.9048 - val_loss: 0.2415 - val_accuracy: 0.8968\n",
      "Epoch 185/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2314 - accuracy: 0.9048 - val_loss: 0.2414 - val_accuracy: 0.8968\n",
      "Epoch 186/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2313 - accuracy: 0.9048 - val_loss: 0.2414 - val_accuracy: 0.8968\n",
      "Epoch 187/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2313 - accuracy: 0.9048 - val_loss: 0.2413 - val_accuracy: 0.8968\n",
      "Epoch 188/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2312 - accuracy: 0.9048 - val_loss: 0.2413 - val_accuracy: 0.8968\n",
      "Epoch 189/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2312 - accuracy: 0.9048 - val_loss: 0.2412 - val_accuracy: 0.8968\n",
      "Epoch 190/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2311 - accuracy: 0.9048 - val_loss: 0.2412 - val_accuracy: 0.8968\n",
      "Epoch 191/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2311 - accuracy: 0.9048 - val_loss: 0.2411 - val_accuracy: 0.8968\n",
      "Epoch 192/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2310 - accuracy: 0.9048 - val_loss: 0.2411 - val_accuracy: 0.8968\n",
      "Epoch 193/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2310 - accuracy: 0.9048 - val_loss: 0.2410 - val_accuracy: 0.8968\n",
      "Epoch 194/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2309 - accuracy: 0.9048 - val_loss: 0.2410 - val_accuracy: 0.8968\n",
      "Epoch 195/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2309 - accuracy: 0.9048 - val_loss: 0.2409 - val_accuracy: 0.8968\n",
      "Epoch 196/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2308 - accuracy: 0.9048 - val_loss: 0.2409 - val_accuracy: 0.8968\n",
      "Epoch 197/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2308 - accuracy: 0.9048 - val_loss: 0.2408 - val_accuracy: 0.8968\n",
      "Epoch 198/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2307 - accuracy: 0.9048 - val_loss: 0.2408 - val_accuracy: 0.8968\n",
      "Epoch 199/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2307 - accuracy: 0.9048 - val_loss: 0.2407 - val_accuracy: 0.8968\n",
      "Epoch 200/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2306 - accuracy: 0.9048 - val_loss: 0.2407 - val_accuracy: 0.8968\n",
      "Epoch 201/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2306 - accuracy: 0.9048 - val_loss: 0.2406 - val_accuracy: 0.8968\n",
      "Epoch 202/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2305 - accuracy: 0.9048 - val_loss: 0.2406 - val_accuracy: 0.8968\n",
      "Epoch 203/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2305 - accuracy: 0.9048 - val_loss: 0.2406 - val_accuracy: 0.8968\n",
      "Epoch 204/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2304 - accuracy: 0.9048 - val_loss: 0.2405 - val_accuracy: 0.8968\n",
      "Epoch 205/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2304 - accuracy: 0.9048 - val_loss: 0.2405 - val_accuracy: 0.8968\n",
      "Epoch 206/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2304 - accuracy: 0.9048 - val_loss: 0.2404 - val_accuracy: 0.8968\n",
      "Epoch 207/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2303 - accuracy: 0.9048 - val_loss: 0.2404 - val_accuracy: 0.8968\n",
      "Epoch 208/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2303 - accuracy: 0.9048 - val_loss: 0.2403 - val_accuracy: 0.8968\n",
      "Epoch 209/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2302 - accuracy: 0.9048 - val_loss: 0.2403 - val_accuracy: 0.8968\n",
      "Epoch 210/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2302 - accuracy: 0.9048 - val_loss: 0.2402 - val_accuracy: 0.8968\n",
      "Epoch 211/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2301 - accuracy: 0.9048 - val_loss: 0.2402 - val_accuracy: 0.8968\n",
      "Epoch 212/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2301 - accuracy: 0.9048 - val_loss: 0.2402 - val_accuracy: 0.8968\n",
      "Epoch 213/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2300 - accuracy: 0.9048 - val_loss: 0.2401 - val_accuracy: 0.8968\n",
      "Epoch 214/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2300 - accuracy: 0.9048 - val_loss: 0.2401 - val_accuracy: 0.8968\n",
      "Epoch 215/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2299 - accuracy: 0.9048 - val_loss: 0.2400 - val_accuracy: 0.8968\n",
      "Epoch 216/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2299 - accuracy: 0.9048 - val_loss: 0.2400 - val_accuracy: 0.8968\n",
      "Epoch 217/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2299 - accuracy: 0.9048 - val_loss: 0.2399 - val_accuracy: 0.8968\n",
      "Epoch 218/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2298 - accuracy: 0.9048 - val_loss: 0.2399 - val_accuracy: 0.8968\n",
      "Epoch 219/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2298 - accuracy: 0.9048 - val_loss: 0.2399 - val_accuracy: 0.8968\n",
      "Epoch 220/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2297 - accuracy: 0.9048 - val_loss: 0.2398 - val_accuracy: 0.8968\n",
      "Epoch 221/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2297 - accuracy: 0.9048 - val_loss: 0.2398 - val_accuracy: 0.8968\n",
      "Epoch 222/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2296 - accuracy: 0.9048 - val_loss: 0.2397 - val_accuracy: 0.8968\n",
      "Epoch 223/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2296 - accuracy: 0.9048 - val_loss: 0.2397 - val_accuracy: 0.8968\n",
      "Epoch 224/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2296 - accuracy: 0.9048 - val_loss: 0.2397 - val_accuracy: 0.8968\n",
      "Epoch 225/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2295 - accuracy: 0.9048 - val_loss: 0.2396 - val_accuracy: 0.8968\n",
      "Epoch 226/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2295 - accuracy: 0.9048 - val_loss: 0.2396 - val_accuracy: 0.8968\n",
      "Epoch 227/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2294 - accuracy: 0.9048 - val_loss: 0.2395 - val_accuracy: 0.8968\n",
      "Epoch 228/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2294 - accuracy: 0.9048 - val_loss: 0.2395 - val_accuracy: 0.8968\n",
      "Epoch 229/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2294 - accuracy: 0.9048 - val_loss: 0.2395 - val_accuracy: 0.8968\n",
      "Epoch 230/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2293 - accuracy: 0.9048 - val_loss: 0.2394 - val_accuracy: 0.8968\n",
      "Epoch 231/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2293 - accuracy: 0.9048 - val_loss: 0.2394 - val_accuracy: 0.8968\n",
      "Epoch 232/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2292 - accuracy: 0.9048 - val_loss: 0.2393 - val_accuracy: 0.8968\n",
      "Epoch 233/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2292 - accuracy: 0.9048 - val_loss: 0.2393 - val_accuracy: 0.8968\n",
      "Epoch 234/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2292 - accuracy: 0.9048 - val_loss: 0.2393 - val_accuracy: 0.8968\n",
      "Epoch 235/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2291 - accuracy: 0.9048 - val_loss: 0.2392 - val_accuracy: 0.8968\n",
      "Epoch 236/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2291 - accuracy: 0.9048 - val_loss: 0.2392 - val_accuracy: 0.8968\n",
      "Epoch 237/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2290 - accuracy: 0.9048 - val_loss: 0.2392 - val_accuracy: 0.8968\n",
      "Epoch 238/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2290 - accuracy: 0.9048 - val_loss: 0.2391 - val_accuracy: 0.8968\n",
      "Epoch 239/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2290 - accuracy: 0.9048 - val_loss: 0.2391 - val_accuracy: 0.8968\n",
      "Epoch 240/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2289 - accuracy: 0.9048 - val_loss: 0.2390 - val_accuracy: 0.8968\n",
      "Epoch 241/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2289 - accuracy: 0.9048 - val_loss: 0.2390 - val_accuracy: 0.8968\n",
      "Epoch 242/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2288 - accuracy: 0.9048 - val_loss: 0.2390 - val_accuracy: 0.8968\n",
      "Epoch 243/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2288 - accuracy: 0.9048 - val_loss: 0.2389 - val_accuracy: 0.8968\n",
      "Epoch 244/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2288 - accuracy: 0.9048 - val_loss: 0.2389 - val_accuracy: 0.8968\n",
      "Epoch 245/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2287 - accuracy: 0.9048 - val_loss: 0.2389 - val_accuracy: 0.8968\n",
      "Epoch 246/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2287 - accuracy: 0.9048 - val_loss: 0.2388 - val_accuracy: 0.8968\n",
      "Epoch 247/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2286 - accuracy: 0.9048 - val_loss: 0.2388 - val_accuracy: 0.8968\n",
      "Epoch 248/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2286 - accuracy: 0.9048 - val_loss: 0.2388 - val_accuracy: 0.8968\n",
      "Epoch 249/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2286 - accuracy: 0.9048 - val_loss: 0.2387 - val_accuracy: 0.8968\n",
      "Epoch 250/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2285 - accuracy: 0.9048 - val_loss: 0.2387 - val_accuracy: 0.8968\n",
      "Epoch 251/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2285 - accuracy: 0.9048 - val_loss: 0.2387 - val_accuracy: 0.8968\n",
      "Epoch 252/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2285 - accuracy: 0.9048 - val_loss: 0.2386 - val_accuracy: 0.8968\n",
      "Epoch 253/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2284 - accuracy: 0.9048 - val_loss: 0.2386 - val_accuracy: 0.8968\n",
      "Epoch 254/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2284 - accuracy: 0.9048 - val_loss: 0.2386 - val_accuracy: 0.8968\n",
      "Epoch 255/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2283 - accuracy: 0.9048 - val_loss: 0.2385 - val_accuracy: 0.8968\n",
      "Epoch 256/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2283 - accuracy: 0.9048 - val_loss: 0.2385 - val_accuracy: 0.8968\n",
      "Epoch 257/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2283 - accuracy: 0.9048 - val_loss: 0.2384 - val_accuracy: 0.8968\n",
      "Epoch 258/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2282 - accuracy: 0.9048 - val_loss: 0.2384 - val_accuracy: 0.8968\n",
      "Epoch 259/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2282 - accuracy: 0.9048 - val_loss: 0.2384 - val_accuracy: 0.8968\n",
      "Epoch 260/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2282 - accuracy: 0.9048 - val_loss: 0.2383 - val_accuracy: 0.8968\n",
      "Epoch 261/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2281 - accuracy: 0.9048 - val_loss: 0.2383 - val_accuracy: 0.8968\n",
      "Epoch 262/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2281 - accuracy: 0.9048 - val_loss: 0.2383 - val_accuracy: 0.8968\n",
      "Epoch 263/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2281 - accuracy: 0.9048 - val_loss: 0.2382 - val_accuracy: 0.8968\n",
      "Epoch 264/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2280 - accuracy: 0.9048 - val_loss: 0.2382 - val_accuracy: 0.8968\n",
      "Epoch 265/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2280 - accuracy: 0.9048 - val_loss: 0.2382 - val_accuracy: 0.8968\n",
      "Epoch 266/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2279 - accuracy: 0.9048 - val_loss: 0.2381 - val_accuracy: 0.8968\n",
      "Epoch 267/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2279 - accuracy: 0.9048 - val_loss: 0.2381 - val_accuracy: 0.8968\n",
      "Epoch 268/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2279 - accuracy: 0.9048 - val_loss: 0.2381 - val_accuracy: 0.8968\n",
      "Epoch 269/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2278 - accuracy: 0.9048 - val_loss: 0.2380 - val_accuracy: 0.8968\n",
      "Epoch 270/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2278 - accuracy: 0.9048 - val_loss: 0.2380 - val_accuracy: 0.8968\n",
      "Epoch 271/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2278 - accuracy: 0.9048 - val_loss: 0.2380 - val_accuracy: 0.8968\n",
      "Epoch 272/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2277 - accuracy: 0.9048 - val_loss: 0.2380 - val_accuracy: 0.8968\n",
      "Epoch 273/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2277 - accuracy: 0.9048 - val_loss: 0.2379 - val_accuracy: 0.8968\n",
      "Epoch 274/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2277 - accuracy: 0.9048 - val_loss: 0.2379 - val_accuracy: 0.8968\n",
      "Epoch 275/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2276 - accuracy: 0.9048 - val_loss: 0.2379 - val_accuracy: 0.8968\n",
      "Epoch 276/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2276 - accuracy: 0.9048 - val_loss: 0.2378 - val_accuracy: 0.8968\n",
      "Epoch 277/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2276 - accuracy: 0.9048 - val_loss: 0.2378 - val_accuracy: 0.8968\n",
      "Epoch 278/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2275 - accuracy: 0.9048 - val_loss: 0.2378 - val_accuracy: 0.8968\n",
      "Epoch 279/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2275 - accuracy: 0.9048 - val_loss: 0.2377 - val_accuracy: 0.8968\n",
      "Epoch 280/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2275 - accuracy: 0.9048 - val_loss: 0.2377 - val_accuracy: 0.8968\n",
      "Epoch 281/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2274 - accuracy: 0.9048 - val_loss: 0.2377 - val_accuracy: 0.8968\n",
      "Epoch 282/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2274 - accuracy: 0.9048 - val_loss: 0.2376 - val_accuracy: 0.8968\n",
      "Epoch 283/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2274 - accuracy: 0.9048 - val_loss: 0.2376 - val_accuracy: 0.8968\n",
      "Epoch 284/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2273 - accuracy: 0.9048 - val_loss: 0.2376 - val_accuracy: 0.8968\n",
      "Epoch 285/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2273 - accuracy: 0.9048 - val_loss: 0.2375 - val_accuracy: 0.8968\n",
      "Epoch 286/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2273 - accuracy: 0.9048 - val_loss: 0.2375 - val_accuracy: 0.8968\n",
      "Epoch 287/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2272 - accuracy: 0.9048 - val_loss: 0.2375 - val_accuracy: 0.8968\n",
      "Epoch 288/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2272 - accuracy: 0.9048 - val_loss: 0.2374 - val_accuracy: 0.8968\n",
      "Epoch 289/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2272 - accuracy: 0.9048 - val_loss: 0.2374 - val_accuracy: 0.8968\n",
      "Epoch 290/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2271 - accuracy: 0.9048 - val_loss: 0.2374 - val_accuracy: 0.8968\n",
      "Epoch 291/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2271 - accuracy: 0.9048 - val_loss: 0.2374 - val_accuracy: 0.8968\n",
      "Epoch 292/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2271 - accuracy: 0.9048 - val_loss: 0.2373 - val_accuracy: 0.8968\n",
      "Epoch 293/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2270 - accuracy: 0.9048 - val_loss: 0.2373 - val_accuracy: 0.8968\n",
      "Epoch 294/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2270 - accuracy: 0.9048 - val_loss: 0.2373 - val_accuracy: 0.8968\n",
      "Epoch 295/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2270 - accuracy: 0.9048 - val_loss: 0.2372 - val_accuracy: 0.8968\n",
      "Epoch 296/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2269 - accuracy: 0.9048 - val_loss: 0.2372 - val_accuracy: 0.8968\n",
      "Epoch 297/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2269 - accuracy: 0.9048 - val_loss: 0.2372 - val_accuracy: 0.8968\n",
      "Epoch 298/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2269 - accuracy: 0.9048 - val_loss: 0.2371 - val_accuracy: 0.8968\n",
      "Epoch 299/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2268 - accuracy: 0.9048 - val_loss: 0.2371 - val_accuracy: 0.8968\n",
      "Epoch 300/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2268 - accuracy: 0.9048 - val_loss: 0.2371 - val_accuracy: 0.8968\n",
      "Epoch 301/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2268 - accuracy: 0.9048 - val_loss: 0.2371 - val_accuracy: 0.8968\n",
      "Epoch 302/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2267 - accuracy: 0.9048 - val_loss: 0.2370 - val_accuracy: 0.8968\n",
      "Epoch 303/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2267 - accuracy: 0.9048 - val_loss: 0.2370 - val_accuracy: 0.8968\n",
      "Epoch 304/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2267 - accuracy: 0.9048 - val_loss: 0.2370 - val_accuracy: 0.8968\n",
      "Epoch 305/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2266 - accuracy: 0.9048 - val_loss: 0.2369 - val_accuracy: 0.8968\n",
      "Epoch 306/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2266 - accuracy: 0.9048 - val_loss: 0.2369 - val_accuracy: 0.8968\n",
      "Epoch 307/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2266 - accuracy: 0.9048 - val_loss: 0.2369 - val_accuracy: 0.8968\n",
      "Epoch 308/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2265 - accuracy: 0.9048 - val_loss: 0.2368 - val_accuracy: 0.8968\n",
      "Epoch 309/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2265 - accuracy: 0.9048 - val_loss: 0.2368 - val_accuracy: 0.8968\n",
      "Epoch 310/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2265 - accuracy: 0.9048 - val_loss: 0.2368 - val_accuracy: 0.8968\n",
      "Epoch 311/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2265 - accuracy: 0.9048 - val_loss: 0.2368 - val_accuracy: 0.8968\n",
      "Epoch 312/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2264 - accuracy: 0.9048 - val_loss: 0.2367 - val_accuracy: 0.8968\n",
      "Epoch 313/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2264 - accuracy: 0.9048 - val_loss: 0.2367 - val_accuracy: 0.8968\n",
      "Epoch 314/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2264 - accuracy: 0.9048 - val_loss: 0.2367 - val_accuracy: 0.8968\n",
      "Epoch 315/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2263 - accuracy: 0.9048 - val_loss: 0.2366 - val_accuracy: 0.8968\n",
      "Epoch 316/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2263 - accuracy: 0.9048 - val_loss: 0.2366 - val_accuracy: 0.8968\n",
      "Epoch 317/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2263 - accuracy: 0.9048 - val_loss: 0.2366 - val_accuracy: 0.8968\n",
      "Epoch 318/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2262 - accuracy: 0.9048 - val_loss: 0.2366 - val_accuracy: 0.8968\n",
      "Epoch 319/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2262 - accuracy: 0.9048 - val_loss: 0.2365 - val_accuracy: 0.8968\n",
      "Epoch 320/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2262 - accuracy: 0.9048 - val_loss: 0.2365 - val_accuracy: 0.8968\n",
      "Epoch 321/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2261 - accuracy: 0.9048 - val_loss: 0.2365 - val_accuracy: 0.8968\n",
      "Epoch 322/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2261 - accuracy: 0.9048 - val_loss: 0.2364 - val_accuracy: 0.8968\n",
      "Epoch 323/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2261 - accuracy: 0.9048 - val_loss: 0.2364 - val_accuracy: 0.8968\n",
      "Epoch 324/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2261 - accuracy: 0.9048 - val_loss: 0.2364 - val_accuracy: 0.8968\n",
      "Epoch 325/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2260 - accuracy: 0.9048 - val_loss: 0.2364 - val_accuracy: 0.8968\n",
      "Epoch 326/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2260 - accuracy: 0.9048 - val_loss: 0.2363 - val_accuracy: 0.8968\n",
      "Epoch 327/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2260 - accuracy: 0.9048 - val_loss: 0.2363 - val_accuracy: 0.8968\n",
      "Epoch 328/500\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.2259 - accuracy: 0.9048 - val_loss: 0.2363 - val_accuracy: 0.8968\n",
      "Epoch 329/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2259 - accuracy: 0.9048 - val_loss: 0.2363 - val_accuracy: 0.8968\n",
      "Epoch 330/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2259 - accuracy: 0.9048 - val_loss: 0.2362 - val_accuracy: 0.8968\n",
      "Epoch 331/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2258 - accuracy: 0.9048 - val_loss: 0.2362 - val_accuracy: 0.8968\n",
      "Epoch 332/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2258 - accuracy: 0.9048 - val_loss: 0.2362 - val_accuracy: 0.8968\n",
      "Epoch 333/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2258 - accuracy: 0.9048 - val_loss: 0.2361 - val_accuracy: 0.8968\n",
      "Epoch 334/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2258 - accuracy: 0.9048 - val_loss: 0.2361 - val_accuracy: 0.8968\n",
      "Epoch 335/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2257 - accuracy: 0.9048 - val_loss: 0.2361 - val_accuracy: 0.8968\n",
      "Epoch 336/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2257 - accuracy: 0.9048 - val_loss: 0.2361 - val_accuracy: 0.8968\n",
      "Epoch 337/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2257 - accuracy: 0.9048 - val_loss: 0.2360 - val_accuracy: 0.8968\n",
      "Epoch 338/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2256 - accuracy: 0.9048 - val_loss: 0.2360 - val_accuracy: 0.8968\n",
      "Epoch 339/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2256 - accuracy: 0.9048 - val_loss: 0.2360 - val_accuracy: 0.8968\n",
      "Epoch 340/500\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.2256 - accuracy: 0.9048 - val_loss: 0.2360 - val_accuracy: 0.8968\n",
      "Epoch 341/500\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.2256 - accuracy: 0.9048 - val_loss: 0.2359 - val_accuracy: 0.8968\n",
      "Epoch 342/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2255 - accuracy: 0.9048 - val_loss: 0.2359 - val_accuracy: 0.8968\n",
      "Epoch 343/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2255 - accuracy: 0.9048 - val_loss: 0.2359 - val_accuracy: 0.8968\n",
      "Epoch 344/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2255 - accuracy: 0.9048 - val_loss: 0.2359 - val_accuracy: 0.8968\n",
      "Epoch 345/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2254 - accuracy: 0.9048 - val_loss: 0.2358 - val_accuracy: 0.8968\n",
      "Epoch 346/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2254 - accuracy: 0.9048 - val_loss: 0.2358 - val_accuracy: 0.8968\n",
      "Epoch 347/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2254 - accuracy: 0.9048 - val_loss: 0.2358 - val_accuracy: 0.8968\n",
      "Epoch 348/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2254 - accuracy: 0.9048 - val_loss: 0.2358 - val_accuracy: 0.8968\n",
      "Epoch 349/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2253 - accuracy: 0.9048 - val_loss: 0.2357 - val_accuracy: 0.8968\n",
      "Epoch 350/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2253 - accuracy: 0.9048 - val_loss: 0.2357 - val_accuracy: 0.8968\n",
      "Epoch 351/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2253 - accuracy: 0.9048 - val_loss: 0.2357 - val_accuracy: 0.8968\n",
      "Epoch 352/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2252 - accuracy: 0.9048 - val_loss: 0.2357 - val_accuracy: 0.8968\n",
      "Epoch 353/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2252 - accuracy: 0.9048 - val_loss: 0.2356 - val_accuracy: 0.8968\n",
      "Epoch 354/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2252 - accuracy: 0.9048 - val_loss: 0.2356 - val_accuracy: 0.8968\n",
      "Epoch 355/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2252 - accuracy: 0.9053 - val_loss: 0.2356 - val_accuracy: 0.8968\n",
      "Epoch 356/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2251 - accuracy: 0.9053 - val_loss: 0.2356 - val_accuracy: 0.8968\n",
      "Epoch 357/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2251 - accuracy: 0.9053 - val_loss: 0.2355 - val_accuracy: 0.8968\n",
      "Epoch 358/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2251 - accuracy: 0.9053 - val_loss: 0.2355 - val_accuracy: 0.8968\n",
      "Epoch 359/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2251 - accuracy: 0.9053 - val_loss: 0.2355 - val_accuracy: 0.8968\n",
      "Epoch 360/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2250 - accuracy: 0.9053 - val_loss: 0.2355 - val_accuracy: 0.8968\n",
      "Epoch 361/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2250 - accuracy: 0.9053 - val_loss: 0.2354 - val_accuracy: 0.8968\n",
      "Epoch 362/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2250 - accuracy: 0.9053 - val_loss: 0.2354 - val_accuracy: 0.8968\n",
      "Epoch 363/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2249 - accuracy: 0.9053 - val_loss: 0.2354 - val_accuracy: 0.8968\n",
      "Epoch 364/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2249 - accuracy: 0.9053 - val_loss: 0.2354 - val_accuracy: 0.8968\n",
      "Epoch 365/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2249 - accuracy: 0.9053 - val_loss: 0.2353 - val_accuracy: 0.8968\n",
      "Epoch 366/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2249 - accuracy: 0.9053 - val_loss: 0.2353 - val_accuracy: 0.8968\n",
      "Epoch 367/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2248 - accuracy: 0.9053 - val_loss: 0.2353 - val_accuracy: 0.8968\n",
      "Epoch 368/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2248 - accuracy: 0.9053 - val_loss: 0.2353 - val_accuracy: 0.8968\n",
      "Epoch 369/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2248 - accuracy: 0.9053 - val_loss: 0.2352 - val_accuracy: 0.8968\n",
      "Epoch 370/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2248 - accuracy: 0.9053 - val_loss: 0.2352 - val_accuracy: 0.8968\n",
      "Epoch 371/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2247 - accuracy: 0.9053 - val_loss: 0.2352 - val_accuracy: 0.8968\n",
      "Epoch 372/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2247 - accuracy: 0.9053 - val_loss: 0.2352 - val_accuracy: 0.8968\n",
      "Epoch 373/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2247 - accuracy: 0.9053 - val_loss: 0.2351 - val_accuracy: 0.8968\n",
      "Epoch 374/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2247 - accuracy: 0.9053 - val_loss: 0.2351 - val_accuracy: 0.8968\n",
      "Epoch 375/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2246 - accuracy: 0.9053 - val_loss: 0.2351 - val_accuracy: 0.8968\n",
      "Epoch 376/500\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.2246 - accuracy: 0.9053 - val_loss: 0.2351 - val_accuracy: 0.8968\n",
      "Epoch 377/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2246 - accuracy: 0.9053 - val_loss: 0.2350 - val_accuracy: 0.8968\n",
      "Epoch 378/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2246 - accuracy: 0.9053 - val_loss: 0.2350 - val_accuracy: 0.8968\n",
      "Epoch 379/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2245 - accuracy: 0.9053 - val_loss: 0.2350 - val_accuracy: 0.8968\n",
      "Epoch 380/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2245 - accuracy: 0.9053 - val_loss: 0.2350 - val_accuracy: 0.8968\n",
      "Epoch 381/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2245 - accuracy: 0.9053 - val_loss: 0.2349 - val_accuracy: 0.8968\n",
      "Epoch 382/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2245 - accuracy: 0.9053 - val_loss: 0.2349 - val_accuracy: 0.8968\n",
      "Epoch 383/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2244 - accuracy: 0.9053 - val_loss: 0.2349 - val_accuracy: 0.8968\n",
      "Epoch 384/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2244 - accuracy: 0.9053 - val_loss: 0.2349 - val_accuracy: 0.8968\n",
      "Epoch 385/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2244 - accuracy: 0.9053 - val_loss: 0.2349 - val_accuracy: 0.8968\n",
      "Epoch 386/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2244 - accuracy: 0.9053 - val_loss: 0.2348 - val_accuracy: 0.8968\n",
      "Epoch 387/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2243 - accuracy: 0.9053 - val_loss: 0.2348 - val_accuracy: 0.8968\n",
      "Epoch 388/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2243 - accuracy: 0.9053 - val_loss: 0.2348 - val_accuracy: 0.8968\n",
      "Epoch 389/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2243 - accuracy: 0.9053 - val_loss: 0.2348 - val_accuracy: 0.8968\n",
      "Epoch 390/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2243 - accuracy: 0.9053 - val_loss: 0.2347 - val_accuracy: 0.8968\n",
      "Epoch 391/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2242 - accuracy: 0.9053 - val_loss: 0.2347 - val_accuracy: 0.8968\n",
      "Epoch 392/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2242 - accuracy: 0.9053 - val_loss: 0.2347 - val_accuracy: 0.8968\n",
      "Epoch 393/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2242 - accuracy: 0.9053 - val_loss: 0.2347 - val_accuracy: 0.8968\n",
      "Epoch 394/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2242 - accuracy: 0.9053 - val_loss: 0.2346 - val_accuracy: 0.8968\n",
      "Epoch 395/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2241 - accuracy: 0.9053 - val_loss: 0.2346 - val_accuracy: 0.8968\n",
      "Epoch 396/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2241 - accuracy: 0.9053 - val_loss: 0.2346 - val_accuracy: 0.8968\n",
      "Epoch 397/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2241 - accuracy: 0.9053 - val_loss: 0.2346 - val_accuracy: 0.8968\n",
      "Epoch 398/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2241 - accuracy: 0.9053 - val_loss: 0.2346 - val_accuracy: 0.8968\n",
      "Epoch 399/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2240 - accuracy: 0.9053 - val_loss: 0.2345 - val_accuracy: 0.8968\n",
      "Epoch 400/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2240 - accuracy: 0.9053 - val_loss: 0.2345 - val_accuracy: 0.8968\n",
      "Epoch 401/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2240 - accuracy: 0.9053 - val_loss: 0.2345 - val_accuracy: 0.8968\n",
      "Epoch 402/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2240 - accuracy: 0.9053 - val_loss: 0.2345 - val_accuracy: 0.8968\n",
      "Epoch 403/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2239 - accuracy: 0.9053 - val_loss: 0.2344 - val_accuracy: 0.8968\n",
      "Epoch 404/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2239 - accuracy: 0.9053 - val_loss: 0.2344 - val_accuracy: 0.8968\n",
      "Epoch 405/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2239 - accuracy: 0.9053 - val_loss: 0.2344 - val_accuracy: 0.8968\n",
      "Epoch 406/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2239 - accuracy: 0.9053 - val_loss: 0.2344 - val_accuracy: 0.8968\n",
      "Epoch 407/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2238 - accuracy: 0.9053 - val_loss: 0.2344 - val_accuracy: 0.8968\n",
      "Epoch 408/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2238 - accuracy: 0.9053 - val_loss: 0.2343 - val_accuracy: 0.8968\n",
      "Epoch 409/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2238 - accuracy: 0.9053 - val_loss: 0.2343 - val_accuracy: 0.8968\n",
      "Epoch 410/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2238 - accuracy: 0.9053 - val_loss: 0.2343 - val_accuracy: 0.8968\n",
      "Epoch 411/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2237 - accuracy: 0.9053 - val_loss: 0.2343 - val_accuracy: 0.8968\n",
      "Epoch 412/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2237 - accuracy: 0.9053 - val_loss: 0.2342 - val_accuracy: 0.8968\n",
      "Epoch 413/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2237 - accuracy: 0.9053 - val_loss: 0.2342 - val_accuracy: 0.8968\n",
      "Epoch 414/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2237 - accuracy: 0.9053 - val_loss: 0.2342 - val_accuracy: 0.8968\n",
      "Epoch 415/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2236 - accuracy: 0.9053 - val_loss: 0.2342 - val_accuracy: 0.8968\n",
      "Epoch 416/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2236 - accuracy: 0.9053 - val_loss: 0.2342 - val_accuracy: 0.8968\n",
      "Epoch 417/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2236 - accuracy: 0.9053 - val_loss: 0.2341 - val_accuracy: 0.8968\n",
      "Epoch 418/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2236 - accuracy: 0.9053 - val_loss: 0.2341 - val_accuracy: 0.8968\n",
      "Epoch 419/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2236 - accuracy: 0.9053 - val_loss: 0.2341 - val_accuracy: 0.8968\n",
      "Epoch 420/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2235 - accuracy: 0.9053 - val_loss: 0.2341 - val_accuracy: 0.8968\n",
      "Epoch 421/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2235 - accuracy: 0.9053 - val_loss: 0.2341 - val_accuracy: 0.8968\n",
      "Epoch 422/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2235 - accuracy: 0.9053 - val_loss: 0.2340 - val_accuracy: 0.8968\n",
      "Epoch 423/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2235 - accuracy: 0.9053 - val_loss: 0.2340 - val_accuracy: 0.8968\n",
      "Epoch 424/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2234 - accuracy: 0.9053 - val_loss: 0.2340 - val_accuracy: 0.8968\n",
      "Epoch 425/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2234 - accuracy: 0.9053 - val_loss: 0.2340 - val_accuracy: 0.8968\n",
      "Epoch 426/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2234 - accuracy: 0.9053 - val_loss: 0.2340 - val_accuracy: 0.8968\n",
      "Epoch 427/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2234 - accuracy: 0.9053 - val_loss: 0.2339 - val_accuracy: 0.8968\n",
      "Epoch 428/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2233 - accuracy: 0.9053 - val_loss: 0.2339 - val_accuracy: 0.8968\n",
      "Epoch 429/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2233 - accuracy: 0.9053 - val_loss: 0.2339 - val_accuracy: 0.8968\n",
      "Epoch 430/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2233 - accuracy: 0.9053 - val_loss: 0.2339 - val_accuracy: 0.8968\n",
      "Epoch 431/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2233 - accuracy: 0.9053 - val_loss: 0.2338 - val_accuracy: 0.8968\n",
      "Epoch 432/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2233 - accuracy: 0.9053 - val_loss: 0.2338 - val_accuracy: 0.8968\n",
      "Epoch 433/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2232 - accuracy: 0.9053 - val_loss: 0.2338 - val_accuracy: 0.8968\n",
      "Epoch 434/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2232 - accuracy: 0.9053 - val_loss: 0.2338 - val_accuracy: 0.8968\n",
      "Epoch 435/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2232 - accuracy: 0.9053 - val_loss: 0.2338 - val_accuracy: 0.8968\n",
      "Epoch 436/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2232 - accuracy: 0.9053 - val_loss: 0.2337 - val_accuracy: 0.8968\n",
      "Epoch 437/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2231 - accuracy: 0.9053 - val_loss: 0.2337 - val_accuracy: 0.8968\n",
      "Epoch 438/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2231 - accuracy: 0.9053 - val_loss: 0.2337 - val_accuracy: 0.8968\n",
      "Epoch 439/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2231 - accuracy: 0.9053 - val_loss: 0.2337 - val_accuracy: 0.8968\n",
      "Epoch 440/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2231 - accuracy: 0.9053 - val_loss: 0.2337 - val_accuracy: 0.8968\n",
      "Epoch 441/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2230 - accuracy: 0.9053 - val_loss: 0.2336 - val_accuracy: 0.8968\n",
      "Epoch 442/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2230 - accuracy: 0.9053 - val_loss: 0.2336 - val_accuracy: 0.8968\n",
      "Epoch 443/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2230 - accuracy: 0.9053 - val_loss: 0.2336 - val_accuracy: 0.8968\n",
      "Epoch 444/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2230 - accuracy: 0.9053 - val_loss: 0.2336 - val_accuracy: 0.8968\n",
      "Epoch 445/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2230 - accuracy: 0.9053 - val_loss: 0.2336 - val_accuracy: 0.8968\n",
      "Epoch 446/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2229 - accuracy: 0.9053 - val_loss: 0.2336 - val_accuracy: 0.8968\n",
      "Epoch 447/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2229 - accuracy: 0.9053 - val_loss: 0.2335 - val_accuracy: 0.8968\n",
      "Epoch 448/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2229 - accuracy: 0.9053 - val_loss: 0.2335 - val_accuracy: 0.8968\n",
      "Epoch 449/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2229 - accuracy: 0.9053 - val_loss: 0.2335 - val_accuracy: 0.8968\n",
      "Epoch 450/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2228 - accuracy: 0.9053 - val_loss: 0.2335 - val_accuracy: 0.8968\n",
      "Epoch 451/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2228 - accuracy: 0.9053 - val_loss: 0.2335 - val_accuracy: 0.8968\n",
      "Epoch 452/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2228 - accuracy: 0.9053 - val_loss: 0.2334 - val_accuracy: 0.8968\n",
      "Epoch 453/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2228 - accuracy: 0.9053 - val_loss: 0.2334 - val_accuracy: 0.8968\n",
      "Epoch 454/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2228 - accuracy: 0.9053 - val_loss: 0.2334 - val_accuracy: 0.8968\n",
      "Epoch 455/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2227 - accuracy: 0.9053 - val_loss: 0.2334 - val_accuracy: 0.8968\n",
      "Epoch 456/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2227 - accuracy: 0.9053 - val_loss: 0.2334 - val_accuracy: 0.8968\n",
      "Epoch 457/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2227 - accuracy: 0.9053 - val_loss: 0.2333 - val_accuracy: 0.8968\n",
      "Epoch 458/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2227 - accuracy: 0.9053 - val_loss: 0.2333 - val_accuracy: 0.8968\n",
      "Epoch 459/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2226 - accuracy: 0.9053 - val_loss: 0.2333 - val_accuracy: 0.8968\n",
      "Epoch 460/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2226 - accuracy: 0.9053 - val_loss: 0.2333 - val_accuracy: 0.8968\n",
      "Epoch 461/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2226 - accuracy: 0.9053 - val_loss: 0.2333 - val_accuracy: 0.8968\n",
      "Epoch 462/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2226 - accuracy: 0.9053 - val_loss: 0.2332 - val_accuracy: 0.8968\n",
      "Epoch 463/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2226 - accuracy: 0.9053 - val_loss: 0.2332 - val_accuracy: 0.8968\n",
      "Epoch 464/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2225 - accuracy: 0.9053 - val_loss: 0.2332 - val_accuracy: 0.8968\n",
      "Epoch 465/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2225 - accuracy: 0.9053 - val_loss: 0.2332 - val_accuracy: 0.8968\n",
      "Epoch 466/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2225 - accuracy: 0.9053 - val_loss: 0.2332 - val_accuracy: 0.8968\n",
      "Epoch 467/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2225 - accuracy: 0.9053 - val_loss: 0.2331 - val_accuracy: 0.8968\n",
      "Epoch 468/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2225 - accuracy: 0.9053 - val_loss: 0.2331 - val_accuracy: 0.8968\n",
      "Epoch 469/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2224 - accuracy: 0.9053 - val_loss: 0.2331 - val_accuracy: 0.8968\n",
      "Epoch 470/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2224 - accuracy: 0.9053 - val_loss: 0.2331 - val_accuracy: 0.8968\n",
      "Epoch 471/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2224 - accuracy: 0.9053 - val_loss: 0.2331 - val_accuracy: 0.8968\n",
      "Epoch 472/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2224 - accuracy: 0.9053 - val_loss: 0.2331 - val_accuracy: 0.8968\n",
      "Epoch 473/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2223 - accuracy: 0.9053 - val_loss: 0.2330 - val_accuracy: 0.8968\n",
      "Epoch 474/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2223 - accuracy: 0.9053 - val_loss: 0.2330 - val_accuracy: 0.8968\n",
      "Epoch 475/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2223 - accuracy: 0.9053 - val_loss: 0.2330 - val_accuracy: 0.8968\n",
      "Epoch 476/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2223 - accuracy: 0.9053 - val_loss: 0.2330 - val_accuracy: 0.8968\n",
      "Epoch 477/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2223 - accuracy: 0.9053 - val_loss: 0.2330 - val_accuracy: 0.8968\n",
      "Epoch 478/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2222 - accuracy: 0.9053 - val_loss: 0.2329 - val_accuracy: 0.8968\n",
      "Epoch 479/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2222 - accuracy: 0.9053 - val_loss: 0.2329 - val_accuracy: 0.8968\n",
      "Epoch 480/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2222 - accuracy: 0.9053 - val_loss: 0.2329 - val_accuracy: 0.8968\n",
      "Epoch 481/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2222 - accuracy: 0.9053 - val_loss: 0.2329 - val_accuracy: 0.8968\n",
      "Epoch 482/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2222 - accuracy: 0.9053 - val_loss: 0.2329 - val_accuracy: 0.8968\n",
      "Epoch 483/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2221 - accuracy: 0.9053 - val_loss: 0.2329 - val_accuracy: 0.8968\n",
      "Epoch 484/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2221 - accuracy: 0.9053 - val_loss: 0.2328 - val_accuracy: 0.8968\n",
      "Epoch 485/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2221 - accuracy: 0.9053 - val_loss: 0.2328 - val_accuracy: 0.8968\n",
      "Epoch 486/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2221 - accuracy: 0.9053 - val_loss: 0.2328 - val_accuracy: 0.8968\n",
      "Epoch 487/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2221 - accuracy: 0.9053 - val_loss: 0.2328 - val_accuracy: 0.8968\n",
      "Epoch 488/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2220 - accuracy: 0.9053 - val_loss: 0.2328 - val_accuracy: 0.8968\n",
      "Epoch 489/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2220 - accuracy: 0.9053 - val_loss: 0.2327 - val_accuracy: 0.8968\n",
      "Epoch 490/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2220 - accuracy: 0.9053 - val_loss: 0.2327 - val_accuracy: 0.8968\n",
      "Epoch 491/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2220 - accuracy: 0.9053 - val_loss: 0.2327 - val_accuracy: 0.8968\n",
      "Epoch 492/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2220 - accuracy: 0.9053 - val_loss: 0.2327 - val_accuracy: 0.8968\n",
      "Epoch 493/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2219 - accuracy: 0.9053 - val_loss: 0.2327 - val_accuracy: 0.8968\n",
      "Epoch 494/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2219 - accuracy: 0.9053 - val_loss: 0.2327 - val_accuracy: 0.8968\n",
      "Epoch 495/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2219 - accuracy: 0.9053 - val_loss: 0.2326 - val_accuracy: 0.8968\n",
      "Epoch 496/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2219 - accuracy: 0.9053 - val_loss: 0.2326 - val_accuracy: 0.8968\n",
      "Epoch 497/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2218 - accuracy: 0.9053 - val_loss: 0.2326 - val_accuracy: 0.8968\n",
      "Epoch 498/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2218 - accuracy: 0.9053 - val_loss: 0.2326 - val_accuracy: 0.8968\n",
      "Epoch 499/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2218 - accuracy: 0.9053 - val_loss: 0.2326 - val_accuracy: 0.8968\n",
      "Epoch 500/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2218 - accuracy: 0.9053 - val_loss: 0.2325 - val_accuracy: 0.8968\n",
      "20/20 [==============================] - 0s 1ms/step\n",
      "Epoch 1/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 2/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 3/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 4/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 5/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 6/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 7/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 8/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 9/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 10/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 11/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 12/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 13/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 14/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 15/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 16/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 17/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 18/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 19/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 20/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 21/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 22/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 23/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 24/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 25/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 26/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 27/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 28/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 29/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 30/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 31/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 32/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 33/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 34/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 35/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 36/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 37/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 38/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 39/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 40/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 41/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 54/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 0s 2ms/step\n",
      "Epoch 1/250\n",
      "63/63 [==============================] - 1s 4ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 2/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 3/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 4/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 5/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 6/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 7/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 8/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 9/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 10/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 11/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 12/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 13/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 14/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 15/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 16/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 17/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 18/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 19/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 20/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 21/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 22/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 23/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 24/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 25/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 26/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 27/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 28/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 29/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 30/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 31/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 32/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 33/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 34/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 35/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 36/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 37/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 38/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 39/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 40/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 41/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 42/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 43/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 44/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 45/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 46/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 47/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 49/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 50/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 51/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 52/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 53/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 54/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 55/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 56/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 57/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 58/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 59/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 60/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 61/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 62/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 63/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 64/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 65/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 66/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 67/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 68/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 69/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 70/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 71/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 72/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 73/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 74/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 75/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 76/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 77/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 78/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 79/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 80/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 81/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 82/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 83/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 84/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 85/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 86/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 87/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 88/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 89/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 90/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 91/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 92/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 93/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 94/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 95/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 96/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 97/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 98/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 99/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 100/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 101/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 102/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 103/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 104/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 105/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 106/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 107/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 108/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 109/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 110/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 111/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 112/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 113/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 114/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 115/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 116/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 117/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 118/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 119/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 120/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 121/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 122/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 123/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 124/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 125/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 126/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 127/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 128/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 129/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 130/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 131/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 132/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 133/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 134/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 135/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 136/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 137/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 138/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 139/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 140/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 141/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 142/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 143/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 144/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 145/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 146/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 147/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 148/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 149/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 150/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 151/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 152/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 153/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 154/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 155/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 156/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 157/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 158/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 159/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 160/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 161/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 162/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 163/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 164/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 165/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 166/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 167/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 168/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 169/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 170/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 171/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 172/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 173/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 174/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 175/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 176/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 177/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 178/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 179/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 180/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 181/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 182/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 183/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 184/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 185/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 186/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 187/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 188/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 189/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 190/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 191/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 192/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 193/250\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 194/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 195/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 196/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 197/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 198/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 199/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 200/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 201/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 202/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 203/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 204/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 205/250\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 206/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 207/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 208/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 209/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 210/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 211/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 212/250\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 213/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 214/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 215/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 216/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 217/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 218/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 219/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 220/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 221/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 222/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 223/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 224/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 225/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 226/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 227/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 228/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 229/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 230/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 231/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 232/250\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 233/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 234/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 235/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 236/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 237/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 238/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 239/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 240/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 241/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 242/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 243/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 244/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 245/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 246/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 247/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 248/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 249/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 250/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "20/20 [==============================] - 0s 1ms/step\n",
      "Epoch 1/500\n",
      "63/63 [==============================] - 1s 4ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 2/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 3/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 4/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 5/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 6/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 7/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 8/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 9/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 10/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 11/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 12/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 13/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 14/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 15/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 16/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 17/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 18/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 19/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 20/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 21/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 22/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 23/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 24/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 25/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 26/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 27/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 28/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 29/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 30/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 31/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 32/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 34/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 35/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 36/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 37/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 38/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 39/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 40/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 41/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 42/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 43/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 44/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 45/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 46/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 47/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 48/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 49/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 50/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 51/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 52/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 53/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 54/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 55/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 56/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 57/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 58/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 59/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 60/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 61/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 62/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 63/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 64/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 65/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 66/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 67/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 68/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 69/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 70/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 71/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 72/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 73/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 74/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 75/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 76/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 77/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 78/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 79/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 80/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 81/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 82/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 83/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 84/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 85/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 86/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 87/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 88/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 89/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 90/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 91/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 92/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 93/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 94/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 95/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 96/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 97/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 98/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 99/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 100/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 101/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 102/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 103/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 104/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 105/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 106/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 107/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 108/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 109/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 110/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 111/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 112/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 113/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 114/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 115/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 116/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 117/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 118/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 119/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 120/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 121/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 122/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 123/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 124/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 125/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 126/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 127/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 128/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 129/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 130/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 131/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 132/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 133/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 134/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 135/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 136/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 137/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 138/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 139/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 140/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 141/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 142/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 143/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 144/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 145/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 146/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 147/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 148/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 149/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 150/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 151/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 152/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 153/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 154/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 155/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 156/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 157/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 158/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 159/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 160/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 161/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 162/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 163/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 164/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 165/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 166/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 167/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 168/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 169/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 170/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 171/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 172/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 173/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 174/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 175/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 176/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 177/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 178/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 179/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 180/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 181/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 182/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 183/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 184/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 185/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 186/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 187/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 188/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 189/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 190/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 191/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 192/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 193/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 194/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 195/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 196/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 197/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 198/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 199/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 200/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 201/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 202/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 203/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 204/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 205/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 206/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 207/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 208/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 209/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 210/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 211/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 212/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 213/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 214/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 215/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 216/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 217/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 218/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 219/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 220/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 221/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 222/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 223/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 224/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 225/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 226/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 227/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 228/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 229/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 230/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 231/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 232/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 233/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 234/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 235/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 236/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 237/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 238/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 239/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 240/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 241/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 242/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 243/500\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 244/500\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 245/500\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 246/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 247/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 248/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 249/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 250/500\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 251/500\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 252/500\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 253/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 254/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 255/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 256/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 257/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 258/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 259/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 260/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 261/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 262/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 263/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 264/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 265/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 266/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 267/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 268/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 269/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 270/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 271/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 272/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 273/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 274/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 275/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 276/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 277/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 278/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 279/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 280/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 281/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 282/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 283/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 284/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 285/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 286/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 287/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 288/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 289/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 290/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 291/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 292/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 293/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 294/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 295/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 296/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 297/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 298/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 299/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 300/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 301/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 302/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 303/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 304/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 305/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 306/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 307/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 308/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 309/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 310/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 311/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 312/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 313/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 314/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 315/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 316/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 317/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 318/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 319/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 320/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 321/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 322/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 323/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 324/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 325/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 326/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 327/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 328/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 329/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 330/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 331/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 332/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 333/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 334/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 335/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 336/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 337/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 338/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 339/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 340/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 341/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 342/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 343/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 344/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 345/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 346/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 347/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 348/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 349/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 350/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 351/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 352/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 353/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 354/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 355/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 356/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 357/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 358/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 359/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 360/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 361/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 362/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 363/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 364/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 365/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 366/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 367/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 368/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 369/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 370/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 371/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 372/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 373/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 374/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 375/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 376/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 377/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 378/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 379/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 380/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 381/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 382/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 383/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 384/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 385/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 386/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 387/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 388/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 389/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 390/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 391/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 392/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 393/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 394/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 395/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 396/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 397/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 398/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 399/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 400/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 401/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 402/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 403/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 404/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 405/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 406/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 407/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 408/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 409/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 410/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 411/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 412/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 413/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 414/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 415/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 416/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 417/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 418/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 419/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 420/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 421/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 422/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 423/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 424/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 425/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 426/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 427/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 428/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 429/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 430/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 431/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 432/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 433/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 434/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 435/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 436/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 437/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 438/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 439/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 440/500\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 441/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 442/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 443/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 444/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 445/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 446/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 447/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 448/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 449/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 450/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 451/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 452/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 453/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 454/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 455/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 456/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 457/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 458/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 459/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 460/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 461/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 462/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 463/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 464/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 465/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 466/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 467/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 468/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 469/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 470/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 471/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 472/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 473/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 474/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 475/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 476/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 477/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 478/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 479/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 480/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 481/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 482/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 483/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 484/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 485/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 486/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 487/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 488/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 489/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 490/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 491/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 492/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 493/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 494/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 495/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 496/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 497/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 498/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 499/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "Epoch 500/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000\n",
      "20/20 [==============================] - 0s 1ms/step\n",
      "Epoch 1/100\n",
      "63/63 [==============================] - 1s 4ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 2/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 4/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 5/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 6/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 7/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 8/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 9/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 10/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 11/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 12/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 13/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 14/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 15/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 16/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 17/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 18/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 19/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 20/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 21/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 22/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 23/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 24/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 25/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 26/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 27/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 28/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 29/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 30/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 31/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 32/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 33/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 34/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 35/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 36/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 37/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 38/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 39/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 40/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 41/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 42/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 43/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 44/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 45/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 46/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 47/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 48/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 49/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 50/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 51/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 52/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 53/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 54/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 55/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 56/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 57/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 58/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 59/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 60/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 62/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 63/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 64/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 65/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 66/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 67/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 68/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 69/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 70/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 71/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 72/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 73/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 74/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 75/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 76/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 77/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 78/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 79/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 80/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 81/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 82/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 83/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 84/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 85/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 86/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 87/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 88/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 89/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 90/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 91/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 92/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 93/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 94/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 95/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 96/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 97/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 98/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 99/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 100/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "20/20 [==============================] - 0s 1ms/step\n",
      "Epoch 1/250\n",
      "63/63 [==============================] - 1s 4ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 2/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 3/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 4/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 5/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 6/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 7/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 8/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 9/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 10/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 11/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 12/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 13/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 14/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 15/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 16/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 17/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 18/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 19/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 20/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 21/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 22/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 23/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 24/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 25/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 26/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 27/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 28/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 29/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 30/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 31/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 32/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 33/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 34/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 35/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 36/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 37/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 38/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 39/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 40/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 41/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 42/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 43/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 44/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 45/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 46/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 47/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 48/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 49/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 50/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 51/250\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 52/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 53/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 54/250\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 55/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 56/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 57/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 58/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 59/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 60/250\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 61/250\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 62/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 63/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 64/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 65/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 66/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 67/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 68/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 69/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 70/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 71/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 72/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 73/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 74/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 75/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 77/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 78/250\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 79/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 80/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 81/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 82/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 83/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 84/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 85/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 86/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 87/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 88/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 89/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 90/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 91/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 92/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 93/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 94/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 95/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 96/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 97/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 98/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 99/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 100/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 101/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 102/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 103/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 104/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 105/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 106/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 107/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 108/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 109/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 110/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 111/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 112/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 113/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 114/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 115/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 116/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 117/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 118/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 119/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 120/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 121/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 122/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 123/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 124/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 125/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 126/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 127/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 128/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 129/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 130/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 131/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 132/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 133/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 134/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 135/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 136/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 137/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 138/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 139/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 140/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 141/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 142/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 143/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 144/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 145/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 146/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 147/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 148/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 149/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 150/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 151/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 152/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 153/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 154/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 155/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 156/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 157/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 158/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 159/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 160/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 161/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 162/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 163/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 164/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 165/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 166/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 167/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 168/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 169/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 170/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 171/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 172/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 173/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 174/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 175/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 176/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 177/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 178/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 179/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 180/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 181/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 182/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 183/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 184/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 185/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 186/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 187/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 188/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 189/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 190/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 191/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 192/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 193/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 194/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 195/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 196/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 197/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 198/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 199/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 200/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 201/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 202/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 203/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 204/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 205/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 206/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 207/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 208/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 209/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 210/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 211/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 212/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 213/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 214/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 215/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 216/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 217/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 218/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 219/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 220/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 221/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 222/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 223/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 224/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 225/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 226/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 227/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 228/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 229/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 230/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 231/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 232/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 233/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 234/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 235/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 236/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 237/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 238/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 239/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 240/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 241/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 242/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 243/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 244/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 245/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 246/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 247/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 248/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 249/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 250/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "20/20 [==============================] - 0s 991us/step\n",
      "Epoch 1/500\n",
      "63/63 [==============================] - 1s 4ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 2/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 3/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 4/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 5/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 6/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 7/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 8/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 9/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 10/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 11/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 12/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 13/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 14/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 15/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 16/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 17/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 18/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 19/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 20/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 21/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 22/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 23/500\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 24/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 25/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 26/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 27/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 28/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 29/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 30/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 31/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 32/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 33/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 34/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 35/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 36/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 37/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 38/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 39/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 40/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 41/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 42/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 43/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 44/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 45/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 46/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 47/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 48/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 49/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 50/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 51/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 52/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 53/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 54/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 55/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 56/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 57/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 58/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 59/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 60/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 61/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 62/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 63/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 64/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 65/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 66/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 67/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 68/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 69/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 70/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 71/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 72/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 73/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 74/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 75/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 76/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 77/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 78/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 79/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 80/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 81/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 82/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 83/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 84/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 85/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 86/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 87/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 88/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 89/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 90/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 91/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 92/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 93/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 94/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 95/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 96/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 97/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 98/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 99/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 100/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 101/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 102/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 103/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 104/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 105/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 106/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 107/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 108/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 109/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 110/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 111/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 113/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 114/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 115/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 116/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 117/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 118/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 119/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 120/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 121/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 122/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 123/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 124/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 125/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 126/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 127/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 128/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 129/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 130/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 131/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 132/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 133/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 134/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 135/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 136/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 137/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 138/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 139/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 140/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 141/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 142/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 143/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 144/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 145/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 146/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 147/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 148/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 149/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 150/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 151/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 152/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 153/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 154/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 155/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 156/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 157/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 158/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 159/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 160/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 161/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 162/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 163/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 164/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 165/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 166/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 167/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 168/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 169/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 170/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 171/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 172/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 173/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 174/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 175/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 176/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 177/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 178/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 179/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 180/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 181/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 182/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 183/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 184/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 185/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 186/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 187/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 188/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 189/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 190/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 191/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 192/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 193/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 194/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 195/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 196/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 197/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 198/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 199/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 200/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 201/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 202/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 203/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 204/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 205/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 206/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 207/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 208/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 209/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 210/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 211/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 212/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 213/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 214/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 215/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 216/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 217/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 218/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 219/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 220/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 221/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 222/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 223/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 224/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 225/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 226/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 227/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 228/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 229/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 230/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 231/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 232/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 233/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 234/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 235/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 236/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 237/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 238/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 239/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 240/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 241/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 242/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 243/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 244/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 245/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 246/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 247/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 248/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 249/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 250/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 251/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 252/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 253/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 254/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 255/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 256/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 257/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 258/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 259/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 260/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 261/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 262/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 263/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 264/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 265/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 266/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 267/500\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 268/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 269/500\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 270/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 271/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 272/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 273/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 274/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 275/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 276/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 277/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 278/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 279/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 280/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 281/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 282/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 283/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 284/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 285/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 286/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 287/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 288/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 289/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 290/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 291/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 292/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 293/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 294/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 295/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 296/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 297/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 298/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 299/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 300/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 301/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 302/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 303/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 304/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 305/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 306/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 307/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 308/500\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 309/500\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 310/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 311/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 312/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 313/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 314/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 315/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 316/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 317/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 318/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 319/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 320/500\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 321/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 322/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 323/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 324/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 325/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 326/500\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 327/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 328/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 329/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 330/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 331/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 332/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 333/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 334/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 335/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 336/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 337/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 338/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 339/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 340/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 341/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 342/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 343/500\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 344/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 345/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 346/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 347/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 348/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 349/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 350/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 351/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 352/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 353/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 354/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 355/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 356/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 357/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 358/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 359/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 360/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 361/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 362/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 363/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 364/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 365/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 366/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 367/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 368/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 369/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 370/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 371/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 372/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 373/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 374/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 375/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 376/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 377/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 378/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 379/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 380/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 381/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 382/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 383/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 384/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 385/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 386/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 387/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 388/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 389/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 390/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 391/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 392/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 393/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 394/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 395/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 396/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 397/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 398/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 399/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 400/500\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 401/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 402/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 403/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 404/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 405/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 406/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 407/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 408/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 409/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 410/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 411/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 412/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 413/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 414/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 415/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 416/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 417/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 418/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 419/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 420/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 421/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 422/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 423/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 424/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 425/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 426/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 427/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 428/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 429/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 430/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 431/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 432/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 433/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 434/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 435/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 436/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 437/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 438/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 439/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 440/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 441/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 442/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 443/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 444/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 445/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 446/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 447/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 448/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 449/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 450/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 451/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 452/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 453/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 454/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 455/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 456/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 457/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 458/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 459/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 460/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 461/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 462/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 463/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 464/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 465/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 466/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 467/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 468/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 469/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 470/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 471/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 472/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 473/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 474/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 475/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 476/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 477/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 478/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 479/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 480/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 481/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 482/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 483/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 484/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 485/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 486/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 487/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 488/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 489/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 490/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 491/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 492/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 493/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 494/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 495/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 496/500\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 497/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 498/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 499/500\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "Epoch 500/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.8452 - val_loss: 2.2648 - val_accuracy: 0.8532\n",
      "20/20 [==============================] - 0s 2ms/step\n",
      "Epoch 1/100\n",
      "63/63 [==============================] - 1s 4ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 2/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 3/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 4/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 5/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 6/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 7/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 8/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 9/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 10/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 11/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 12/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 13/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 14/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 15/100\n",
      "63/63 [==============================] - 0s 4ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 16/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 17/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 18/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 19/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 20/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 21/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 22/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 23/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 24/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 25/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 26/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 27/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 28/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 29/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 30/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 31/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 32/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 33/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 34/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 35/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 36/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 37/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 38/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 39/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 40/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 41/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "63/63 [==============================] - 0s 4ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "63/63 [==============================] - 0s 4ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "63/63 [==============================] - 0s 4ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "63/63 [==============================] - 0s 4ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "63/63 [==============================] - 0s 4ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "63/63 [==============================] - 0s 4ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "63/63 [==============================] - 0s 4ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "63/63 [==============================] - 0s 4ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "63/63 [==============================] - 0s 4ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "20/20 [==============================] - 0s 970us/step\n",
      "Epoch 1/250\n",
      "63/63 [==============================] - 1s 5ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 2/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 3/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 4/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 5/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 6/250\n",
      "63/63 [==============================] - 0s 4ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 7/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 8/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 9/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 10/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 11/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 13/250\n",
      "63/63 [==============================] - 0s 4ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 14/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 15/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 16/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 17/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 18/250\n",
      "63/63 [==============================] - 0s 4ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 19/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 20/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 21/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 22/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 23/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 24/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 25/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 26/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 27/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 28/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 29/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 30/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 31/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 32/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 33/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 34/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 35/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 36/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 37/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 38/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 39/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 40/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 41/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 42/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 43/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 44/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 45/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 46/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 47/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 48/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 49/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 50/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 51/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 52/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 53/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 54/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 55/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 56/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 57/250\n",
      "63/63 [==============================] - 0s 4ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 58/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 59/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 60/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 61/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 62/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 63/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 4ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 64/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 65/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 66/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 67/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 68/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 69/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 70/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 71/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 72/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 73/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 74/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 75/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 76/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 77/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 78/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 79/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 80/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 81/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 82/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 83/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 84/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 85/250\n",
      "63/63 [==============================] - 0s 4ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 86/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 87/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 88/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 89/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 90/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 91/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 92/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 93/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 94/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 95/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 96/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 97/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 98/250\n",
      "63/63 [==============================] - 0s 4ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 99/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 100/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 101/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 102/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 103/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 104/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 105/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 106/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 107/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 108/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 109/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 110/250\n",
      "63/63 [==============================] - 0s 4ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 111/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 112/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 113/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 114/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 115/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 116/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 117/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 118/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 119/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 120/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 121/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 122/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 123/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 124/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 125/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 126/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 127/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 128/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 129/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 130/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 131/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 132/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 133/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 134/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 135/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 136/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 137/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 138/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 139/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 140/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 141/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 142/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 143/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 144/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 145/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 146/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 147/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 148/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 149/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 150/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 151/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 152/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 153/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 154/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 155/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 156/250\n",
      "63/63 [==============================] - 0s 4ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 157/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 158/250\n",
      "63/63 [==============================] - 0s 4ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 159/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 160/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 161/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 162/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 163/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 164/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 165/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 166/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 167/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 168/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 169/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 170/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 171/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 172/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 173/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 174/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 175/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 176/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 177/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 178/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 179/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 180/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 181/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 182/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 183/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 184/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 185/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 186/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 187/250\n",
      "63/63 [==============================] - 0s 4ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 188/250\n",
      "63/63 [==============================] - 0s 4ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 189/250\n",
      "63/63 [==============================] - 0s 4ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 190/250\n",
      "63/63 [==============================] - 0s 4ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 191/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 192/250\n",
      "63/63 [==============================] - 0s 4ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 193/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 194/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 195/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 196/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 197/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 198/250\n",
      "63/63 [==============================] - 0s 4ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 199/250\n",
      "63/63 [==============================] - 0s 4ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 200/250\n",
      "63/63 [==============================] - 0s 4ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 201/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 202/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 203/250\n",
      "63/63 [==============================] - 0s 4ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 204/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 205/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 206/250\n",
      "63/63 [==============================] - 0s 4ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 207/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 208/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 209/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 210/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 211/250\n",
      "63/63 [==============================] - 0s 4ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 212/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 213/250\n",
      "63/63 [==============================] - 0s 4ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 214/250\n",
      "63/63 [==============================] - 0s 4ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 215/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 216/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 217/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 218/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 219/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 220/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 221/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 222/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 223/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 224/250\n",
      "63/63 [==============================] - 0s 4ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 225/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 226/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 227/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 228/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 229/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 230/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 231/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 232/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 233/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 234/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 235/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 236/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 237/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 238/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 239/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 240/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 241/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 242/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 243/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 244/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 245/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 246/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 247/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 248/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 249/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 250/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "20/20 [==============================] - 0s 980us/step\n",
      "Epoch 1/500\n",
      "63/63 [==============================] - 1s 5ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 2/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 3/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 4/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 5/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 6/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 7/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 8/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 9/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 10/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 11/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 12/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 13/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 14/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 15/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 16/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 18/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 19/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 20/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 21/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 22/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 23/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 24/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 25/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 26/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 27/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 28/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 29/500\n",
      "63/63 [==============================] - 0s 4ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 30/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 31/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 32/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 33/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 34/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 35/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 36/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 37/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 38/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 39/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 40/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 41/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 42/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 43/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 44/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 45/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 46/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 47/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 48/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 49/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 50/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 51/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 52/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 53/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 54/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 55/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 56/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 57/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 58/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 59/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 60/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 61/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 62/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 63/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 64/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 65/500\n",
      "63/63 [==============================] - 0s 4ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 66/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 67/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 68/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 69/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 70/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 71/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 72/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 73/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 74/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 75/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 76/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 77/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 78/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 79/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 80/500\n",
      "63/63 [==============================] - 0s 4ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 81/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 82/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 83/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 84/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 85/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 86/500\n",
      "63/63 [==============================] - 0s 4ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 87/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 88/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 89/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 90/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 91/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 92/500\n",
      "63/63 [==============================] - 0s 4ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 93/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 94/500\n",
      "63/63 [==============================] - 0s 4ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 95/500\n",
      "63/63 [==============================] - 0s 4ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 96/500\n",
      "63/63 [==============================] - 0s 5ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 97/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 98/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 99/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 100/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 101/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 102/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 103/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 104/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 105/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 106/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 107/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 108/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 109/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 110/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 111/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 112/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 113/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 114/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 115/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 116/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 117/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 118/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 119/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 120/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 121/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 122/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 123/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 124/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 125/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 126/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 127/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 128/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 129/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 130/500\n",
      "63/63 [==============================] - 0s 4ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 131/500\n",
      "63/63 [==============================] - 0s 4ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 132/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 133/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 134/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 135/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 136/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 137/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 138/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 139/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 140/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 141/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 142/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 143/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 144/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 145/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 146/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 147/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 148/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 149/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 150/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 151/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 152/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 153/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 154/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 155/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 156/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 157/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 158/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 159/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 160/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 161/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 162/500\n",
      "63/63 [==============================] - 0s 4ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 163/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 164/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 165/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 166/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 167/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 168/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 169/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 170/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 171/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 172/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 173/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 174/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 175/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 176/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 177/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 178/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 179/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 180/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 181/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 182/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 183/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 184/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 185/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 186/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 187/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 188/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 189/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 190/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 191/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 192/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 193/500\n",
      "63/63 [==============================] - 0s 4ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 194/500\n",
      "63/63 [==============================] - 0s 4ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 195/500\n",
      "63/63 [==============================] - 0s 4ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 196/500\n",
      "63/63 [==============================] - 0s 4ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 197/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 198/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 199/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 200/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 201/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 202/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 203/500\n",
      "63/63 [==============================] - 0s 4ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 204/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 205/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 206/500\n",
      "63/63 [==============================] - 0s 4ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 207/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 208/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 209/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 210/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 211/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 212/500\n",
      "63/63 [==============================] - 0s 4ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 213/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 214/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 215/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 216/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 217/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 218/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 219/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 220/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 221/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 222/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 223/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 224/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 225/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 226/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 227/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 228/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 229/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 230/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 231/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 232/500\n",
      "63/63 [==============================] - 0s 4ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 233/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 234/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 235/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 236/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 237/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 238/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 239/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 240/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 241/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 242/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 243/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 244/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 245/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 246/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 247/500\n",
      "63/63 [==============================] - 0s 4ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 248/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 249/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 250/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 251/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 252/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 253/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 254/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 255/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 256/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 257/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 258/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 259/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 260/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 261/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 262/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 263/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 264/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 265/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 266/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 267/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 268/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 269/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 270/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 271/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 272/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 273/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 274/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 275/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 276/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 277/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 278/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 279/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 280/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 281/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 282/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 283/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 284/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 285/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 286/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 287/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 288/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 289/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 290/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 291/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 292/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 293/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 294/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 295/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 296/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 297/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 298/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 299/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 300/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 301/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 302/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 303/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 304/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 305/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 306/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 307/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 308/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 309/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 310/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 311/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 312/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 313/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 314/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 315/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 316/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 317/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 318/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 319/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 320/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 321/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 322/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 323/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 324/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 325/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 326/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 327/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 328/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 329/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 330/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 331/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 332/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 333/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 334/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 335/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 336/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 337/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 338/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 339/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 340/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 341/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 342/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 343/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 344/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 345/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 346/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 347/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 348/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 349/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 350/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 351/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 352/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 353/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 354/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 355/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 356/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 357/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 358/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 359/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 360/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 361/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 362/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 363/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 364/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 365/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 366/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 367/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 368/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 369/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 370/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 371/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 372/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 373/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 374/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 375/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 376/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 377/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 378/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 379/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 380/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 381/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 382/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 383/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 384/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 385/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 386/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 387/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 388/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 389/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 390/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 391/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 392/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 393/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 394/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 395/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 396/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 397/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 398/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 399/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 400/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 401/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 402/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 403/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 404/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 405/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 406/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 407/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 408/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 409/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 410/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 411/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 412/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 413/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 414/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 415/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 416/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 417/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 418/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 419/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 420/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 421/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 422/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 423/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 424/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 425/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 426/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 427/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 428/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 429/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 430/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 431/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 432/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 433/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 434/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 435/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 436/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 437/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 438/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 439/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 440/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 441/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 442/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 443/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 444/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 445/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 446/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 447/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 448/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 449/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 450/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 451/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 452/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 453/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 454/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 455/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 456/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 457/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 458/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 459/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 460/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 461/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 462/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 463/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 464/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 465/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 466/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 467/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 468/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 469/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 470/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 471/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 472/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 473/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 474/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 475/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 476/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 477/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 478/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 479/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 480/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 481/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 482/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 483/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 484/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 485/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 486/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 487/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 488/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 489/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 490/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 491/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 492/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 493/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 494/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 495/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 496/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 497/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 498/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 499/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "Epoch 500/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: nan - categorical_accuracy: 1.0000 - val_loss: nan - val_categorical_accuracy: 1.0000\n",
      "20/20 [==============================] - 0s 1ms/step\n",
      "Epoch 1/100\n",
      "63/63 [==============================] - 1s 4ms/step - loss: 2.6735 - accuracy: 0.5918 - val_loss: 2.0548 - val_accuracy: 0.6667\n",
      "Epoch 2/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8685 - accuracy: 0.6657 - val_loss: 1.7044 - val_accuracy: 0.7004\n",
      "Epoch 3/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.6136 - accuracy: 0.6949 - val_loss: 1.5230 - val_accuracy: 0.7202\n",
      "Epoch 4/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.4717 - accuracy: 0.7148 - val_loss: 1.4293 - val_accuracy: 0.7302\n",
      "Epoch 5/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.3828 - accuracy: 0.7302 - val_loss: 1.3832 - val_accuracy: 0.7381\n",
      "Epoch 6/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.3088 - accuracy: 0.7386 - val_loss: 1.3540 - val_accuracy: 0.7560\n",
      "Epoch 7/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.2701 - accuracy: 0.7515 - val_loss: 1.3568 - val_accuracy: 0.7619\n",
      "Epoch 8/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.1929 - accuracy: 0.7579 - val_loss: 1.2646 - val_accuracy: 0.7659\n",
      "Epoch 9/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.1393 - accuracy: 0.7718 - val_loss: 1.2245 - val_accuracy: 0.7698\n",
      "Epoch 10/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.1111 - accuracy: 0.7793 - val_loss: 1.2110 - val_accuracy: 0.7778\n",
      "Epoch 11/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.0994 - accuracy: 0.7847 - val_loss: 1.2024 - val_accuracy: 0.7798\n",
      "Epoch 12/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.0690 - accuracy: 0.7907 - val_loss: 1.1701 - val_accuracy: 0.7798\n",
      "Epoch 13/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.0566 - accuracy: 0.7937 - val_loss: 1.1386 - val_accuracy: 0.7837\n",
      "Epoch 14/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.0444 - accuracy: 0.7966 - val_loss: 1.1294 - val_accuracy: 0.7897\n",
      "Epoch 15/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.0143 - accuracy: 0.7996 - val_loss: 1.0996 - val_accuracy: 0.7956\n",
      "Epoch 16/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9928 - accuracy: 0.8051 - val_loss: 1.0679 - val_accuracy: 0.8016\n",
      "Epoch 17/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.9755 - accuracy: 0.8065 - val_loss: 1.0605 - val_accuracy: 0.7996\n",
      "Epoch 18/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.9612 - accuracy: 0.8085 - val_loss: 1.0547 - val_accuracy: 0.8016\n",
      "Epoch 19/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9555 - accuracy: 0.8100 - val_loss: 1.0503 - val_accuracy: 0.8016\n",
      "Epoch 20/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9455 - accuracy: 0.8125 - val_loss: 1.0285 - val_accuracy: 0.8036\n",
      "Epoch 21/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9407 - accuracy: 0.8140 - val_loss: 1.0034 - val_accuracy: 0.8056\n",
      "Epoch 22/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9367 - accuracy: 0.8140 - val_loss: 0.9984 - val_accuracy: 0.8056\n",
      "Epoch 23/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9271 - accuracy: 0.8160 - val_loss: 0.9936 - val_accuracy: 0.8075\n",
      "Epoch 24/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9228 - accuracy: 0.8175 - val_loss: 0.9901 - val_accuracy: 0.8075\n",
      "Epoch 25/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9195 - accuracy: 0.8185 - val_loss: 0.9869 - val_accuracy: 0.8115\n",
      "Epoch 26/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9165 - accuracy: 0.8209 - val_loss: 0.9841 - val_accuracy: 0.8155\n",
      "Epoch 27/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9086 - accuracy: 0.8214 - val_loss: 0.9808 - val_accuracy: 0.8155\n",
      "Epoch 28/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8995 - accuracy: 0.8229 - val_loss: 0.9609 - val_accuracy: 0.8175\n",
      "Epoch 29/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8901 - accuracy: 0.8234 - val_loss: 0.9510 - val_accuracy: 0.8175\n",
      "Epoch 30/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8864 - accuracy: 0.8239 - val_loss: 0.9477 - val_accuracy: 0.8175\n",
      "Epoch 31/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8730 - accuracy: 0.8254 - val_loss: 0.9214 - val_accuracy: 0.8194\n",
      "Epoch 32/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8684 - accuracy: 0.8254 - val_loss: 0.9187 - val_accuracy: 0.8194\n",
      "Epoch 33/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8486 - accuracy: 0.8254 - val_loss: 0.9139 - val_accuracy: 0.8214\n",
      "Epoch 34/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8438 - accuracy: 0.8254 - val_loss: 0.9119 - val_accuracy: 0.8214\n",
      "Epoch 35/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8318 - accuracy: 0.8274 - val_loss: 0.8644 - val_accuracy: 0.8234\n",
      "Epoch 36/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8255 - accuracy: 0.8299 - val_loss: 0.8635 - val_accuracy: 0.8234\n",
      "Epoch 37/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8238 - accuracy: 0.8289 - val_loss: 0.8628 - val_accuracy: 0.8234\n",
      "Epoch 38/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8223 - accuracy: 0.8304 - val_loss: 0.8623 - val_accuracy: 0.8214\n",
      "Epoch 39/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8209 - accuracy: 0.8304 - val_loss: 0.8622 - val_accuracy: 0.8214\n",
      "Epoch 40/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8195 - accuracy: 0.8318 - val_loss: 0.8627 - val_accuracy: 0.8234\n",
      "Epoch 41/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8183 - accuracy: 0.8318 - val_loss: 0.8786 - val_accuracy: 0.8234\n",
      "Epoch 42/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8170 - accuracy: 0.8328 - val_loss: 0.8777 - val_accuracy: 0.8234\n",
      "Epoch 43/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8159 - accuracy: 0.8323 - val_loss: 0.8769 - val_accuracy: 0.8254\n",
      "Epoch 44/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8148 - accuracy: 0.8323 - val_loss: 0.8761 - val_accuracy: 0.8254\n",
      "Epoch 45/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8137 - accuracy: 0.8333 - val_loss: 0.8753 - val_accuracy: 0.8254\n",
      "Epoch 46/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8127 - accuracy: 0.8333 - val_loss: 0.8747 - val_accuracy: 0.8254\n",
      "Epoch 47/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8117 - accuracy: 0.8333 - val_loss: 0.8740 - val_accuracy: 0.8254\n",
      "Epoch 48/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8108 - accuracy: 0.8348 - val_loss: 0.8734 - val_accuracy: 0.8274\n",
      "Epoch 49/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8099 - accuracy: 0.8358 - val_loss: 0.8728 - val_accuracy: 0.8274\n",
      "Epoch 50/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8091 - accuracy: 0.8363 - val_loss: 0.8722 - val_accuracy: 0.8294\n",
      "Epoch 51/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8082 - accuracy: 0.8368 - val_loss: 0.8717 - val_accuracy: 0.8294\n",
      "Epoch 52/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8074 - accuracy: 0.8373 - val_loss: 0.8711 - val_accuracy: 0.8294\n",
      "Epoch 53/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8066 - accuracy: 0.8378 - val_loss: 0.8706 - val_accuracy: 0.8294\n",
      "Epoch 54/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8058 - accuracy: 0.8388 - val_loss: 0.8700 - val_accuracy: 0.8313\n",
      "Epoch 55/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8051 - accuracy: 0.8398 - val_loss: 0.8695 - val_accuracy: 0.8333\n",
      "Epoch 56/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8043 - accuracy: 0.8398 - val_loss: 0.8691 - val_accuracy: 0.8333\n",
      "Epoch 57/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8036 - accuracy: 0.8403 - val_loss: 0.8686 - val_accuracy: 0.8333\n",
      "Epoch 58/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8030 - accuracy: 0.8403 - val_loss: 0.8682 - val_accuracy: 0.8353\n",
      "Epoch 59/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8023 - accuracy: 0.8398 - val_loss: 0.8527 - val_accuracy: 0.8333\n",
      "Epoch 60/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8017 - accuracy: 0.8403 - val_loss: 0.8502 - val_accuracy: 0.8333\n",
      "Epoch 61/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8010 - accuracy: 0.8408 - val_loss: 0.8487 - val_accuracy: 0.8333\n",
      "Epoch 62/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8004 - accuracy: 0.8408 - val_loss: 0.8477 - val_accuracy: 0.8333\n",
      "Epoch 63/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.7998 - accuracy: 0.8413 - val_loss: 0.8468 - val_accuracy: 0.8333\n",
      "Epoch 64/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.7992 - accuracy: 0.8413 - val_loss: 0.8461 - val_accuracy: 0.8333\n",
      "Epoch 65/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.7986 - accuracy: 0.8418 - val_loss: 0.8453 - val_accuracy: 0.8333\n",
      "Epoch 66/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.7980 - accuracy: 0.8418 - val_loss: 0.8446 - val_accuracy: 0.8333\n",
      "Epoch 67/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.7975 - accuracy: 0.8433 - val_loss: 0.8439 - val_accuracy: 0.8333\n",
      "Epoch 68/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.7969 - accuracy: 0.8442 - val_loss: 0.8434 - val_accuracy: 0.8353\n",
      "Epoch 69/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.7964 - accuracy: 0.8457 - val_loss: 0.8428 - val_accuracy: 0.8353\n",
      "Epoch 70/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.7959 - accuracy: 0.8452 - val_loss: 0.8423 - val_accuracy: 0.8353\n",
      "Epoch 71/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.7954 - accuracy: 0.8452 - val_loss: 0.8418 - val_accuracy: 0.8353\n",
      "Epoch 72/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.7949 - accuracy: 0.8462 - val_loss: 0.8413 - val_accuracy: 0.8353\n",
      "Epoch 73/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.7944 - accuracy: 0.8462 - val_loss: 0.8409 - val_accuracy: 0.8353\n",
      "Epoch 74/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.7939 - accuracy: 0.8467 - val_loss: 0.8404 - val_accuracy: 0.8353\n",
      "Epoch 75/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.7934 - accuracy: 0.8467 - val_loss: 0.8400 - val_accuracy: 0.8373\n",
      "Epoch 76/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.7930 - accuracy: 0.8482 - val_loss: 0.8395 - val_accuracy: 0.8373\n",
      "Epoch 77/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.7925 - accuracy: 0.8477 - val_loss: 0.8391 - val_accuracy: 0.8373\n",
      "Epoch 78/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.7921 - accuracy: 0.8482 - val_loss: 0.8387 - val_accuracy: 0.8373\n",
      "Epoch 79/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.7917 - accuracy: 0.8492 - val_loss: 0.8383 - val_accuracy: 0.8373\n",
      "Epoch 80/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.7912 - accuracy: 0.8492 - val_loss: 0.8378 - val_accuracy: 0.8373\n",
      "Epoch 81/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.7908 - accuracy: 0.8492 - val_loss: 0.8374 - val_accuracy: 0.8373\n",
      "Epoch 82/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.7904 - accuracy: 0.8497 - val_loss: 0.8370 - val_accuracy: 0.8373\n",
      "Epoch 83/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.7900 - accuracy: 0.8497 - val_loss: 0.8366 - val_accuracy: 0.8373\n",
      "Epoch 84/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.7896 - accuracy: 0.8497 - val_loss: 0.8363 - val_accuracy: 0.8373\n",
      "Epoch 85/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.7892 - accuracy: 0.8507 - val_loss: 0.8359 - val_accuracy: 0.8373\n",
      "Epoch 86/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.7889 - accuracy: 0.8507 - val_loss: 0.8355 - val_accuracy: 0.8373\n",
      "Epoch 87/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.7885 - accuracy: 0.8507 - val_loss: 0.8351 - val_accuracy: 0.8373\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.7881 - accuracy: 0.8507 - val_loss: 0.8347 - val_accuracy: 0.8373\n",
      "Epoch 89/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.7878 - accuracy: 0.8507 - val_loss: 0.8344 - val_accuracy: 0.8373\n",
      "Epoch 90/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.7874 - accuracy: 0.8502 - val_loss: 0.8340 - val_accuracy: 0.8373\n",
      "Epoch 91/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.7826 - accuracy: 0.8502 - val_loss: 0.8313 - val_accuracy: 0.8393\n",
      "Epoch 92/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.7808 - accuracy: 0.8512 - val_loss: 0.8309 - val_accuracy: 0.8393\n",
      "Epoch 93/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.7804 - accuracy: 0.8512 - val_loss: 0.8305 - val_accuracy: 0.8413\n",
      "Epoch 94/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.7800 - accuracy: 0.8502 - val_loss: 0.8301 - val_accuracy: 0.8413\n",
      "Epoch 95/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7796 - accuracy: 0.8517 - val_loss: 0.8298 - val_accuracy: 0.8452\n",
      "Epoch 96/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.7792 - accuracy: 0.8527 - val_loss: 0.8294 - val_accuracy: 0.8452\n",
      "Epoch 97/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.7788 - accuracy: 0.8527 - val_loss: 0.8291 - val_accuracy: 0.8452\n",
      "Epoch 98/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.7785 - accuracy: 0.8532 - val_loss: 0.8288 - val_accuracy: 0.8452\n",
      "Epoch 99/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.7781 - accuracy: 0.8527 - val_loss: 0.8285 - val_accuracy: 0.8452\n",
      "Epoch 100/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7778 - accuracy: 0.8532 - val_loss: 0.8282 - val_accuracy: 0.8452\n",
      "20/20 [==============================] - 0s 2ms/step\n",
      "Epoch 1/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7742 - accuracy: 0.8616 - val_loss: 0.7978 - val_accuracy: 0.8532\n",
      "Epoch 2/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.7518 - accuracy: 0.8710 - val_loss: 0.8104 - val_accuracy: 0.8532\n",
      "Epoch 3/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.7427 - accuracy: 0.8725 - val_loss: 0.7887 - val_accuracy: 0.8571\n",
      "Epoch 4/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.7387 - accuracy: 0.8725 - val_loss: 0.8059 - val_accuracy: 0.8611\n",
      "Epoch 5/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.7364 - accuracy: 0.8745 - val_loss: 0.8031 - val_accuracy: 0.8611\n",
      "Epoch 6/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.7295 - accuracy: 0.8770 - val_loss: 0.7991 - val_accuracy: 0.8611\n",
      "Epoch 7/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.7272 - accuracy: 0.8780 - val_loss: 0.7985 - val_accuracy: 0.8611\n",
      "Epoch 8/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.7262 - accuracy: 0.8800 - val_loss: 0.7979 - val_accuracy: 0.8671\n",
      "Epoch 9/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.7252 - accuracy: 0.8805 - val_loss: 0.7973 - val_accuracy: 0.8671\n",
      "Epoch 10/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.7243 - accuracy: 0.8829 - val_loss: 0.7965 - val_accuracy: 0.8671\n",
      "Epoch 11/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.7236 - accuracy: 0.8824 - val_loss: 0.7961 - val_accuracy: 0.8671\n",
      "Epoch 12/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.7228 - accuracy: 0.8819 - val_loss: 0.7956 - val_accuracy: 0.8671\n",
      "Epoch 13/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.7221 - accuracy: 0.8824 - val_loss: 0.7951 - val_accuracy: 0.8671\n",
      "Epoch 14/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7215 - accuracy: 0.8829 - val_loss: 0.7790 - val_accuracy: 0.8671\n",
      "Epoch 15/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.7209 - accuracy: 0.8839 - val_loss: 0.7771 - val_accuracy: 0.8690\n",
      "Epoch 16/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.7202 - accuracy: 0.8849 - val_loss: 0.7751 - val_accuracy: 0.8690\n",
      "Epoch 17/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.7197 - accuracy: 0.8844 - val_loss: 0.7746 - val_accuracy: 0.8690\n",
      "Epoch 18/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.7192 - accuracy: 0.8849 - val_loss: 0.7733 - val_accuracy: 0.8690\n",
      "Epoch 19/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.7187 - accuracy: 0.8849 - val_loss: 0.7723 - val_accuracy: 0.8710\n",
      "Epoch 20/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.7182 - accuracy: 0.8854 - val_loss: 0.7719 - val_accuracy: 0.8710\n",
      "Epoch 21/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.7178 - accuracy: 0.8854 - val_loss: 0.7711 - val_accuracy: 0.8710\n",
      "Epoch 22/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7174 - accuracy: 0.8864 - val_loss: 0.7704 - val_accuracy: 0.8730\n",
      "Epoch 23/250\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.7170 - accuracy: 0.8864 - val_loss: 0.7700 - val_accuracy: 0.8730\n",
      "Epoch 24/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7165 - accuracy: 0.8874 - val_loss: 0.7695 - val_accuracy: 0.8730\n",
      "Epoch 25/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7161 - accuracy: 0.8869 - val_loss: 0.7689 - val_accuracy: 0.8730\n",
      "Epoch 26/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.7158 - accuracy: 0.8864 - val_loss: 0.7686 - val_accuracy: 0.8730\n",
      "Epoch 27/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.7155 - accuracy: 0.8874 - val_loss: 0.7682 - val_accuracy: 0.8730\n",
      "Epoch 28/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.7113 - accuracy: 0.8879 - val_loss: 0.7399 - val_accuracy: 0.8690\n",
      "Epoch 29/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.7090 - accuracy: 0.8864 - val_loss: 0.7401 - val_accuracy: 0.8690\n",
      "Epoch 30/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.7087 - accuracy: 0.8874 - val_loss: 0.7404 - val_accuracy: 0.8690\n",
      "Epoch 31/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7085 - accuracy: 0.8874 - val_loss: 0.7406 - val_accuracy: 0.8710\n",
      "Epoch 32/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7082 - accuracy: 0.8869 - val_loss: 0.7408 - val_accuracy: 0.8710\n",
      "Epoch 33/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7080 - accuracy: 0.8869 - val_loss: 0.7411 - val_accuracy: 0.8710\n",
      "Epoch 34/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7077 - accuracy: 0.8869 - val_loss: 0.7414 - val_accuracy: 0.8710\n",
      "Epoch 35/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7075 - accuracy: 0.8869 - val_loss: 0.7417 - val_accuracy: 0.8730\n",
      "Epoch 36/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.7073 - accuracy: 0.8874 - val_loss: 0.7419 - val_accuracy: 0.8730\n",
      "Epoch 37/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7071 - accuracy: 0.8869 - val_loss: 0.7270 - val_accuracy: 0.8730\n",
      "Epoch 38/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.7069 - accuracy: 0.8869 - val_loss: 0.7261 - val_accuracy: 0.8730\n",
      "Epoch 39/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.7067 - accuracy: 0.8864 - val_loss: 0.7257 - val_accuracy: 0.8730\n",
      "Epoch 40/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.7065 - accuracy: 0.8859 - val_loss: 0.7257 - val_accuracy: 0.8730\n",
      "Epoch 41/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.7064 - accuracy: 0.8869 - val_loss: 0.7258 - val_accuracy: 0.8730\n",
      "Epoch 42/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.7062 - accuracy: 0.8869 - val_loss: 0.7260 - val_accuracy: 0.8730\n",
      "Epoch 43/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7060 - accuracy: 0.8869 - val_loss: 0.7266 - val_accuracy: 0.8730\n",
      "Epoch 44/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.7059 - accuracy: 0.8869 - val_loss: 0.7274 - val_accuracy: 0.8730\n",
      "Epoch 45/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 2ms/step - loss: 0.7057 - accuracy: 0.8874 - val_loss: 0.7305 - val_accuracy: 0.8730\n",
      "Epoch 46/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.7056 - accuracy: 0.8874 - val_loss: 0.7407 - val_accuracy: 0.8750\n",
      "Epoch 47/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.7054 - accuracy: 0.8874 - val_loss: 0.7404 - val_accuracy: 0.8750\n",
      "Epoch 48/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.7053 - accuracy: 0.8874 - val_loss: 0.7402 - val_accuracy: 0.8750\n",
      "Epoch 49/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7051 - accuracy: 0.8874 - val_loss: 0.7400 - val_accuracy: 0.8750\n",
      "Epoch 50/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.7050 - accuracy: 0.8874 - val_loss: 0.7398 - val_accuracy: 0.8750\n",
      "Epoch 51/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.7048 - accuracy: 0.8874 - val_loss: 0.7397 - val_accuracy: 0.8750\n",
      "Epoch 52/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.7047 - accuracy: 0.8874 - val_loss: 0.7395 - val_accuracy: 0.8750\n",
      "Epoch 53/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.7046 - accuracy: 0.8874 - val_loss: 0.7393 - val_accuracy: 0.8750\n",
      "Epoch 54/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.7044 - accuracy: 0.8874 - val_loss: 0.7392 - val_accuracy: 0.8750\n",
      "Epoch 55/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.7043 - accuracy: 0.8874 - val_loss: 0.7390 - val_accuracy: 0.8750\n",
      "Epoch 56/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.7042 - accuracy: 0.8869 - val_loss: 0.7389 - val_accuracy: 0.8750\n",
      "Epoch 57/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.7041 - accuracy: 0.8874 - val_loss: 0.7387 - val_accuracy: 0.8750\n",
      "Epoch 58/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.7039 - accuracy: 0.8874 - val_loss: 0.7386 - val_accuracy: 0.8750\n",
      "Epoch 59/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.7038 - accuracy: 0.8874 - val_loss: 0.7385 - val_accuracy: 0.8750\n",
      "Epoch 60/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7037 - accuracy: 0.8874 - val_loss: 0.7384 - val_accuracy: 0.8750\n",
      "Epoch 61/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.7036 - accuracy: 0.8874 - val_loss: 0.7382 - val_accuracy: 0.8750\n",
      "Epoch 62/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.7035 - accuracy: 0.8874 - val_loss: 0.7381 - val_accuracy: 0.8750\n",
      "Epoch 63/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.7033 - accuracy: 0.8874 - val_loss: 0.7380 - val_accuracy: 0.8750\n",
      "Epoch 64/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.7032 - accuracy: 0.8879 - val_loss: 0.7379 - val_accuracy: 0.8750\n",
      "Epoch 65/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.7031 - accuracy: 0.8879 - val_loss: 0.7378 - val_accuracy: 0.8750\n",
      "Epoch 66/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.7030 - accuracy: 0.8884 - val_loss: 0.7376 - val_accuracy: 0.8750\n",
      "Epoch 67/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.7029 - accuracy: 0.8879 - val_loss: 0.7374 - val_accuracy: 0.8750\n",
      "Epoch 68/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.7027 - accuracy: 0.8884 - val_loss: 0.7372 - val_accuracy: 0.8750\n",
      "Epoch 69/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.7026 - accuracy: 0.8884 - val_loss: 0.7370 - val_accuracy: 0.8750\n",
      "Epoch 70/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.7025 - accuracy: 0.8884 - val_loss: 0.7368 - val_accuracy: 0.8750\n",
      "Epoch 71/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.7023 - accuracy: 0.8889 - val_loss: 0.7367 - val_accuracy: 0.8750\n",
      "Epoch 72/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.7022 - accuracy: 0.8889 - val_loss: 0.7365 - val_accuracy: 0.8750\n",
      "Epoch 73/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.7021 - accuracy: 0.8894 - val_loss: 0.7364 - val_accuracy: 0.8750\n",
      "Epoch 74/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.7019 - accuracy: 0.8899 - val_loss: 0.7362 - val_accuracy: 0.8750\n",
      "Epoch 75/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.7018 - accuracy: 0.8899 - val_loss: 0.7360 - val_accuracy: 0.8750\n",
      "Epoch 76/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.7017 - accuracy: 0.8899 - val_loss: 0.7359 - val_accuracy: 0.8750\n",
      "Epoch 77/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.7016 - accuracy: 0.8899 - val_loss: 0.7357 - val_accuracy: 0.8750\n",
      "Epoch 78/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.7015 - accuracy: 0.8899 - val_loss: 0.7356 - val_accuracy: 0.8750\n",
      "Epoch 79/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.7014 - accuracy: 0.8899 - val_loss: 0.7354 - val_accuracy: 0.8750\n",
      "Epoch 80/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.7012 - accuracy: 0.8899 - val_loss: 0.7353 - val_accuracy: 0.8750\n",
      "Epoch 81/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.7011 - accuracy: 0.8904 - val_loss: 0.7352 - val_accuracy: 0.8750\n",
      "Epoch 82/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.7010 - accuracy: 0.8904 - val_loss: 0.7350 - val_accuracy: 0.8750\n",
      "Epoch 83/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.7009 - accuracy: 0.8904 - val_loss: 0.7349 - val_accuracy: 0.8750\n",
      "Epoch 84/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.7008 - accuracy: 0.8909 - val_loss: 0.7348 - val_accuracy: 0.8770\n",
      "Epoch 85/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.7007 - accuracy: 0.8909 - val_loss: 0.7346 - val_accuracy: 0.8790\n",
      "Epoch 86/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.7006 - accuracy: 0.8899 - val_loss: 0.7345 - val_accuracy: 0.8790\n",
      "Epoch 87/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.7005 - accuracy: 0.8904 - val_loss: 0.7344 - val_accuracy: 0.8790\n",
      "Epoch 88/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.7004 - accuracy: 0.8904 - val_loss: 0.7343 - val_accuracy: 0.8810\n",
      "Epoch 89/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.7003 - accuracy: 0.8899 - val_loss: 0.7341 - val_accuracy: 0.8810\n",
      "Epoch 90/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.7002 - accuracy: 0.8899 - val_loss: 0.7340 - val_accuracy: 0.8810\n",
      "Epoch 91/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.7001 - accuracy: 0.8904 - val_loss: 0.7339 - val_accuracy: 0.8810\n",
      "Epoch 92/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.7000 - accuracy: 0.8904 - val_loss: 0.7338 - val_accuracy: 0.8810\n",
      "Epoch 93/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6999 - accuracy: 0.8904 - val_loss: 0.7337 - val_accuracy: 0.8810\n",
      "Epoch 94/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6998 - accuracy: 0.8904 - val_loss: 0.7336 - val_accuracy: 0.8810\n",
      "Epoch 95/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6997 - accuracy: 0.8904 - val_loss: 0.7335 - val_accuracy: 0.8810\n",
      "Epoch 96/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6996 - accuracy: 0.8904 - val_loss: 0.7334 - val_accuracy: 0.8810\n",
      "Epoch 97/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6995 - accuracy: 0.8904 - val_loss: 0.7332 - val_accuracy: 0.8810\n",
      "Epoch 98/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6994 - accuracy: 0.8899 - val_loss: 0.7332 - val_accuracy: 0.8810\n",
      "Epoch 99/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6993 - accuracy: 0.8909 - val_loss: 0.7331 - val_accuracy: 0.8810\n",
      "Epoch 100/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6992 - accuracy: 0.8904 - val_loss: 0.7329 - val_accuracy: 0.8810\n",
      "Epoch 101/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6991 - accuracy: 0.8909 - val_loss: 0.7329 - val_accuracy: 0.8810\n",
      "Epoch 102/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6991 - accuracy: 0.8909 - val_loss: 0.7328 - val_accuracy: 0.8810\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 103/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6990 - accuracy: 0.8904 - val_loss: 0.7327 - val_accuracy: 0.8810\n",
      "Epoch 104/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6989 - accuracy: 0.8909 - val_loss: 0.7326 - val_accuracy: 0.8810\n",
      "Epoch 105/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6988 - accuracy: 0.8909 - val_loss: 0.7240 - val_accuracy: 0.8810\n",
      "Epoch 106/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6987 - accuracy: 0.8914 - val_loss: 0.7200 - val_accuracy: 0.8829\n",
      "Epoch 107/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6986 - accuracy: 0.8914 - val_loss: 0.7185 - val_accuracy: 0.8849\n",
      "Epoch 108/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6986 - accuracy: 0.8909 - val_loss: 0.7179 - val_accuracy: 0.8849\n",
      "Epoch 109/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6985 - accuracy: 0.8914 - val_loss: 0.7171 - val_accuracy: 0.8849\n",
      "Epoch 110/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6984 - accuracy: 0.8914 - val_loss: 0.7166 - val_accuracy: 0.8849\n",
      "Epoch 111/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6983 - accuracy: 0.8914 - val_loss: 0.7162 - val_accuracy: 0.8849\n",
      "Epoch 112/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6982 - accuracy: 0.8914 - val_loss: 0.7158 - val_accuracy: 0.8849\n",
      "Epoch 113/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6982 - accuracy: 0.8914 - val_loss: 0.7155 - val_accuracy: 0.8849\n",
      "Epoch 114/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6981 - accuracy: 0.8914 - val_loss: 0.7153 - val_accuracy: 0.8849\n",
      "Epoch 115/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6980 - accuracy: 0.8914 - val_loss: 0.7150 - val_accuracy: 0.8849\n",
      "Epoch 116/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6979 - accuracy: 0.8919 - val_loss: 0.7147 - val_accuracy: 0.8869\n",
      "Epoch 117/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6979 - accuracy: 0.8919 - val_loss: 0.7145 - val_accuracy: 0.8869\n",
      "Epoch 118/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6978 - accuracy: 0.8919 - val_loss: 0.7141 - val_accuracy: 0.8869\n",
      "Epoch 119/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6977 - accuracy: 0.8919 - val_loss: 0.7138 - val_accuracy: 0.8869\n",
      "Epoch 120/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6976 - accuracy: 0.8919 - val_loss: 0.7136 - val_accuracy: 0.8869\n",
      "Epoch 121/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6976 - accuracy: 0.8924 - val_loss: 0.7134 - val_accuracy: 0.8869\n",
      "Epoch 122/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6975 - accuracy: 0.8919 - val_loss: 0.7132 - val_accuracy: 0.8869\n",
      "Epoch 123/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6974 - accuracy: 0.8924 - val_loss: 0.7130 - val_accuracy: 0.8869\n",
      "Epoch 124/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6973 - accuracy: 0.8924 - val_loss: 0.7128 - val_accuracy: 0.8869\n",
      "Epoch 125/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6973 - accuracy: 0.8924 - val_loss: 0.7126 - val_accuracy: 0.8869\n",
      "Epoch 126/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6972 - accuracy: 0.8929 - val_loss: 0.7125 - val_accuracy: 0.8869\n",
      "Epoch 127/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6971 - accuracy: 0.8924 - val_loss: 0.7124 - val_accuracy: 0.8869\n",
      "Epoch 128/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6971 - accuracy: 0.8929 - val_loss: 0.7123 - val_accuracy: 0.8869\n",
      "Epoch 129/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6970 - accuracy: 0.8934 - val_loss: 0.7121 - val_accuracy: 0.8869\n",
      "Epoch 130/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6969 - accuracy: 0.8934 - val_loss: 0.7119 - val_accuracy: 0.8869\n",
      "Epoch 131/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6968 - accuracy: 0.8938 - val_loss: 0.7118 - val_accuracy: 0.8869\n",
      "Epoch 132/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6968 - accuracy: 0.8938 - val_loss: 0.7116 - val_accuracy: 0.8869\n",
      "Epoch 133/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6967 - accuracy: 0.8938 - val_loss: 0.7114 - val_accuracy: 0.8869\n",
      "Epoch 134/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6966 - accuracy: 0.8938 - val_loss: 0.7113 - val_accuracy: 0.8869\n",
      "Epoch 135/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6966 - accuracy: 0.8938 - val_loss: 0.7112 - val_accuracy: 0.8869\n",
      "Epoch 136/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6965 - accuracy: 0.8938 - val_loss: 0.7111 - val_accuracy: 0.8869\n",
      "Epoch 137/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6964 - accuracy: 0.8938 - val_loss: 0.7109 - val_accuracy: 0.8869\n",
      "Epoch 138/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6964 - accuracy: 0.8929 - val_loss: 0.7108 - val_accuracy: 0.8869\n",
      "Epoch 139/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6963 - accuracy: 0.8938 - val_loss: 0.7107 - val_accuracy: 0.8869\n",
      "Epoch 140/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6962 - accuracy: 0.8943 - val_loss: 0.7106 - val_accuracy: 0.8869\n",
      "Epoch 141/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6961 - accuracy: 0.8943 - val_loss: 0.7105 - val_accuracy: 0.8869\n",
      "Epoch 142/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6961 - accuracy: 0.8943 - val_loss: 0.7104 - val_accuracy: 0.8889\n",
      "Epoch 143/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6960 - accuracy: 0.8943 - val_loss: 0.7102 - val_accuracy: 0.8889\n",
      "Epoch 144/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6960 - accuracy: 0.8943 - val_loss: 0.7102 - val_accuracy: 0.8889\n",
      "Epoch 145/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6959 - accuracy: 0.8943 - val_loss: 0.7101 - val_accuracy: 0.8889\n",
      "Epoch 146/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6958 - accuracy: 0.8943 - val_loss: 0.7100 - val_accuracy: 0.8889\n",
      "Epoch 147/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6958 - accuracy: 0.8943 - val_loss: 0.7099 - val_accuracy: 0.8889\n",
      "Epoch 148/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6957 - accuracy: 0.8938 - val_loss: 0.7098 - val_accuracy: 0.8889\n",
      "Epoch 149/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6956 - accuracy: 0.8943 - val_loss: 0.7097 - val_accuracy: 0.8889\n",
      "Epoch 150/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6956 - accuracy: 0.8943 - val_loss: 0.7096 - val_accuracy: 0.8889\n",
      "Epoch 151/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6955 - accuracy: 0.8943 - val_loss: 0.7095 - val_accuracy: 0.8889\n",
      "Epoch 152/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6954 - accuracy: 0.8938 - val_loss: 0.7094 - val_accuracy: 0.8889\n",
      "Epoch 153/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6954 - accuracy: 0.8943 - val_loss: 0.7094 - val_accuracy: 0.8889\n",
      "Epoch 154/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6953 - accuracy: 0.8943 - val_loss: 0.7093 - val_accuracy: 0.8889\n",
      "Epoch 155/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6953 - accuracy: 0.8943 - val_loss: 0.7091 - val_accuracy: 0.8889\n",
      "Epoch 156/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6952 - accuracy: 0.8943 - val_loss: 0.7090 - val_accuracy: 0.8889\n",
      "Epoch 157/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6951 - accuracy: 0.8943 - val_loss: 0.7089 - val_accuracy: 0.8889\n",
      "Epoch 158/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6951 - accuracy: 0.8943 - val_loss: 0.7088 - val_accuracy: 0.8889\n",
      "Epoch 159/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6950 - accuracy: 0.8943 - val_loss: 0.7088 - val_accuracy: 0.8889\n",
      "Epoch 160/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6950 - accuracy: 0.8943 - val_loss: 0.7087 - val_accuracy: 0.8889\n",
      "Epoch 161/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6949 - accuracy: 0.8948 - val_loss: 0.7086 - val_accuracy: 0.8889\n",
      "Epoch 162/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6949 - accuracy: 0.8943 - val_loss: 0.7085 - val_accuracy: 0.8889\n",
      "Epoch 163/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6948 - accuracy: 0.8943 - val_loss: 0.7085 - val_accuracy: 0.8889\n",
      "Epoch 164/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6947 - accuracy: 0.8943 - val_loss: 0.7084 - val_accuracy: 0.8889\n",
      "Epoch 165/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6947 - accuracy: 0.8943 - val_loss: 0.7083 - val_accuracy: 0.8889\n",
      "Epoch 166/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6946 - accuracy: 0.8943 - val_loss: 0.7083 - val_accuracy: 0.8889\n",
      "Epoch 167/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6946 - accuracy: 0.8948 - val_loss: 0.7082 - val_accuracy: 0.8889\n",
      "Epoch 168/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6945 - accuracy: 0.8948 - val_loss: 0.7081 - val_accuracy: 0.8889\n",
      "Epoch 169/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6945 - accuracy: 0.8948 - val_loss: 0.7081 - val_accuracy: 0.8889\n",
      "Epoch 170/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6944 - accuracy: 0.8948 - val_loss: 0.7080 - val_accuracy: 0.8889\n",
      "Epoch 171/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6944 - accuracy: 0.8948 - val_loss: 0.7080 - val_accuracy: 0.8889\n",
      "Epoch 172/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6943 - accuracy: 0.8948 - val_loss: 0.7080 - val_accuracy: 0.8889\n",
      "Epoch 173/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6943 - accuracy: 0.8953 - val_loss: 0.7079 - val_accuracy: 0.8889\n",
      "Epoch 174/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6942 - accuracy: 0.8953 - val_loss: 0.7079 - val_accuracy: 0.8889\n",
      "Epoch 175/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6942 - accuracy: 0.8953 - val_loss: 0.7078 - val_accuracy: 0.8889\n",
      "Epoch 176/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6941 - accuracy: 0.8953 - val_loss: 0.7078 - val_accuracy: 0.8889\n",
      "Epoch 177/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6940 - accuracy: 0.8953 - val_loss: 0.7077 - val_accuracy: 0.8889\n",
      "Epoch 178/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6940 - accuracy: 0.8953 - val_loss: 0.7077 - val_accuracy: 0.8889\n",
      "Epoch 179/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6939 - accuracy: 0.8953 - val_loss: 0.7076 - val_accuracy: 0.8889\n",
      "Epoch 180/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6939 - accuracy: 0.8953 - val_loss: 0.7075 - val_accuracy: 0.8889\n",
      "Epoch 181/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6938 - accuracy: 0.8953 - val_loss: 0.7075 - val_accuracy: 0.8889\n",
      "Epoch 182/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6938 - accuracy: 0.8953 - val_loss: 0.7074 - val_accuracy: 0.8889\n",
      "Epoch 183/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6937 - accuracy: 0.8953 - val_loss: 0.7073 - val_accuracy: 0.8889\n",
      "Epoch 184/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6937 - accuracy: 0.8953 - val_loss: 0.7073 - val_accuracy: 0.8889\n",
      "Epoch 185/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6936 - accuracy: 0.8953 - val_loss: 0.7072 - val_accuracy: 0.8889\n",
      "Epoch 186/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6936 - accuracy: 0.8953 - val_loss: 0.7071 - val_accuracy: 0.8889\n",
      "Epoch 187/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6935 - accuracy: 0.8953 - val_loss: 0.7071 - val_accuracy: 0.8889\n",
      "Epoch 188/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6935 - accuracy: 0.8953 - val_loss: 0.7070 - val_accuracy: 0.8889\n",
      "Epoch 189/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6934 - accuracy: 0.8953 - val_loss: 0.7070 - val_accuracy: 0.8889\n",
      "Epoch 190/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6934 - accuracy: 0.8958 - val_loss: 0.7069 - val_accuracy: 0.8889\n",
      "Epoch 191/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6933 - accuracy: 0.8958 - val_loss: 0.7069 - val_accuracy: 0.8889\n",
      "Epoch 192/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6933 - accuracy: 0.8958 - val_loss: 0.7068 - val_accuracy: 0.8889\n",
      "Epoch 193/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.8958 - val_loss: 0.7068 - val_accuracy: 0.8889\n",
      "Epoch 194/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.8958 - val_loss: 0.7068 - val_accuracy: 0.8889\n",
      "Epoch 195/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.8958 - val_loss: 0.7067 - val_accuracy: 0.8889\n",
      "Epoch 196/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.8958 - val_loss: 0.7066 - val_accuracy: 0.8889\n",
      "Epoch 197/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6930 - accuracy: 0.8958 - val_loss: 0.7066 - val_accuracy: 0.8889\n",
      "Epoch 198/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6930 - accuracy: 0.8958 - val_loss: 0.7065 - val_accuracy: 0.8889\n",
      "Epoch 199/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.8958 - val_loss: 0.7065 - val_accuracy: 0.8889\n",
      "Epoch 200/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.8958 - val_loss: 0.7064 - val_accuracy: 0.8889\n",
      "Epoch 201/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.8958 - val_loss: 0.7063 - val_accuracy: 0.8889\n",
      "Epoch 202/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6928 - accuracy: 0.8958 - val_loss: 0.7063 - val_accuracy: 0.8889\n",
      "Epoch 203/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6928 - accuracy: 0.8958 - val_loss: 0.7063 - val_accuracy: 0.8889\n",
      "Epoch 204/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6927 - accuracy: 0.8958 - val_loss: 0.7062 - val_accuracy: 0.8889\n",
      "Epoch 205/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6927 - accuracy: 0.8958 - val_loss: 0.7062 - val_accuracy: 0.8889\n",
      "Epoch 206/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6926 - accuracy: 0.8953 - val_loss: 0.7061 - val_accuracy: 0.8889\n",
      "Epoch 207/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6926 - accuracy: 0.8958 - val_loss: 0.7061 - val_accuracy: 0.8889\n",
      "Epoch 208/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6925 - accuracy: 0.8958 - val_loss: 0.7060 - val_accuracy: 0.8889\n",
      "Epoch 209/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6925 - accuracy: 0.8958 - val_loss: 0.7060 - val_accuracy: 0.8889\n",
      "Epoch 210/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6925 - accuracy: 0.8958 - val_loss: 0.7059 - val_accuracy: 0.8889\n",
      "Epoch 211/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6924 - accuracy: 0.8953 - val_loss: 0.7059 - val_accuracy: 0.8889\n",
      "Epoch 212/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6924 - accuracy: 0.8953 - val_loss: 0.7058 - val_accuracy: 0.8889\n",
      "Epoch 213/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6923 - accuracy: 0.8953 - val_loss: 0.7058 - val_accuracy: 0.8889\n",
      "Epoch 214/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6923 - accuracy: 0.8963 - val_loss: 0.7057 - val_accuracy: 0.8889\n",
      "Epoch 215/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6922 - accuracy: 0.8953 - val_loss: 0.7057 - val_accuracy: 0.8889\n",
      "Epoch 216/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6922 - accuracy: 0.8958 - val_loss: 0.7057 - val_accuracy: 0.8889\n",
      "Epoch 217/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6921 - accuracy: 0.8953 - val_loss: 0.7056 - val_accuracy: 0.8889\n",
      "Epoch 218/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6921 - accuracy: 0.8953 - val_loss: 0.7055 - val_accuracy: 0.8889\n",
      "Epoch 219/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6921 - accuracy: 0.8953 - val_loss: 0.7055 - val_accuracy: 0.8889\n",
      "Epoch 220/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6920 - accuracy: 0.8953 - val_loss: 0.7055 - val_accuracy: 0.8889\n",
      "Epoch 221/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6920 - accuracy: 0.8953 - val_loss: 0.7055 - val_accuracy: 0.8889\n",
      "Epoch 222/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6919 - accuracy: 0.8958 - val_loss: 0.7054 - val_accuracy: 0.8889\n",
      "Epoch 223/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6919 - accuracy: 0.8953 - val_loss: 0.7054 - val_accuracy: 0.8909\n",
      "Epoch 224/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6918 - accuracy: 0.8953 - val_loss: 0.7053 - val_accuracy: 0.8909\n",
      "Epoch 225/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6918 - accuracy: 0.8958 - val_loss: 0.7053 - val_accuracy: 0.8909\n",
      "Epoch 226/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6918 - accuracy: 0.8958 - val_loss: 0.7052 - val_accuracy: 0.8909\n",
      "Epoch 227/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6917 - accuracy: 0.8953 - val_loss: 0.7052 - val_accuracy: 0.8909\n",
      "Epoch 228/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6917 - accuracy: 0.8958 - val_loss: 0.7052 - val_accuracy: 0.8909\n",
      "Epoch 229/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6916 - accuracy: 0.8958 - val_loss: 0.7051 - val_accuracy: 0.8909\n",
      "Epoch 230/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6916 - accuracy: 0.8958 - val_loss: 0.7051 - val_accuracy: 0.8909\n",
      "Epoch 231/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6915 - accuracy: 0.8963 - val_loss: 0.7051 - val_accuracy: 0.8909\n",
      "Epoch 232/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6915 - accuracy: 0.8958 - val_loss: 0.7050 - val_accuracy: 0.8909\n",
      "Epoch 233/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6915 - accuracy: 0.8958 - val_loss: 0.7050 - val_accuracy: 0.8909\n",
      "Epoch 234/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6914 - accuracy: 0.8958 - val_loss: 0.7050 - val_accuracy: 0.8909\n",
      "Epoch 235/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6914 - accuracy: 0.8958 - val_loss: 0.7049 - val_accuracy: 0.8909\n",
      "Epoch 236/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6913 - accuracy: 0.8958 - val_loss: 0.7049 - val_accuracy: 0.8909\n",
      "Epoch 237/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6913 - accuracy: 0.8958 - val_loss: 0.7049 - val_accuracy: 0.8909\n",
      "Epoch 238/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6913 - accuracy: 0.8958 - val_loss: 0.7049 - val_accuracy: 0.8909\n",
      "Epoch 239/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6912 - accuracy: 0.8958 - val_loss: 0.7048 - val_accuracy: 0.8909\n",
      "Epoch 240/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6912 - accuracy: 0.8958 - val_loss: 0.7048 - val_accuracy: 0.8909\n",
      "Epoch 241/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6912 - accuracy: 0.8963 - val_loss: 0.7048 - val_accuracy: 0.8909\n",
      "Epoch 242/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6911 - accuracy: 0.8958 - val_loss: 0.7048 - val_accuracy: 0.8909\n",
      "Epoch 243/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6911 - accuracy: 0.8958 - val_loss: 0.7048 - val_accuracy: 0.8909\n",
      "Epoch 244/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6910 - accuracy: 0.8958 - val_loss: 0.7047 - val_accuracy: 0.8909\n",
      "Epoch 245/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6910 - accuracy: 0.8958 - val_loss: 0.7047 - val_accuracy: 0.8909\n",
      "Epoch 246/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6910 - accuracy: 0.8958 - val_loss: 0.7047 - val_accuracy: 0.8909\n",
      "Epoch 247/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6909 - accuracy: 0.8958 - val_loss: 0.7047 - val_accuracy: 0.8909\n",
      "Epoch 248/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6909 - accuracy: 0.8963 - val_loss: 0.7047 - val_accuracy: 0.8909\n",
      "Epoch 249/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6909 - accuracy: 0.8958 - val_loss: 0.7046 - val_accuracy: 0.8909\n",
      "Epoch 250/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6908 - accuracy: 0.8963 - val_loss: 0.7046 - val_accuracy: 0.8909\n",
      "20/20 [==============================] - 0s 1ms/step\n",
      "Epoch 1/500\n",
      "63/63 [==============================] - 1s 4ms/step - loss: 0.6968 - accuracy: 0.8958 - val_loss: 0.6980 - val_accuracy: 0.8869\n",
      "Epoch 2/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6951 - accuracy: 0.8973 - val_loss: 0.6984 - val_accuracy: 0.8909\n",
      "Epoch 3/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6944 - accuracy: 0.8993 - val_loss: 0.6967 - val_accuracy: 0.8889\n",
      "Epoch 4/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6938 - accuracy: 0.8978 - val_loss: 0.6962 - val_accuracy: 0.8909\n",
      "Epoch 5/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.8973 - val_loss: 0.6960 - val_accuracy: 0.8909\n",
      "Epoch 6/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.8988 - val_loss: 0.6953 - val_accuracy: 0.8909\n",
      "Epoch 7/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6925 - accuracy: 0.8978 - val_loss: 0.6952 - val_accuracy: 0.8909\n",
      "Epoch 8/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6922 - accuracy: 0.8988 - val_loss: 0.6950 - val_accuracy: 0.8909\n",
      "Epoch 9/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6919 - accuracy: 0.8993 - val_loss: 0.6947 - val_accuracy: 0.8929\n",
      "Epoch 10/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6863 - accuracy: 0.8988 - val_loss: 0.6912 - val_accuracy: 0.8929\n",
      "Epoch 11/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6734 - accuracy: 0.8993 - val_loss: 0.6893 - val_accuracy: 0.8909\n",
      "Epoch 12/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6668 - accuracy: 0.8988 - val_loss: 0.6889 - val_accuracy: 0.8909\n",
      "Epoch 13/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6654 - accuracy: 0.8983 - val_loss: 0.6888 - val_accuracy: 0.8909\n",
      "Epoch 14/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6651 - accuracy: 0.8978 - val_loss: 0.6888 - val_accuracy: 0.8929\n",
      "Epoch 15/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6648 - accuracy: 0.8983 - val_loss: 0.6891 - val_accuracy: 0.8929\n",
      "Epoch 16/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6645 - accuracy: 0.8978 - val_loss: 0.6894 - val_accuracy: 0.8929\n",
      "Epoch 17/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6643 - accuracy: 0.8983 - val_loss: 0.6895 - val_accuracy: 0.8929\n",
      "Epoch 18/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6641 - accuracy: 0.8988 - val_loss: 0.6898 - val_accuracy: 0.8929\n",
      "Epoch 19/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6596 - accuracy: 0.8988 - val_loss: 0.6623 - val_accuracy: 0.8810\n",
      "Epoch 20/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6466 - accuracy: 0.8988 - val_loss: 0.6620 - val_accuracy: 0.8810\n",
      "Epoch 21/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6457 - accuracy: 0.8988 - val_loss: 0.6620 - val_accuracy: 0.8810\n",
      "Epoch 22/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6454 - accuracy: 0.8988 - val_loss: 0.6621 - val_accuracy: 0.8829\n",
      "Epoch 23/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6451 - accuracy: 0.8993 - val_loss: 0.6622 - val_accuracy: 0.8869\n",
      "Epoch 24/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6449 - accuracy: 0.8993 - val_loss: 0.6626 - val_accuracy: 0.8909\n",
      "Epoch 25/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6447 - accuracy: 0.8998 - val_loss: 0.6632 - val_accuracy: 0.8909\n",
      "Epoch 26/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6445 - accuracy: 0.9003 - val_loss: 0.6644 - val_accuracy: 0.8909\n",
      "Epoch 27/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6443 - accuracy: 0.8993 - val_loss: 0.6823 - val_accuracy: 0.8909\n",
      "Epoch 28/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6442 - accuracy: 0.8988 - val_loss: 0.6820 - val_accuracy: 0.8909\n",
      "Epoch 29/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6440 - accuracy: 0.8988 - val_loss: 0.6819 - val_accuracy: 0.8929\n",
      "Epoch 30/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6439 - accuracy: 0.8988 - val_loss: 0.6817 - val_accuracy: 0.8948\n",
      "Epoch 31/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6438 - accuracy: 0.8988 - val_loss: 0.6815 - val_accuracy: 0.8948\n",
      "Epoch 32/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6436 - accuracy: 0.8988 - val_loss: 0.6814 - val_accuracy: 0.8948\n",
      "Epoch 33/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6435 - accuracy: 0.8988 - val_loss: 0.6812 - val_accuracy: 0.8948\n",
      "Epoch 34/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6434 - accuracy: 0.8988 - val_loss: 0.6811 - val_accuracy: 0.8948\n",
      "Epoch 35/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6433 - accuracy: 0.8988 - val_loss: 0.6810 - val_accuracy: 0.8948\n",
      "Epoch 36/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6432 - accuracy: 0.8988 - val_loss: 0.6808 - val_accuracy: 0.8948\n",
      "Epoch 37/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6431 - accuracy: 0.8988 - val_loss: 0.6807 - val_accuracy: 0.8948\n",
      "Epoch 38/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6430 - accuracy: 0.8988 - val_loss: 0.6806 - val_accuracy: 0.8948\n",
      "Epoch 39/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6429 - accuracy: 0.8988 - val_loss: 0.6805 - val_accuracy: 0.8948\n",
      "Epoch 40/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6428 - accuracy: 0.8993 - val_loss: 0.6804 - val_accuracy: 0.8948\n",
      "Epoch 41/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6427 - accuracy: 0.8993 - val_loss: 0.6803 - val_accuracy: 0.8948\n",
      "Epoch 42/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6426 - accuracy: 0.8988 - val_loss: 0.6802 - val_accuracy: 0.8968\n",
      "Epoch 43/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6425 - accuracy: 0.8998 - val_loss: 0.6801 - val_accuracy: 0.8968\n",
      "Epoch 44/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6425 - accuracy: 0.9003 - val_loss: 0.6800 - val_accuracy: 0.8968\n",
      "Epoch 45/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6424 - accuracy: 0.9003 - val_loss: 0.6799 - val_accuracy: 0.8968\n",
      "Epoch 46/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6423 - accuracy: 0.9003 - val_loss: 0.6798 - val_accuracy: 0.8968\n",
      "Epoch 47/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6422 - accuracy: 0.9003 - val_loss: 0.6797 - val_accuracy: 0.8968\n",
      "Epoch 48/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6421 - accuracy: 0.8998 - val_loss: 0.6796 - val_accuracy: 0.8968\n",
      "Epoch 49/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6421 - accuracy: 0.9008 - val_loss: 0.6796 - val_accuracy: 0.8968\n",
      "Epoch 50/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6420 - accuracy: 0.9003 - val_loss: 0.6795 - val_accuracy: 0.8968\n",
      "Epoch 51/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6419 - accuracy: 0.9003 - val_loss: 0.6794 - val_accuracy: 0.8968\n",
      "Epoch 52/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6419 - accuracy: 0.9003 - val_loss: 0.6793 - val_accuracy: 0.8968\n",
      "Epoch 53/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6418 - accuracy: 0.9008 - val_loss: 0.6793 - val_accuracy: 0.8968\n",
      "Epoch 54/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6417 - accuracy: 0.9008 - val_loss: 0.6792 - val_accuracy: 0.8968\n",
      "Epoch 55/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6417 - accuracy: 0.9008 - val_loss: 0.6791 - val_accuracy: 0.8968\n",
      "Epoch 56/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6416 - accuracy: 0.9008 - val_loss: 0.6791 - val_accuracy: 0.8968\n",
      "Epoch 57/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6415 - accuracy: 0.9008 - val_loss: 0.6790 - val_accuracy: 0.8968\n",
      "Epoch 58/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6415 - accuracy: 0.9013 - val_loss: 0.6789 - val_accuracy: 0.8968\n",
      "Epoch 59/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6414 - accuracy: 0.9008 - val_loss: 0.6789 - val_accuracy: 0.8968\n",
      "Epoch 60/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6413 - accuracy: 0.9013 - val_loss: 0.6788 - val_accuracy: 0.8988\n",
      "Epoch 61/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6413 - accuracy: 0.9013 - val_loss: 0.6787 - val_accuracy: 0.8988\n",
      "Epoch 62/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6412 - accuracy: 0.9013 - val_loss: 0.6787 - val_accuracy: 0.8988\n",
      "Epoch 63/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6411 - accuracy: 0.9013 - val_loss: 0.6786 - val_accuracy: 0.8988\n",
      "Epoch 64/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6411 - accuracy: 0.9013 - val_loss: 0.6785 - val_accuracy: 0.8988\n",
      "Epoch 65/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6410 - accuracy: 0.9013 - val_loss: 0.6785 - val_accuracy: 0.8988\n",
      "Epoch 66/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6409 - accuracy: 0.9013 - val_loss: 0.6784 - val_accuracy: 0.8988\n",
      "Epoch 67/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6409 - accuracy: 0.9013 - val_loss: 0.6783 - val_accuracy: 0.8988\n",
      "Epoch 68/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6408 - accuracy: 0.9013 - val_loss: 0.6783 - val_accuracy: 0.8988\n",
      "Epoch 69/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6407 - accuracy: 0.9013 - val_loss: 0.6782 - val_accuracy: 0.8988\n",
      "Epoch 70/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6407 - accuracy: 0.9013 - val_loss: 0.6781 - val_accuracy: 0.8988\n",
      "Epoch 71/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6406 - accuracy: 0.9013 - val_loss: 0.6781 - val_accuracy: 0.8988\n",
      "Epoch 72/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6405 - accuracy: 0.9018 - val_loss: 0.6780 - val_accuracy: 0.8988\n",
      "Epoch 73/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6405 - accuracy: 0.9013 - val_loss: 0.6780 - val_accuracy: 0.8988\n",
      "Epoch 74/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6404 - accuracy: 0.9013 - val_loss: 0.6779 - val_accuracy: 0.8988\n",
      "Epoch 75/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6403 - accuracy: 0.9018 - val_loss: 0.6778 - val_accuracy: 0.8988\n",
      "Epoch 76/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6403 - accuracy: 0.9018 - val_loss: 0.6778 - val_accuracy: 0.8988\n",
      "Epoch 77/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6402 - accuracy: 0.9023 - val_loss: 0.6777 - val_accuracy: 0.8988\n",
      "Epoch 78/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6401 - accuracy: 0.9018 - val_loss: 0.6777 - val_accuracy: 0.8988\n",
      "Epoch 79/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6401 - accuracy: 0.9018 - val_loss: 0.6776 - val_accuracy: 0.8988\n",
      "Epoch 80/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6400 - accuracy: 0.9018 - val_loss: 0.6776 - val_accuracy: 0.8988\n",
      "Epoch 81/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6400 - accuracy: 0.9018 - val_loss: 0.6775 - val_accuracy: 0.8988\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6399 - accuracy: 0.9018 - val_loss: 0.6775 - val_accuracy: 0.8988\n",
      "Epoch 83/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6369 - accuracy: 0.9023 - val_loss: 0.6768 - val_accuracy: 0.8948\n",
      "Epoch 84/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6278 - accuracy: 0.8993 - val_loss: 0.6767 - val_accuracy: 0.8948\n",
      "Epoch 85/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6278 - accuracy: 0.8993 - val_loss: 0.6767 - val_accuracy: 0.8948\n",
      "Epoch 86/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6277 - accuracy: 0.8993 - val_loss: 0.6767 - val_accuracy: 0.8948\n",
      "Epoch 87/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6277 - accuracy: 0.8993 - val_loss: 0.6767 - val_accuracy: 0.8948\n",
      "Epoch 88/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6277 - accuracy: 0.8993 - val_loss: 0.6767 - val_accuracy: 0.8948\n",
      "Epoch 89/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6276 - accuracy: 0.8988 - val_loss: 0.6767 - val_accuracy: 0.8948\n",
      "Epoch 90/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6276 - accuracy: 0.8998 - val_loss: 0.6767 - val_accuracy: 0.8968\n",
      "Epoch 91/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6275 - accuracy: 0.9003 - val_loss: 0.6766 - val_accuracy: 0.8968\n",
      "Epoch 92/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6275 - accuracy: 0.9003 - val_loss: 0.6766 - val_accuracy: 0.8968\n",
      "Epoch 93/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6275 - accuracy: 0.9003 - val_loss: 0.6766 - val_accuracy: 0.8968\n",
      "Epoch 94/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6274 - accuracy: 0.9008 - val_loss: 0.6766 - val_accuracy: 0.8968\n",
      "Epoch 95/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6274 - accuracy: 0.9008 - val_loss: 0.6766 - val_accuracy: 0.8968\n",
      "Epoch 96/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6273 - accuracy: 0.9008 - val_loss: 0.6766 - val_accuracy: 0.8968\n",
      "Epoch 97/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6273 - accuracy: 0.9008 - val_loss: 0.6766 - val_accuracy: 0.8968\n",
      "Epoch 98/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6273 - accuracy: 0.9008 - val_loss: 0.6766 - val_accuracy: 0.8968\n",
      "Epoch 99/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6272 - accuracy: 0.9013 - val_loss: 0.6765 - val_accuracy: 0.8968\n",
      "Epoch 100/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6272 - accuracy: 0.9013 - val_loss: 0.6765 - val_accuracy: 0.8968\n",
      "Epoch 101/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6272 - accuracy: 0.9018 - val_loss: 0.6765 - val_accuracy: 0.8968\n",
      "Epoch 102/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6271 - accuracy: 0.9018 - val_loss: 0.6765 - val_accuracy: 0.8968\n",
      "Epoch 103/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6271 - accuracy: 0.9018 - val_loss: 0.6765 - val_accuracy: 0.8968\n",
      "Epoch 104/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6271 - accuracy: 0.9018 - val_loss: 0.6765 - val_accuracy: 0.8968\n",
      "Epoch 105/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6271 - accuracy: 0.9018 - val_loss: 0.6765 - val_accuracy: 0.8968\n",
      "Epoch 106/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6270 - accuracy: 0.9018 - val_loss: 0.6764 - val_accuracy: 0.8968\n",
      "Epoch 107/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6270 - accuracy: 0.9018 - val_loss: 0.6764 - val_accuracy: 0.8968\n",
      "Epoch 108/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6270 - accuracy: 0.9018 - val_loss: 0.6764 - val_accuracy: 0.8968\n",
      "Epoch 109/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.9018 - val_loss: 0.6764 - val_accuracy: 0.8968\n",
      "Epoch 110/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6269 - accuracy: 0.9018 - val_loss: 0.6644 - val_accuracy: 0.8968\n",
      "Epoch 111/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6269 - accuracy: 0.9018 - val_loss: 0.6623 - val_accuracy: 0.8988\n",
      "Epoch 112/500\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.6269 - accuracy: 0.9018 - val_loss: 0.6613 - val_accuracy: 0.8988\n",
      "Epoch 113/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6268 - accuracy: 0.9023 - val_loss: 0.6606 - val_accuracy: 0.8988\n",
      "Epoch 114/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6268 - accuracy: 0.9023 - val_loss: 0.6601 - val_accuracy: 0.8988\n",
      "Epoch 115/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6268 - accuracy: 0.9023 - val_loss: 0.6597 - val_accuracy: 0.8988\n",
      "Epoch 116/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6268 - accuracy: 0.9023 - val_loss: 0.6593 - val_accuracy: 0.8988\n",
      "Epoch 117/500\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.6267 - accuracy: 0.9023 - val_loss: 0.6591 - val_accuracy: 0.8988\n",
      "Epoch 118/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6267 - accuracy: 0.9023 - val_loss: 0.6588 - val_accuracy: 0.8988\n",
      "Epoch 119/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6267 - accuracy: 0.9023 - val_loss: 0.6586 - val_accuracy: 0.8988\n",
      "Epoch 120/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6267 - accuracy: 0.9023 - val_loss: 0.6584 - val_accuracy: 0.8988\n",
      "Epoch 121/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6266 - accuracy: 0.9023 - val_loss: 0.6582 - val_accuracy: 0.8988\n",
      "Epoch 122/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6266 - accuracy: 0.9023 - val_loss: 0.6581 - val_accuracy: 0.8988\n",
      "Epoch 123/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6266 - accuracy: 0.9023 - val_loss: 0.6579 - val_accuracy: 0.8988\n",
      "Epoch 124/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6266 - accuracy: 0.9023 - val_loss: 0.6578 - val_accuracy: 0.8988\n",
      "Epoch 125/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6265 - accuracy: 0.9023 - val_loss: 0.6577 - val_accuracy: 0.8988\n",
      "Epoch 126/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6265 - accuracy: 0.9023 - val_loss: 0.6575 - val_accuracy: 0.8988\n",
      "Epoch 127/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6265 - accuracy: 0.9023 - val_loss: 0.6574 - val_accuracy: 0.8988\n",
      "Epoch 128/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6265 - accuracy: 0.9023 - val_loss: 0.6573 - val_accuracy: 0.8988\n",
      "Epoch 129/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6264 - accuracy: 0.9023 - val_loss: 0.6572 - val_accuracy: 0.8988\n",
      "Epoch 130/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6264 - accuracy: 0.9023 - val_loss: 0.6571 - val_accuracy: 0.8988\n",
      "Epoch 131/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6264 - accuracy: 0.9023 - val_loss: 0.6571 - val_accuracy: 0.8988\n",
      "Epoch 132/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6030 - accuracy: 0.9028 - val_loss: 0.6739 - val_accuracy: 0.8869\n",
      "Epoch 133/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.5983 - accuracy: 0.9028 - val_loss: 0.6739 - val_accuracy: 0.8869\n",
      "Epoch 134/500\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.5981 - accuracy: 0.9028 - val_loss: 0.6739 - val_accuracy: 0.8869\n",
      "Epoch 135/500\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.5979 - accuracy: 0.9028 - val_loss: 0.6738 - val_accuracy: 0.8869\n",
      "Epoch 136/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.5978 - accuracy: 0.9028 - val_loss: 0.6738 - val_accuracy: 0.8869\n",
      "Epoch 137/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5977 - accuracy: 0.9028 - val_loss: 0.6738 - val_accuracy: 0.8869\n",
      "Epoch 138/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.5976 - accuracy: 0.9028 - val_loss: 0.6738 - val_accuracy: 0.8869\n",
      "Epoch 139/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 3ms/step - loss: 0.5975 - accuracy: 0.9023 - val_loss: 0.6738 - val_accuracy: 0.8869\n",
      "Epoch 140/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.5974 - accuracy: 0.9028 - val_loss: 0.6738 - val_accuracy: 0.8869\n",
      "Epoch 141/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5973 - accuracy: 0.9023 - val_loss: 0.6738 - val_accuracy: 0.8869\n",
      "Epoch 142/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.5972 - accuracy: 0.9023 - val_loss: 0.6738 - val_accuracy: 0.8869\n",
      "Epoch 143/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.5972 - accuracy: 0.9023 - val_loss: 0.6737 - val_accuracy: 0.8869\n",
      "Epoch 144/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.5971 - accuracy: 0.9023 - val_loss: 0.6737 - val_accuracy: 0.8869\n",
      "Epoch 145/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.5970 - accuracy: 0.9023 - val_loss: 0.6737 - val_accuracy: 0.8869\n",
      "Epoch 146/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.5970 - accuracy: 0.9023 - val_loss: 0.6737 - val_accuracy: 0.8869\n",
      "Epoch 147/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.5969 - accuracy: 0.9023 - val_loss: 0.6737 - val_accuracy: 0.8869\n",
      "Epoch 148/500\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.5969 - accuracy: 0.9023 - val_loss: 0.6737 - val_accuracy: 0.8869\n",
      "Epoch 149/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.5968 - accuracy: 0.9023 - val_loss: 0.6737 - val_accuracy: 0.8869\n",
      "Epoch 150/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.5968 - accuracy: 0.9023 - val_loss: 0.6737 - val_accuracy: 0.8869\n",
      "Epoch 151/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5967 - accuracy: 0.9023 - val_loss: 0.6736 - val_accuracy: 0.8869\n",
      "Epoch 152/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.5967 - accuracy: 0.9023 - val_loss: 0.6736 - val_accuracy: 0.8869\n",
      "Epoch 153/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.5966 - accuracy: 0.9023 - val_loss: 0.6736 - val_accuracy: 0.8869\n",
      "Epoch 154/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.5966 - accuracy: 0.9023 - val_loss: 0.6736 - val_accuracy: 0.8869\n",
      "Epoch 155/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.5965 - accuracy: 0.9023 - val_loss: 0.6736 - val_accuracy: 0.8869\n",
      "Epoch 156/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.5965 - accuracy: 0.9023 - val_loss: 0.6736 - val_accuracy: 0.8869\n",
      "Epoch 157/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5964 - accuracy: 0.9023 - val_loss: 0.6736 - val_accuracy: 0.8869\n",
      "Epoch 158/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.5964 - accuracy: 0.9023 - val_loss: 0.6736 - val_accuracy: 0.8869\n",
      "Epoch 159/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.5963 - accuracy: 0.9023 - val_loss: 0.6735 - val_accuracy: 0.8869\n",
      "Epoch 160/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.5963 - accuracy: 0.9023 - val_loss: 0.6735 - val_accuracy: 0.8869\n",
      "Epoch 161/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.5963 - accuracy: 0.9023 - val_loss: 0.6735 - val_accuracy: 0.8869\n",
      "Epoch 162/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.5962 - accuracy: 0.9023 - val_loss: 0.6735 - val_accuracy: 0.8869\n",
      "Epoch 163/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.5962 - accuracy: 0.9023 - val_loss: 0.6735 - val_accuracy: 0.8869\n",
      "Epoch 164/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5961 - accuracy: 0.9023 - val_loss: 0.6735 - val_accuracy: 0.8869\n",
      "Epoch 165/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5961 - accuracy: 0.9023 - val_loss: 0.6735 - val_accuracy: 0.8869\n",
      "Epoch 166/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.5961 - accuracy: 0.9023 - val_loss: 0.6735 - val_accuracy: 0.8869\n",
      "Epoch 167/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5960 - accuracy: 0.9023 - val_loss: 0.6735 - val_accuracy: 0.8869\n",
      "Epoch 168/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5960 - accuracy: 0.9023 - val_loss: 0.6734 - val_accuracy: 0.8869\n",
      "Epoch 169/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5960 - accuracy: 0.9023 - val_loss: 0.6734 - val_accuracy: 0.8869\n",
      "Epoch 170/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5959 - accuracy: 0.9018 - val_loss: 0.6734 - val_accuracy: 0.8869\n",
      "Epoch 171/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5959 - accuracy: 0.9018 - val_loss: 0.6734 - val_accuracy: 0.8869\n",
      "Epoch 172/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.5959 - accuracy: 0.9018 - val_loss: 0.6734 - val_accuracy: 0.8869\n",
      "Epoch 173/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5958 - accuracy: 0.9018 - val_loss: 0.6734 - val_accuracy: 0.8869\n",
      "Epoch 174/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.5958 - accuracy: 0.9018 - val_loss: 0.6734 - val_accuracy: 0.8869\n",
      "Epoch 175/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.5958 - accuracy: 0.9018 - val_loss: 0.6734 - val_accuracy: 0.8869\n",
      "Epoch 176/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.5957 - accuracy: 0.9018 - val_loss: 0.6734 - val_accuracy: 0.8869\n",
      "Epoch 177/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.5957 - accuracy: 0.9018 - val_loss: 0.6734 - val_accuracy: 0.8869\n",
      "Epoch 178/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.5957 - accuracy: 0.9018 - val_loss: 0.6733 - val_accuracy: 0.8869\n",
      "Epoch 179/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.5956 - accuracy: 0.9018 - val_loss: 0.6733 - val_accuracy: 0.8869\n",
      "Epoch 180/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.5956 - accuracy: 0.9018 - val_loss: 0.6733 - val_accuracy: 0.8869\n",
      "Epoch 181/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.5956 - accuracy: 0.9018 - val_loss: 0.6733 - val_accuracy: 0.8869\n",
      "Epoch 182/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.5956 - accuracy: 0.9018 - val_loss: 0.6733 - val_accuracy: 0.8869\n",
      "Epoch 183/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.5955 - accuracy: 0.9018 - val_loss: 0.6733 - val_accuracy: 0.8869\n",
      "Epoch 184/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.5955 - accuracy: 0.9018 - val_loss: 0.6733 - val_accuracy: 0.8869\n",
      "Epoch 185/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.5955 - accuracy: 0.9018 - val_loss: 0.6733 - val_accuracy: 0.8869\n",
      "Epoch 186/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5954 - accuracy: 0.9018 - val_loss: 0.6733 - val_accuracy: 0.8869\n",
      "Epoch 187/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5954 - accuracy: 0.9018 - val_loss: 0.6733 - val_accuracy: 0.8869\n",
      "Epoch 188/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.5954 - accuracy: 0.9018 - val_loss: 0.6732 - val_accuracy: 0.8869\n",
      "Epoch 189/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.5954 - accuracy: 0.9018 - val_loss: 0.6732 - val_accuracy: 0.8869\n",
      "Epoch 190/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.5953 - accuracy: 0.9018 - val_loss: 0.6732 - val_accuracy: 0.8869\n",
      "Epoch 191/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5953 - accuracy: 0.9018 - val_loss: 0.6732 - val_accuracy: 0.8869\n",
      "Epoch 192/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5953 - accuracy: 0.9018 - val_loss: 0.6732 - val_accuracy: 0.8869\n",
      "Epoch 193/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.5952 - accuracy: 0.9018 - val_loss: 0.6732 - val_accuracy: 0.8869\n",
      "Epoch 194/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.5952 - accuracy: 0.9018 - val_loss: 0.6732 - val_accuracy: 0.8869\n",
      "Epoch 195/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5952 - accuracy: 0.9018 - val_loss: 0.6732 - val_accuracy: 0.8869\n",
      "Epoch 196/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 3ms/step - loss: 0.5952 - accuracy: 0.9018 - val_loss: 0.6732 - val_accuracy: 0.8869\n",
      "Epoch 197/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.5951 - accuracy: 0.9018 - val_loss: 0.6732 - val_accuracy: 0.8869\n",
      "Epoch 198/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.5951 - accuracy: 0.9018 - val_loss: 0.6732 - val_accuracy: 0.8869\n",
      "Epoch 199/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5951 - accuracy: 0.9018 - val_loss: 0.6610 - val_accuracy: 0.8869\n",
      "Epoch 200/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5951 - accuracy: 0.9018 - val_loss: 0.6595 - val_accuracy: 0.8869\n",
      "Epoch 201/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5950 - accuracy: 0.9023 - val_loss: 0.6587 - val_accuracy: 0.8869\n",
      "Epoch 202/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.5950 - accuracy: 0.9023 - val_loss: 0.6581 - val_accuracy: 0.8869\n",
      "Epoch 203/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5863 - accuracy: 0.8998 - val_loss: 0.6724 - val_accuracy: 0.8810\n",
      "Epoch 204/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5830 - accuracy: 0.8993 - val_loss: 0.6724 - val_accuracy: 0.8810\n",
      "Epoch 205/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.5830 - accuracy: 0.8993 - val_loss: 0.6724 - val_accuracy: 0.8810\n",
      "Epoch 206/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.5829 - accuracy: 0.8993 - val_loss: 0.6724 - val_accuracy: 0.8810\n",
      "Epoch 207/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5828 - accuracy: 0.8993 - val_loss: 0.6724 - val_accuracy: 0.8810\n",
      "Epoch 208/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5828 - accuracy: 0.8993 - val_loss: 0.6724 - val_accuracy: 0.8810\n",
      "Epoch 209/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5827 - accuracy: 0.8993 - val_loss: 0.6724 - val_accuracy: 0.8810\n",
      "Epoch 210/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5827 - accuracy: 0.8993 - val_loss: 0.6724 - val_accuracy: 0.8810\n",
      "Epoch 211/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5826 - accuracy: 0.8998 - val_loss: 0.6723 - val_accuracy: 0.8810\n",
      "Epoch 212/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5826 - accuracy: 0.8998 - val_loss: 0.6723 - val_accuracy: 0.8810\n",
      "Epoch 213/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5826 - accuracy: 0.8998 - val_loss: 0.6723 - val_accuracy: 0.8810\n",
      "Epoch 214/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5825 - accuracy: 0.8998 - val_loss: 0.6723 - val_accuracy: 0.8810\n",
      "Epoch 215/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.5825 - accuracy: 0.8998 - val_loss: 0.6723 - val_accuracy: 0.8810\n",
      "Epoch 216/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.5824 - accuracy: 0.8998 - val_loss: 0.6723 - val_accuracy: 0.8810\n",
      "Epoch 217/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.5824 - accuracy: 0.9003 - val_loss: 0.6723 - val_accuracy: 0.8810\n",
      "Epoch 218/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5824 - accuracy: 0.9003 - val_loss: 0.6723 - val_accuracy: 0.8810\n",
      "Epoch 219/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.5823 - accuracy: 0.9003 - val_loss: 0.6723 - val_accuracy: 0.8810\n",
      "Epoch 220/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.5823 - accuracy: 0.9003 - val_loss: 0.6723 - val_accuracy: 0.8810\n",
      "Epoch 221/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5823 - accuracy: 0.9003 - val_loss: 0.6723 - val_accuracy: 0.8810\n",
      "Epoch 222/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5822 - accuracy: 0.9003 - val_loss: 0.6723 - val_accuracy: 0.8810\n",
      "Epoch 223/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5822 - accuracy: 0.9003 - val_loss: 0.6723 - val_accuracy: 0.8810\n",
      "Epoch 224/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.5822 - accuracy: 0.9003 - val_loss: 0.6723 - val_accuracy: 0.8810\n",
      "Epoch 225/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5821 - accuracy: 0.9003 - val_loss: 0.6723 - val_accuracy: 0.8810\n",
      "Epoch 226/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5821 - accuracy: 0.9008 - val_loss: 0.6722 - val_accuracy: 0.8810\n",
      "Epoch 227/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.5821 - accuracy: 0.9008 - val_loss: 0.6722 - val_accuracy: 0.8810\n",
      "Epoch 228/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5820 - accuracy: 0.9008 - val_loss: 0.6722 - val_accuracy: 0.8810\n",
      "Epoch 229/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.5820 - accuracy: 0.9008 - val_loss: 0.6722 - val_accuracy: 0.8810\n",
      "Epoch 230/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.5820 - accuracy: 0.9008 - val_loss: 0.6722 - val_accuracy: 0.8810\n",
      "Epoch 231/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.5820 - accuracy: 0.9008 - val_loss: 0.6722 - val_accuracy: 0.8810\n",
      "Epoch 232/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.5819 - accuracy: 0.9008 - val_loss: 0.6722 - val_accuracy: 0.8810\n",
      "Epoch 233/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.5819 - accuracy: 0.9008 - val_loss: 0.6722 - val_accuracy: 0.8810\n",
      "Epoch 234/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.5819 - accuracy: 0.9008 - val_loss: 0.6722 - val_accuracy: 0.8810\n",
      "Epoch 235/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.5819 - accuracy: 0.9008 - val_loss: 0.6722 - val_accuracy: 0.8810\n",
      "Epoch 236/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.5818 - accuracy: 0.9008 - val_loss: 0.6722 - val_accuracy: 0.8810\n",
      "Epoch 237/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.5818 - accuracy: 0.9008 - val_loss: 0.6722 - val_accuracy: 0.8810\n",
      "Epoch 238/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5818 - accuracy: 0.9008 - val_loss: 0.6722 - val_accuracy: 0.8810\n",
      "Epoch 239/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5817 - accuracy: 0.9008 - val_loss: 0.6721 - val_accuracy: 0.8810\n",
      "Epoch 240/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.5817 - accuracy: 0.9008 - val_loss: 0.6721 - val_accuracy: 0.8810\n",
      "Epoch 241/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5817 - accuracy: 0.9008 - val_loss: 0.6721 - val_accuracy: 0.8810\n",
      "Epoch 242/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5817 - accuracy: 0.9008 - val_loss: 0.6721 - val_accuracy: 0.8810\n",
      "Epoch 243/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.5817 - accuracy: 0.9008 - val_loss: 0.6721 - val_accuracy: 0.8810\n",
      "Epoch 244/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.5816 - accuracy: 0.9008 - val_loss: 0.6721 - val_accuracy: 0.8810\n",
      "Epoch 245/500\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.5816 - accuracy: 0.9008 - val_loss: 0.6475 - val_accuracy: 0.8810\n",
      "Epoch 246/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.5816 - accuracy: 0.9008 - val_loss: 0.6445 - val_accuracy: 0.8810\n",
      "Epoch 247/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.5816 - accuracy: 0.9008 - val_loss: 0.6428 - val_accuracy: 0.8810\n",
      "Epoch 248/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5815 - accuracy: 0.9008 - val_loss: 0.6416 - val_accuracy: 0.8810\n",
      "Epoch 249/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5815 - accuracy: 0.9008 - val_loss: 0.6407 - val_accuracy: 0.8810\n",
      "Epoch 250/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.5815 - accuracy: 0.9008 - val_loss: 0.6400 - val_accuracy: 0.8810\n",
      "Epoch 251/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.5815 - accuracy: 0.9008 - val_loss: 0.6394 - val_accuracy: 0.8810\n",
      "Epoch 252/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.5814 - accuracy: 0.9008 - val_loss: 0.6389 - val_accuracy: 0.8810\n",
      "Epoch 253/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 3ms/step - loss: 0.5814 - accuracy: 0.9008 - val_loss: 0.6384 - val_accuracy: 0.8810\n",
      "Epoch 254/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.5814 - accuracy: 0.9008 - val_loss: 0.6380 - val_accuracy: 0.8810\n",
      "Epoch 255/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.5814 - accuracy: 0.9008 - val_loss: 0.6376 - val_accuracy: 0.8810\n",
      "Epoch 256/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5814 - accuracy: 0.9008 - val_loss: 0.6373 - val_accuracy: 0.8810\n",
      "Epoch 257/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.5813 - accuracy: 0.9008 - val_loss: 0.6370 - val_accuracy: 0.8810\n",
      "Epoch 258/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.5813 - accuracy: 0.9008 - val_loss: 0.6367 - val_accuracy: 0.8810\n",
      "Epoch 259/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.5813 - accuracy: 0.9008 - val_loss: 0.6365 - val_accuracy: 0.8810\n",
      "Epoch 260/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.5813 - accuracy: 0.9008 - val_loss: 0.6362 - val_accuracy: 0.8810\n",
      "Epoch 261/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.5813 - accuracy: 0.9008 - val_loss: 0.6360 - val_accuracy: 0.8810\n",
      "Epoch 262/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.5812 - accuracy: 0.9008 - val_loss: 0.6358 - val_accuracy: 0.8810\n",
      "Epoch 263/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.5812 - accuracy: 0.9008 - val_loss: 0.6356 - val_accuracy: 0.8810\n",
      "Epoch 264/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.5812 - accuracy: 0.9008 - val_loss: 0.6354 - val_accuracy: 0.8810\n",
      "Epoch 265/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.5812 - accuracy: 0.9008 - val_loss: 0.6352 - val_accuracy: 0.8810\n",
      "Epoch 266/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.5812 - accuracy: 0.9008 - val_loss: 0.6350 - val_accuracy: 0.8810\n",
      "Epoch 267/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5811 - accuracy: 0.9008 - val_loss: 0.6348 - val_accuracy: 0.8810\n",
      "Epoch 268/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5811 - accuracy: 0.9008 - val_loss: 0.6347 - val_accuracy: 0.8810\n",
      "Epoch 269/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5811 - accuracy: 0.9008 - val_loss: 0.6345 - val_accuracy: 0.8810\n",
      "Epoch 270/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.5811 - accuracy: 0.9008 - val_loss: 0.6344 - val_accuracy: 0.8810\n",
      "Epoch 271/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5811 - accuracy: 0.9008 - val_loss: 0.6342 - val_accuracy: 0.8810\n",
      "Epoch 272/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.5810 - accuracy: 0.9008 - val_loss: 0.6341 - val_accuracy: 0.8810\n",
      "Epoch 273/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5810 - accuracy: 0.9008 - val_loss: 0.6340 - val_accuracy: 0.8810\n",
      "Epoch 274/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5810 - accuracy: 0.9008 - val_loss: 0.6338 - val_accuracy: 0.8810\n",
      "Epoch 275/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5810 - accuracy: 0.9008 - val_loss: 0.6337 - val_accuracy: 0.8810\n",
      "Epoch 276/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5810 - accuracy: 0.9008 - val_loss: 0.6336 - val_accuracy: 0.8810\n",
      "Epoch 277/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5809 - accuracy: 0.9008 - val_loss: 0.6335 - val_accuracy: 0.8810\n",
      "Epoch 278/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.5809 - accuracy: 0.9008 - val_loss: 0.6334 - val_accuracy: 0.8810\n",
      "Epoch 279/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5809 - accuracy: 0.9008 - val_loss: 0.6333 - val_accuracy: 0.8810\n",
      "Epoch 280/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5809 - accuracy: 0.9008 - val_loss: 0.6332 - val_accuracy: 0.8810\n",
      "Epoch 281/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5809 - accuracy: 0.9008 - val_loss: 0.6331 - val_accuracy: 0.8810\n",
      "Epoch 282/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5808 - accuracy: 0.9008 - val_loss: 0.6330 - val_accuracy: 0.8810\n",
      "Epoch 283/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5808 - accuracy: 0.9008 - val_loss: 0.6329 - val_accuracy: 0.8810\n",
      "Epoch 284/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5808 - accuracy: 0.9008 - val_loss: 0.6328 - val_accuracy: 0.8810\n",
      "Epoch 285/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5808 - accuracy: 0.9018 - val_loss: 0.6327 - val_accuracy: 0.8829\n",
      "Epoch 286/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5808 - accuracy: 0.9018 - val_loss: 0.6326 - val_accuracy: 0.8829\n",
      "Epoch 287/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5808 - accuracy: 0.9018 - val_loss: 0.6325 - val_accuracy: 0.8829\n",
      "Epoch 288/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5807 - accuracy: 0.9018 - val_loss: 0.6324 - val_accuracy: 0.8829\n",
      "Epoch 289/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5807 - accuracy: 0.9018 - val_loss: 0.6323 - val_accuracy: 0.8829\n",
      "Epoch 290/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5807 - accuracy: 0.9018 - val_loss: 0.6323 - val_accuracy: 0.8829\n",
      "Epoch 291/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5807 - accuracy: 0.9018 - val_loss: 0.6322 - val_accuracy: 0.8829\n",
      "Epoch 292/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5807 - accuracy: 0.9018 - val_loss: 0.6321 - val_accuracy: 0.8829\n",
      "Epoch 293/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5806 - accuracy: 0.9018 - val_loss: 0.6320 - val_accuracy: 0.8829\n",
      "Epoch 294/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5806 - accuracy: 0.9018 - val_loss: 0.6320 - val_accuracy: 0.8829\n",
      "Epoch 295/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5806 - accuracy: 0.9018 - val_loss: 0.6319 - val_accuracy: 0.8829\n",
      "Epoch 296/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5806 - accuracy: 0.9018 - val_loss: 0.6318 - val_accuracy: 0.8829\n",
      "Epoch 297/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5806 - accuracy: 0.9018 - val_loss: 0.6317 - val_accuracy: 0.8829\n",
      "Epoch 298/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5806 - accuracy: 0.9018 - val_loss: 0.6317 - val_accuracy: 0.8829\n",
      "Epoch 299/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5805 - accuracy: 0.9018 - val_loss: 0.6316 - val_accuracy: 0.8829\n",
      "Epoch 300/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5805 - accuracy: 0.9018 - val_loss: 0.6315 - val_accuracy: 0.8829\n",
      "Epoch 301/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5805 - accuracy: 0.9018 - val_loss: 0.6315 - val_accuracy: 0.8829\n",
      "Epoch 302/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.5805 - accuracy: 0.9018 - val_loss: 0.6314 - val_accuracy: 0.8829\n",
      "Epoch 303/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5805 - accuracy: 0.9018 - val_loss: 0.6314 - val_accuracy: 0.8829\n",
      "Epoch 304/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5805 - accuracy: 0.9018 - val_loss: 0.6313 - val_accuracy: 0.8829\n",
      "Epoch 305/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5804 - accuracy: 0.9013 - val_loss: 0.6312 - val_accuracy: 0.8829\n",
      "Epoch 306/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5804 - accuracy: 0.9013 - val_loss: 0.6312 - val_accuracy: 0.8829\n",
      "Epoch 307/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5804 - accuracy: 0.9013 - val_loss: 0.6311 - val_accuracy: 0.8829\n",
      "Epoch 308/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5804 - accuracy: 0.9013 - val_loss: 0.6311 - val_accuracy: 0.8829\n",
      "Epoch 309/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5804 - accuracy: 0.9013 - val_loss: 0.6310 - val_accuracy: 0.8829\n",
      "Epoch 310/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5804 - accuracy: 0.9013 - val_loss: 0.6309 - val_accuracy: 0.8829\n",
      "Epoch 311/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5803 - accuracy: 0.9013 - val_loss: 0.6309 - val_accuracy: 0.8829\n",
      "Epoch 312/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5803 - accuracy: 0.9013 - val_loss: 0.6308 - val_accuracy: 0.8829\n",
      "Epoch 313/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5803 - accuracy: 0.9013 - val_loss: 0.6308 - val_accuracy: 0.8829\n",
      "Epoch 314/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.5803 - accuracy: 0.9018 - val_loss: 0.6307 - val_accuracy: 0.8829\n",
      "Epoch 315/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5803 - accuracy: 0.9018 - val_loss: 0.6307 - val_accuracy: 0.8829\n",
      "Epoch 316/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5803 - accuracy: 0.9018 - val_loss: 0.6306 - val_accuracy: 0.8829\n",
      "Epoch 317/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5803 - accuracy: 0.9018 - val_loss: 0.6306 - val_accuracy: 0.8829\n",
      "Epoch 318/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5802 - accuracy: 0.9018 - val_loss: 0.6305 - val_accuracy: 0.8829\n",
      "Epoch 319/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5802 - accuracy: 0.9013 - val_loss: 0.6305 - val_accuracy: 0.8829\n",
      "Epoch 320/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5802 - accuracy: 0.9013 - val_loss: 0.6304 - val_accuracy: 0.8829\n",
      "Epoch 321/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5802 - accuracy: 0.9013 - val_loss: 0.6304 - val_accuracy: 0.8829\n",
      "Epoch 322/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5802 - accuracy: 0.9013 - val_loss: 0.6304 - val_accuracy: 0.8829\n",
      "Epoch 323/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5802 - accuracy: 0.9013 - val_loss: 0.6303 - val_accuracy: 0.8829\n",
      "Epoch 324/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5801 - accuracy: 0.9013 - val_loss: 0.6303 - val_accuracy: 0.8829\n",
      "Epoch 325/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5801 - accuracy: 0.9013 - val_loss: 0.6302 - val_accuracy: 0.8829\n",
      "Epoch 326/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5801 - accuracy: 0.9013 - val_loss: 0.6302 - val_accuracy: 0.8829\n",
      "Epoch 327/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5801 - accuracy: 0.9013 - val_loss: 0.6301 - val_accuracy: 0.8829\n",
      "Epoch 328/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5801 - accuracy: 0.9013 - val_loss: 0.6301 - val_accuracy: 0.8829\n",
      "Epoch 329/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5801 - accuracy: 0.9013 - val_loss: 0.6301 - val_accuracy: 0.8829\n",
      "Epoch 330/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5801 - accuracy: 0.9013 - val_loss: 0.6300 - val_accuracy: 0.8829\n",
      "Epoch 331/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5800 - accuracy: 0.9013 - val_loss: 0.6300 - val_accuracy: 0.8829\n",
      "Epoch 332/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5800 - accuracy: 0.9018 - val_loss: 0.6299 - val_accuracy: 0.8829\n",
      "Epoch 333/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5800 - accuracy: 0.9013 - val_loss: 0.6299 - val_accuracy: 0.8829\n",
      "Epoch 334/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5800 - accuracy: 0.9013 - val_loss: 0.6299 - val_accuracy: 0.8829\n",
      "Epoch 335/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.5800 - accuracy: 0.9018 - val_loss: 0.6298 - val_accuracy: 0.8829\n",
      "Epoch 336/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5800 - accuracy: 0.9018 - val_loss: 0.6298 - val_accuracy: 0.8829\n",
      "Epoch 337/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5800 - accuracy: 0.9018 - val_loss: 0.6297 - val_accuracy: 0.8829\n",
      "Epoch 338/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5799 - accuracy: 0.9018 - val_loss: 0.6297 - val_accuracy: 0.8829\n",
      "Epoch 339/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5799 - accuracy: 0.9018 - val_loss: 0.6297 - val_accuracy: 0.8829\n",
      "Epoch 340/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5799 - accuracy: 0.9018 - val_loss: 0.6296 - val_accuracy: 0.8829\n",
      "Epoch 341/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5799 - accuracy: 0.9018 - val_loss: 0.6296 - val_accuracy: 0.8829\n",
      "Epoch 342/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5799 - accuracy: 0.9018 - val_loss: 0.6296 - val_accuracy: 0.8829\n",
      "Epoch 343/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5799 - accuracy: 0.9018 - val_loss: 0.6295 - val_accuracy: 0.8829\n",
      "Epoch 344/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5799 - accuracy: 0.9018 - val_loss: 0.6295 - val_accuracy: 0.8829\n",
      "Epoch 345/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.5798 - accuracy: 0.9018 - val_loss: 0.6295 - val_accuracy: 0.8829\n",
      "Epoch 346/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5798 - accuracy: 0.9018 - val_loss: 0.6294 - val_accuracy: 0.8829\n",
      "Epoch 347/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5798 - accuracy: 0.9023 - val_loss: 0.6294 - val_accuracy: 0.8829\n",
      "Epoch 348/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5798 - accuracy: 0.9023 - val_loss: 0.6294 - val_accuracy: 0.8829\n",
      "Epoch 349/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5798 - accuracy: 0.9023 - val_loss: 0.6293 - val_accuracy: 0.8829\n",
      "Epoch 350/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5798 - accuracy: 0.9023 - val_loss: 0.6293 - val_accuracy: 0.8829\n",
      "Epoch 351/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5798 - accuracy: 0.9023 - val_loss: 0.6293 - val_accuracy: 0.8829\n",
      "Epoch 352/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5797 - accuracy: 0.9023 - val_loss: 0.6292 - val_accuracy: 0.8829\n",
      "Epoch 353/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5797 - accuracy: 0.9023 - val_loss: 0.6292 - val_accuracy: 0.8829\n",
      "Epoch 354/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5797 - accuracy: 0.9023 - val_loss: 0.6292 - val_accuracy: 0.8829\n",
      "Epoch 355/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5797 - accuracy: 0.9023 - val_loss: 0.6291 - val_accuracy: 0.8829\n",
      "Epoch 356/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5797 - accuracy: 0.9023 - val_loss: 0.6291 - val_accuracy: 0.8829\n",
      "Epoch 357/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5797 - accuracy: 0.9023 - val_loss: 0.6291 - val_accuracy: 0.8829\n",
      "Epoch 358/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5797 - accuracy: 0.9023 - val_loss: 0.6290 - val_accuracy: 0.8829\n",
      "Epoch 359/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5797 - accuracy: 0.9023 - val_loss: 0.6290 - val_accuracy: 0.8829\n",
      "Epoch 360/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5796 - accuracy: 0.9023 - val_loss: 0.6290 - val_accuracy: 0.8829\n",
      "Epoch 361/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5796 - accuracy: 0.9023 - val_loss: 0.6290 - val_accuracy: 0.8829\n",
      "Epoch 362/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5796 - accuracy: 0.9023 - val_loss: 0.6289 - val_accuracy: 0.8829\n",
      "Epoch 363/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5796 - accuracy: 0.9023 - val_loss: 0.6289 - val_accuracy: 0.8829\n",
      "Epoch 364/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5796 - accuracy: 0.9023 - val_loss: 0.6175 - val_accuracy: 0.8829\n",
      "Epoch 365/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5796 - accuracy: 0.9023 - val_loss: 0.6158 - val_accuracy: 0.8829\n",
      "Epoch 366/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5796 - accuracy: 0.9033 - val_loss: 0.6149 - val_accuracy: 0.8849\n",
      "Epoch 367/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5796 - accuracy: 0.9033 - val_loss: 0.6143 - val_accuracy: 0.8849\n",
      "Epoch 368/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5795 - accuracy: 0.9033 - val_loss: 0.6138 - val_accuracy: 0.8849\n",
      "Epoch 369/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5795 - accuracy: 0.9038 - val_loss: 0.6134 - val_accuracy: 0.8849\n",
      "Epoch 370/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5795 - accuracy: 0.9038 - val_loss: 0.6130 - val_accuracy: 0.8849\n",
      "Epoch 371/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5795 - accuracy: 0.9038 - val_loss: 0.6127 - val_accuracy: 0.8849\n",
      "Epoch 372/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5795 - accuracy: 0.9038 - val_loss: 0.6125 - val_accuracy: 0.8849\n",
      "Epoch 373/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5795 - accuracy: 0.9038 - val_loss: 0.6122 - val_accuracy: 0.8849\n",
      "Epoch 374/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.5795 - accuracy: 0.9038 - val_loss: 0.6120 - val_accuracy: 0.8849\n",
      "Epoch 375/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5795 - accuracy: 0.9038 - val_loss: 0.6118 - val_accuracy: 0.8869\n",
      "Epoch 376/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5794 - accuracy: 0.9038 - val_loss: 0.6116 - val_accuracy: 0.8869\n",
      "Epoch 377/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5794 - accuracy: 0.9038 - val_loss: 0.6114 - val_accuracy: 0.8869\n",
      "Epoch 378/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5794 - accuracy: 0.9038 - val_loss: 0.6113 - val_accuracy: 0.8869\n",
      "Epoch 379/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5794 - accuracy: 0.9038 - val_loss: 0.6111 - val_accuracy: 0.8869\n",
      "Epoch 380/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5794 - accuracy: 0.9038 - val_loss: 0.6110 - val_accuracy: 0.8869\n",
      "Epoch 381/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5794 - accuracy: 0.9038 - val_loss: 0.6108 - val_accuracy: 0.8869\n",
      "Epoch 382/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5794 - accuracy: 0.9038 - val_loss: 0.6107 - val_accuracy: 0.8869\n",
      "Epoch 383/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5794 - accuracy: 0.9038 - val_loss: 0.6106 - val_accuracy: 0.8869\n",
      "Epoch 384/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5793 - accuracy: 0.9038 - val_loss: 0.6105 - val_accuracy: 0.8869\n",
      "Epoch 385/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5793 - accuracy: 0.9038 - val_loss: 0.6103 - val_accuracy: 0.8869\n",
      "Epoch 386/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5793 - accuracy: 0.9038 - val_loss: 0.6102 - val_accuracy: 0.8869\n",
      "Epoch 387/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5793 - accuracy: 0.9038 - val_loss: 0.6101 - val_accuracy: 0.8869\n",
      "Epoch 388/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5793 - accuracy: 0.9038 - val_loss: 0.6100 - val_accuracy: 0.8869\n",
      "Epoch 389/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5793 - accuracy: 0.9038 - val_loss: 0.6099 - val_accuracy: 0.8869\n",
      "Epoch 390/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5793 - accuracy: 0.9038 - val_loss: 0.6098 - val_accuracy: 0.8869\n",
      "Epoch 391/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5793 - accuracy: 0.9038 - val_loss: 0.6097 - val_accuracy: 0.8869\n",
      "Epoch 392/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5792 - accuracy: 0.9038 - val_loss: 0.6096 - val_accuracy: 0.8869\n",
      "Epoch 393/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5792 - accuracy: 0.9038 - val_loss: 0.6095 - val_accuracy: 0.8869\n",
      "Epoch 394/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5792 - accuracy: 0.9038 - val_loss: 0.6095 - val_accuracy: 0.8869\n",
      "Epoch 395/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5792 - accuracy: 0.9038 - val_loss: 0.6094 - val_accuracy: 0.8869\n",
      "Epoch 396/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5792 - accuracy: 0.9038 - val_loss: 0.6093 - val_accuracy: 0.8869\n",
      "Epoch 397/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5792 - accuracy: 0.9038 - val_loss: 0.6092 - val_accuracy: 0.8869\n",
      "Epoch 398/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5792 - accuracy: 0.9038 - val_loss: 0.6091 - val_accuracy: 0.8869\n",
      "Epoch 399/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5792 - accuracy: 0.9038 - val_loss: 0.6091 - val_accuracy: 0.8869\n",
      "Epoch 400/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5792 - accuracy: 0.9038 - val_loss: 0.6090 - val_accuracy: 0.8869\n",
      "Epoch 401/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5791 - accuracy: 0.9038 - val_loss: 0.6089 - val_accuracy: 0.8869\n",
      "Epoch 402/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5791 - accuracy: 0.9038 - val_loss: 0.6088 - val_accuracy: 0.8869\n",
      "Epoch 403/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5791 - accuracy: 0.9038 - val_loss: 0.6088 - val_accuracy: 0.8869\n",
      "Epoch 404/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5791 - accuracy: 0.9038 - val_loss: 0.6087 - val_accuracy: 0.8869\n",
      "Epoch 405/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5791 - accuracy: 0.9038 - val_loss: 0.6086 - val_accuracy: 0.8869\n",
      "Epoch 406/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5791 - accuracy: 0.9038 - val_loss: 0.6086 - val_accuracy: 0.8869\n",
      "Epoch 407/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5791 - accuracy: 0.9038 - val_loss: 0.6085 - val_accuracy: 0.8869\n",
      "Epoch 408/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5791 - accuracy: 0.9038 - val_loss: 0.6084 - val_accuracy: 0.8869\n",
      "Epoch 409/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5791 - accuracy: 0.9038 - val_loss: 0.6084 - val_accuracy: 0.8869\n",
      "Epoch 410/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.5790 - accuracy: 0.9038 - val_loss: 0.6083 - val_accuracy: 0.8869\n",
      "Epoch 411/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5790 - accuracy: 0.9038 - val_loss: 0.6082 - val_accuracy: 0.8869\n",
      "Epoch 412/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5790 - accuracy: 0.9038 - val_loss: 0.6082 - val_accuracy: 0.8869\n",
      "Epoch 413/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5790 - accuracy: 0.9038 - val_loss: 0.6081 - val_accuracy: 0.8869\n",
      "Epoch 414/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5790 - accuracy: 0.9038 - val_loss: 0.6081 - val_accuracy: 0.8869\n",
      "Epoch 415/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5790 - accuracy: 0.9038 - val_loss: 0.6080 - val_accuracy: 0.8869\n",
      "Epoch 416/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5790 - accuracy: 0.9038 - val_loss: 0.6080 - val_accuracy: 0.8869\n",
      "Epoch 417/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.5789 - accuracy: 0.9038 - val_loss: 0.6079 - val_accuracy: 0.8869\n",
      "Epoch 418/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5789 - accuracy: 0.9038 - val_loss: 0.6079 - val_accuracy: 0.8869\n",
      "Epoch 419/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5789 - accuracy: 0.9038 - val_loss: 0.6078 - val_accuracy: 0.8869\n",
      "Epoch 420/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5789 - accuracy: 0.9038 - val_loss: 0.6078 - val_accuracy: 0.8869\n",
      "Epoch 421/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5789 - accuracy: 0.9038 - val_loss: 0.6077 - val_accuracy: 0.8869\n",
      "Epoch 422/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5789 - accuracy: 0.9038 - val_loss: 0.6077 - val_accuracy: 0.8869\n",
      "Epoch 423/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5789 - accuracy: 0.9038 - val_loss: 0.6076 - val_accuracy: 0.8869\n",
      "Epoch 424/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5788 - accuracy: 0.9038 - val_loss: 0.6076 - val_accuracy: 0.8869\n",
      "Epoch 425/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5788 - accuracy: 0.9038 - val_loss: 0.6075 - val_accuracy: 0.8869\n",
      "Epoch 426/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5788 - accuracy: 0.9038 - val_loss: 0.6075 - val_accuracy: 0.8869\n",
      "Epoch 427/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5788 - accuracy: 0.9038 - val_loss: 0.6074 - val_accuracy: 0.8869\n",
      "Epoch 428/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5788 - accuracy: 0.9038 - val_loss: 0.6074 - val_accuracy: 0.8869\n",
      "Epoch 429/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5788 - accuracy: 0.9038 - val_loss: 0.6073 - val_accuracy: 0.8869\n",
      "Epoch 430/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5788 - accuracy: 0.9038 - val_loss: 0.6073 - val_accuracy: 0.8869\n",
      "Epoch 431/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5788 - accuracy: 0.9038 - val_loss: 0.6073 - val_accuracy: 0.8869\n",
      "Epoch 432/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5787 - accuracy: 0.9038 - val_loss: 0.6072 - val_accuracy: 0.8869\n",
      "Epoch 433/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5787 - accuracy: 0.9038 - val_loss: 0.6072 - val_accuracy: 0.8869\n",
      "Epoch 434/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5787 - accuracy: 0.9038 - val_loss: 0.6071 - val_accuracy: 0.8869\n",
      "Epoch 435/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5787 - accuracy: 0.9038 - val_loss: 0.6071 - val_accuracy: 0.8869\n",
      "Epoch 436/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5787 - accuracy: 0.9038 - val_loss: 0.6071 - val_accuracy: 0.8869\n",
      "Epoch 437/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5787 - accuracy: 0.9038 - val_loss: 0.6070 - val_accuracy: 0.8869\n",
      "Epoch 438/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5787 - accuracy: 0.9038 - val_loss: 0.6070 - val_accuracy: 0.8869\n",
      "Epoch 439/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5786 - accuracy: 0.9038 - val_loss: 0.6069 - val_accuracy: 0.8869\n",
      "Epoch 440/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5786 - accuracy: 0.9038 - val_loss: 0.6069 - val_accuracy: 0.8869\n",
      "Epoch 441/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5786 - accuracy: 0.9038 - val_loss: 0.6069 - val_accuracy: 0.8869\n",
      "Epoch 442/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5786 - accuracy: 0.9038 - val_loss: 0.6068 - val_accuracy: 0.8869\n",
      "Epoch 443/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5786 - accuracy: 0.9038 - val_loss: 0.6068 - val_accuracy: 0.8869\n",
      "Epoch 444/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5786 - accuracy: 0.9038 - val_loss: 0.6068 - val_accuracy: 0.8869\n",
      "Epoch 445/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5786 - accuracy: 0.9038 - val_loss: 0.6067 - val_accuracy: 0.8869\n",
      "Epoch 446/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5786 - accuracy: 0.9038 - val_loss: 0.6067 - val_accuracy: 0.8869\n",
      "Epoch 447/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5785 - accuracy: 0.9038 - val_loss: 0.6067 - val_accuracy: 0.8869\n",
      "Epoch 448/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5785 - accuracy: 0.9038 - val_loss: 0.6066 - val_accuracy: 0.8869\n",
      "Epoch 449/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5785 - accuracy: 0.9038 - val_loss: 0.6066 - val_accuracy: 0.8889\n",
      "Epoch 450/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5785 - accuracy: 0.9048 - val_loss: 0.6066 - val_accuracy: 0.8889\n",
      "Epoch 451/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5785 - accuracy: 0.9048 - val_loss: 0.6065 - val_accuracy: 0.8889\n",
      "Epoch 452/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5785 - accuracy: 0.9048 - val_loss: 0.6065 - val_accuracy: 0.8889\n",
      "Epoch 453/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5785 - accuracy: 0.9048 - val_loss: 0.6065 - val_accuracy: 0.8889\n",
      "Epoch 454/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5785 - accuracy: 0.9048 - val_loss: 0.6064 - val_accuracy: 0.8889\n",
      "Epoch 455/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5784 - accuracy: 0.9048 - val_loss: 0.6064 - val_accuracy: 0.8889\n",
      "Epoch 456/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5784 - accuracy: 0.9048 - val_loss: 0.6064 - val_accuracy: 0.8889\n",
      "Epoch 457/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.5784 - accuracy: 0.9048 - val_loss: 0.6063 - val_accuracy: 0.8889\n",
      "Epoch 458/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5784 - accuracy: 0.9048 - val_loss: 0.6063 - val_accuracy: 0.8889\n",
      "Epoch 459/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5784 - accuracy: 0.9048 - val_loss: 0.6063 - val_accuracy: 0.8889\n",
      "Epoch 460/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5784 - accuracy: 0.9048 - val_loss: 0.6062 - val_accuracy: 0.8889\n",
      "Epoch 461/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5784 - accuracy: 0.9048 - val_loss: 0.6062 - val_accuracy: 0.8889\n",
      "Epoch 462/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5784 - accuracy: 0.9048 - val_loss: 0.6062 - val_accuracy: 0.8889\n",
      "Epoch 463/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5783 - accuracy: 0.9048 - val_loss: 0.6061 - val_accuracy: 0.8889\n",
      "Epoch 464/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5783 - accuracy: 0.9048 - val_loss: 0.6061 - val_accuracy: 0.8889\n",
      "Epoch 465/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5783 - accuracy: 0.9048 - val_loss: 0.6061 - val_accuracy: 0.8889\n",
      "Epoch 466/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5783 - accuracy: 0.9048 - val_loss: 0.6060 - val_accuracy: 0.8889\n",
      "Epoch 467/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5783 - accuracy: 0.9048 - val_loss: 0.6060 - val_accuracy: 0.8889\n",
      "Epoch 468/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5783 - accuracy: 0.9048 - val_loss: 0.6060 - val_accuracy: 0.8889\n",
      "Epoch 469/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5783 - accuracy: 0.9048 - val_loss: 0.6060 - val_accuracy: 0.8889\n",
      "Epoch 470/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5783 - accuracy: 0.9048 - val_loss: 0.6059 - val_accuracy: 0.8889\n",
      "Epoch 471/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5783 - accuracy: 0.9048 - val_loss: 0.6059 - val_accuracy: 0.8889\n",
      "Epoch 472/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5782 - accuracy: 0.9048 - val_loss: 0.6059 - val_accuracy: 0.8889\n",
      "Epoch 473/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5782 - accuracy: 0.9048 - val_loss: 0.6058 - val_accuracy: 0.8889\n",
      "Epoch 474/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5782 - accuracy: 0.9048 - val_loss: 0.6058 - val_accuracy: 0.8889\n",
      "Epoch 475/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5782 - accuracy: 0.9048 - val_loss: 0.6058 - val_accuracy: 0.8889\n",
      "Epoch 476/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5782 - accuracy: 0.9048 - val_loss: 0.6058 - val_accuracy: 0.8889\n",
      "Epoch 477/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5782 - accuracy: 0.9048 - val_loss: 0.6057 - val_accuracy: 0.8889\n",
      "Epoch 478/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5782 - accuracy: 0.9048 - val_loss: 0.6057 - val_accuracy: 0.8889\n",
      "Epoch 479/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5782 - accuracy: 0.9048 - val_loss: 0.6057 - val_accuracy: 0.8889\n",
      "Epoch 480/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.5781 - accuracy: 0.9048 - val_loss: 0.6056 - val_accuracy: 0.8889\n",
      "Epoch 481/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5781 - accuracy: 0.9048 - val_loss: 0.6056 - val_accuracy: 0.8889\n",
      "Epoch 482/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5781 - accuracy: 0.9048 - val_loss: 0.6056 - val_accuracy: 0.8889\n",
      "Epoch 483/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5781 - accuracy: 0.9048 - val_loss: 0.6056 - val_accuracy: 0.8889\n",
      "Epoch 484/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5781 - accuracy: 0.9048 - val_loss: 0.6055 - val_accuracy: 0.8889\n",
      "Epoch 485/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5781 - accuracy: 0.9048 - val_loss: 0.6055 - val_accuracy: 0.8889\n",
      "Epoch 486/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5781 - accuracy: 0.9048 - val_loss: 0.6055 - val_accuracy: 0.8889\n",
      "Epoch 487/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5781 - accuracy: 0.9048 - val_loss: 0.6055 - val_accuracy: 0.8889\n",
      "Epoch 488/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5781 - accuracy: 0.9048 - val_loss: 0.6054 - val_accuracy: 0.8889\n",
      "Epoch 489/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5780 - accuracy: 0.9048 - val_loss: 0.6054 - val_accuracy: 0.8889\n",
      "Epoch 490/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5780 - accuracy: 0.9048 - val_loss: 0.6054 - val_accuracy: 0.8889\n",
      "Epoch 491/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5780 - accuracy: 0.9048 - val_loss: 0.6054 - val_accuracy: 0.8889\n",
      "Epoch 492/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5780 - accuracy: 0.9048 - val_loss: 0.6053 - val_accuracy: 0.8889\n",
      "Epoch 493/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5780 - accuracy: 0.9048 - val_loss: 0.6053 - val_accuracy: 0.8889\n",
      "Epoch 494/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5780 - accuracy: 0.9048 - val_loss: 0.6053 - val_accuracy: 0.8889\n",
      "Epoch 495/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5780 - accuracy: 0.9048 - val_loss: 0.6053 - val_accuracy: 0.8909\n",
      "Epoch 496/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5780 - accuracy: 0.9048 - val_loss: 0.6052 - val_accuracy: 0.8909\n",
      "Epoch 497/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5780 - accuracy: 0.9048 - val_loss: 0.6052 - val_accuracy: 0.8909\n",
      "Epoch 498/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5779 - accuracy: 0.9048 - val_loss: 0.6052 - val_accuracy: 0.8909\n",
      "Epoch 499/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5779 - accuracy: 0.9048 - val_loss: 0.6052 - val_accuracy: 0.8909\n",
      "Epoch 500/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.5779 - accuracy: 0.9048 - val_loss: 0.6051 - val_accuracy: 0.8909\n",
      "20/20 [==============================] - 0s 841us/step\n",
      "Epoch 1/100\n",
      "63/63 [==============================] - 1s 4ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 2/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 3/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 4/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 5/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 6/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 7/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 8/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 9/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 10/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 11/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 12/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 13/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 14/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 15/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 16/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 17/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 18/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 19/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 20/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 21/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 22/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 23/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 24/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 25/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 26/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 27/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 28/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 29/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 30/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 31/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 32/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 33/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 34/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 35/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 36/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 37/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 38/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 39/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 40/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 41/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 78/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "20/20 [==============================] - 0s 883us/step\n",
      "Epoch 1/250\n",
      "63/63 [==============================] - 1s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 2/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 3/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 4/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 5/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 6/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 7/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 8/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 9/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 10/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 11/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 12/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 13/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 14/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 15/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 16/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 17/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 18/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 19/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 20/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 21/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 22/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 23/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 24/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 26/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 27/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 28/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 29/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 30/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 31/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 32/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 33/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 34/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 35/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 36/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 37/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 38/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 39/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 40/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 41/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 42/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 43/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 44/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 45/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 46/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 47/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 48/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 49/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 50/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 51/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 52/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 53/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 54/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 55/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 56/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 57/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 58/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 59/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 60/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 61/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 62/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 63/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 64/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 65/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 66/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 67/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 68/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 69/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 70/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 71/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 72/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 73/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 74/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 75/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 76/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 77/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 78/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 79/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 80/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 81/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 82/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 83/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 84/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 85/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 86/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 87/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 88/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 89/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 90/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 91/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 92/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 93/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 94/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 95/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 96/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 97/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 98/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 99/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 100/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 101/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 102/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 103/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 104/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 105/250\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 106/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 107/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 108/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 109/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 110/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 111/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 112/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 113/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 114/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 115/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 116/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 117/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 118/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 119/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 120/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 121/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 122/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 123/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 124/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 125/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 126/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 127/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 128/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 129/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 130/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 131/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 132/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 133/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 134/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 135/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 136/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 137/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 138/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 139/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 140/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 141/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 142/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 143/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 144/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 145/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 146/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 147/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 148/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 149/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 150/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 151/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 152/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 153/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 154/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 155/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 156/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 157/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 158/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 159/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 160/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 161/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 162/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 163/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 164/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 165/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 166/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 167/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 168/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 169/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 170/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 171/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 172/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 173/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 174/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 175/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 176/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 177/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 178/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 179/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 180/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 181/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 182/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 183/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 184/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 185/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 186/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 187/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 188/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 189/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 190/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 191/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 192/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 193/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 194/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 195/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 196/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 197/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 198/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 199/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 200/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 201/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 202/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 203/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 204/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 205/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 206/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 207/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 208/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 209/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 210/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 211/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 212/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 213/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 214/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 215/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 216/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 217/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 218/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 219/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 220/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 221/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 222/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 223/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 224/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 225/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 226/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 227/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 228/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 229/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 230/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 231/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 232/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 233/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 234/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 235/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 236/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 237/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 238/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 239/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 240/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 241/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 242/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 243/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 244/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 245/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 246/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 247/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 248/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 249/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 250/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "20/20 [==============================] - 0s 1ms/step\n",
      "Epoch 1/500\n",
      "63/63 [==============================] - 1s 4ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 2/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 3/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 4/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 5/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 6/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 7/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 8/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 9/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 10/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 11/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 12/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 13/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 14/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 15/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 16/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 17/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 18/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 19/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 20/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 21/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 22/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 23/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 24/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 25/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 26/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 27/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 28/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 29/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 30/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 31/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 32/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 33/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 34/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 35/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 36/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 37/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 38/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 39/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 40/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 41/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 42/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 43/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 44/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 45/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 46/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 47/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 48/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 49/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 50/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 51/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 52/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 53/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 54/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 55/500\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 56/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 57/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 58/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 59/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 60/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 61/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 62/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 63/500\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 64/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 65/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 66/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 67/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 68/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 69/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 70/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 71/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 72/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 73/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 74/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 75/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 76/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 77/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 78/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 79/500\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 80/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 81/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 82/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 83/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 84/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 85/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 86/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 87/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 88/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 89/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 90/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 91/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 92/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 93/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 94/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 95/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 96/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 97/500\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 98/500\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 99/500\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 100/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 101/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 102/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 103/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 104/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 105/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 106/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 107/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 108/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 109/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 110/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 111/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 112/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 113/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 114/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 115/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 116/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 117/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 118/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 119/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 120/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 121/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 122/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 123/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 124/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 125/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 126/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 127/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 128/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 129/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 130/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 131/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 132/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 133/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 134/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 135/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 136/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 137/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 138/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 139/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 140/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 141/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 142/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 143/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 144/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 145/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 146/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 147/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 148/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 149/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 150/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 151/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 152/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 153/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 154/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 155/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 156/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 157/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 158/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 159/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 160/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 161/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 162/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 163/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 164/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 165/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 166/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 167/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 168/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 169/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 170/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 171/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 172/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 173/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 174/500\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 175/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 176/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 177/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 178/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 179/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 180/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 181/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 182/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 183/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 184/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 185/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 186/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 187/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 188/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 189/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 190/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 191/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 192/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 193/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 194/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 195/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 196/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 197/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 198/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 199/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 200/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 201/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 202/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 203/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 204/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 205/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 206/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 207/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 208/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 209/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 210/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 211/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 212/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 213/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 214/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 215/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 216/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 217/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 218/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 219/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 220/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 221/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 222/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 223/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 224/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 225/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 226/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 227/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 228/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 229/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 230/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 231/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 232/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 233/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 234/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 235/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 236/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 237/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 238/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 239/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 240/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 241/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 242/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 243/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 244/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 245/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 246/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 247/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 248/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 249/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 250/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 251/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 252/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 253/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 254/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 255/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 256/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 257/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 258/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 259/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 260/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 261/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 262/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 263/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 264/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 265/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 266/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 267/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 268/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 269/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 270/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 271/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 272/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 273/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 274/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 275/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 276/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 277/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 278/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 279/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 280/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 281/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 282/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 283/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 284/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 285/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 286/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 287/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 288/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 289/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 290/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 291/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 292/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 293/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 294/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 295/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 296/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 297/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 298/500\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 299/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 300/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 301/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 302/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 303/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 304/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 305/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 306/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 307/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 308/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 309/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 310/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 311/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 312/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 313/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 314/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 315/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 316/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 317/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 318/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 319/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 320/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 321/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 322/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 323/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 324/500\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 325/500\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 326/500\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 327/500\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 328/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 329/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 330/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 331/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 332/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 333/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 334/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 335/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 336/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 337/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 338/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 339/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 340/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 341/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 342/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 343/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 344/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 345/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 346/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 347/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 348/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 349/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 350/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 351/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 352/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 353/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 354/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 355/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 356/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 357/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 358/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 359/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 360/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 361/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 362/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 363/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 364/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 365/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 366/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 367/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 368/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 369/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 370/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 371/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 372/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 373/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 374/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 375/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 376/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 377/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 378/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 379/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 380/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 381/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 382/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 383/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 384/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 385/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 386/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 387/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 388/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 389/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 390/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 391/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 392/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 393/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 394/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 395/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 396/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 397/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 398/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 399/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 400/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 401/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 402/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 403/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 404/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 405/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 406/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 407/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 408/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 409/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 410/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 411/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 412/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 413/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 414/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 415/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 416/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 417/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 418/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 419/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 420/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 421/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 422/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 423/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 424/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 425/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 426/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 427/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 428/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 429/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 430/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 431/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 432/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 433/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 434/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 435/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 436/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 437/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 438/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 439/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 440/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 441/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 442/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 443/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 444/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 445/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 446/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 447/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 448/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 449/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 450/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 451/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 452/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 453/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 454/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 455/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 456/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 457/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 458/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 459/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 460/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 461/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 462/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 463/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 464/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 465/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 466/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 467/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 468/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 469/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 470/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 471/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 472/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 473/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 474/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 475/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 476/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 477/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 478/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 479/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 480/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 481/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 482/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 483/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 484/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 485/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 486/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 487/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 488/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 489/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 490/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 491/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 492/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 493/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 494/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 495/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 496/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 497/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 498/500\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 499/500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 500/500\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8449e-08 - categorical_accuracy: 1.0000 - val_loss: 1.7503e-08 - val_categorical_accuracy: 1.0000\n",
      "20/20 [==============================] - 0s 1ms/step\n",
      "0.8888888888888888 sigmoid binary_crossentropy accuracy 250\n"
     ]
    }
   ],
   "source": [
    "best_acc = 0\n",
    "best_act = None\n",
    "best_loss_func = None\n",
    "acc_metric = None\n",
    "epoch_count = None\n",
    "\n",
    "activation =  [\n",
    "    'sigmoid',\n",
    "    'relu',\n",
    "    'leaky_relu'\n",
    "]\n",
    "\n",
    "for i in range(len(activation)):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=13, activation='relu', input_dim=13))\n",
    "    model.add(Dense(units=7, activation='relu', input_dim=7))\n",
    "    model.add(Dense(units=1, activation=activation[i]))\n",
    "    \n",
    "    loss_function= ['binary_crossentropy', 'categorical_crossentropy']\n",
    "    acc_score = ['accuracy','categorical_accuracy']\n",
    "    for k in range(len(loss_function)):\n",
    "        epoch_range = [100, 250, 500]\n",
    "        for l in range(len(epoch_range)):\n",
    "            model.compile(loss=loss_function[k], optimizer= keras.optimizers.Adagrad() , metrics=acc_score[k])\n",
    "            model.fit(X_train_scaled, y_train, epochs = epoch_range[l], validation_split=0.2)\n",
    "            y_log = model.predict(X_test_scaled)\n",
    "            y_pred = np.where(y_log > 0.5, 1, 0)\n",
    "            acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "            if acc > best_acc:\n",
    "                best_loss_func = loss_function[k]\n",
    "                best_act = activation[i]\n",
    "                best_acc = acc\n",
    "                acc_metric = acc_score[k]\n",
    "                epoch_count = epoch_range[l]\n",
    "            \n",
    "print(best_acc , best_act, best_loss_func, acc_metric, epoch_count)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd20f853",
   "metadata": {},
   "source": [
    "\n",
    "<b>best in accuracy:</b> 0.8888888888888888 sigmoid binary_crossentropy accuracy 250 7 layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "a9334f15",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "63/63 [==============================] - 1s 4ms/step - loss: 0.6650 - accuracy: 0.6815 - val_loss: 0.6512 - val_accuracy: 0.6885\n",
      "Epoch 2/250\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.6220 - accuracy: 0.7326 - val_loss: 0.6182 - val_accuracy: 0.7083\n",
      "Epoch 3/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.5948 - accuracy: 0.7505 - val_loss: 0.5943 - val_accuracy: 0.7401\n",
      "Epoch 4/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.5743 - accuracy: 0.7713 - val_loss: 0.5756 - val_accuracy: 0.7579\n",
      "Epoch 5/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5578 - accuracy: 0.8001 - val_loss: 0.5601 - val_accuracy: 0.7937\n",
      "Epoch 6/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5440 - accuracy: 0.8249 - val_loss: 0.5469 - val_accuracy: 0.8214\n",
      "Epoch 7/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.5321 - accuracy: 0.8353 - val_loss: 0.5354 - val_accuracy: 0.8373\n",
      "Epoch 8/250\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.5216 - accuracy: 0.8418 - val_loss: 0.5252 - val_accuracy: 0.8472\n",
      "Epoch 9/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5123 - accuracy: 0.8462 - val_loss: 0.5160 - val_accuracy: 0.8472\n",
      "Epoch 10/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.8472 - val_loss: 0.5076 - val_accuracy: 0.8492\n",
      "Epoch 11/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4963 - accuracy: 0.8467 - val_loss: 0.5000 - val_accuracy: 0.8512\n",
      "Epoch 12/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4893 - accuracy: 0.8467 - val_loss: 0.4930 - val_accuracy: 0.8512\n",
      "Epoch 13/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4828 - accuracy: 0.8487 - val_loss: 0.4865 - val_accuracy: 0.8552\n",
      "Epoch 14/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4768 - accuracy: 0.8487 - val_loss: 0.4804 - val_accuracy: 0.8552\n",
      "Epoch 15/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4712 - accuracy: 0.8487 - val_loss: 0.4748 - val_accuracy: 0.8552\n",
      "Epoch 16/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4659 - accuracy: 0.8492 - val_loss: 0.4694 - val_accuracy: 0.8532\n",
      "Epoch 17/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4610 - accuracy: 0.8492 - val_loss: 0.4644 - val_accuracy: 0.8532\n",
      "Epoch 18/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4563 - accuracy: 0.8492 - val_loss: 0.4597 - val_accuracy: 0.8532\n",
      "Epoch 19/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.4519 - accuracy: 0.8487 - val_loss: 0.4552 - val_accuracy: 0.8532\n",
      "Epoch 20/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4477 - accuracy: 0.8487 - val_loss: 0.4509 - val_accuracy: 0.8532\n",
      "Epoch 21/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.4437 - accuracy: 0.8477 - val_loss: 0.4468 - val_accuracy: 0.8532\n",
      "Epoch 22/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.4399 - accuracy: 0.8482 - val_loss: 0.4429 - val_accuracy: 0.8532\n",
      "Epoch 23/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4363 - accuracy: 0.8482 - val_loss: 0.4392 - val_accuracy: 0.8552\n",
      "Epoch 24/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4328 - accuracy: 0.8482 - val_loss: 0.4356 - val_accuracy: 0.8552\n",
      "Epoch 25/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4295 - accuracy: 0.8482 - val_loss: 0.4322 - val_accuracy: 0.8552\n",
      "Epoch 26/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4263 - accuracy: 0.8482 - val_loss: 0.4289 - val_accuracy: 0.8552\n",
      "Epoch 27/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4232 - accuracy: 0.8482 - val_loss: 0.4258 - val_accuracy: 0.8552\n",
      "Epoch 28/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4203 - accuracy: 0.8482 - val_loss: 0.4228 - val_accuracy: 0.8552\n",
      "Epoch 29/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4174 - accuracy: 0.8482 - val_loss: 0.4198 - val_accuracy: 0.8552\n",
      "Epoch 30/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4147 - accuracy: 0.8482 - val_loss: 0.4170 - val_accuracy: 0.8552\n",
      "Epoch 31/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.4120 - accuracy: 0.8482 - val_loss: 0.4143 - val_accuracy: 0.8552\n",
      "Epoch 32/250\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.4095 - accuracy: 0.8482 - val_loss: 0.4117 - val_accuracy: 0.8552\n",
      "Epoch 33/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4070 - accuracy: 0.8482 - val_loss: 0.4091 - val_accuracy: 0.8552\n",
      "Epoch 34/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4046 - accuracy: 0.8482 - val_loss: 0.4067 - val_accuracy: 0.8552\n",
      "Epoch 35/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4023 - accuracy: 0.8482 - val_loss: 0.4043 - val_accuracy: 0.8552\n",
      "Epoch 36/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4000 - accuracy: 0.8482 - val_loss: 0.4020 - val_accuracy: 0.8552\n",
      "Epoch 37/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3978 - accuracy: 0.8482 - val_loss: 0.3997 - val_accuracy: 0.8552\n",
      "Epoch 38/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.3956 - accuracy: 0.8482 - val_loss: 0.3975 - val_accuracy: 0.8571\n",
      "Epoch 39/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.3936 - accuracy: 0.8497 - val_loss: 0.3954 - val_accuracy: 0.8571\n",
      "Epoch 40/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.3915 - accuracy: 0.8497 - val_loss: 0.3933 - val_accuracy: 0.8571\n",
      "Epoch 41/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.3896 - accuracy: 0.8497 - val_loss: 0.3913 - val_accuracy: 0.8571\n",
      "Epoch 42/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3876 - accuracy: 0.8497 - val_loss: 0.3894 - val_accuracy: 0.8571\n",
      "Epoch 43/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3858 - accuracy: 0.8497 - val_loss: 0.3875 - val_accuracy: 0.8571\n",
      "Epoch 44/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3839 - accuracy: 0.8507 - val_loss: 0.3856 - val_accuracy: 0.8571\n",
      "Epoch 45/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3822 - accuracy: 0.8507 - val_loss: 0.3838 - val_accuracy: 0.8571\n",
      "Epoch 46/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3804 - accuracy: 0.8512 - val_loss: 0.3820 - val_accuracy: 0.8571\n",
      "Epoch 47/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3787 - accuracy: 0.8512 - val_loss: 0.3803 - val_accuracy: 0.8571\n",
      "Epoch 48/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3771 - accuracy: 0.8517 - val_loss: 0.3786 - val_accuracy: 0.8571\n",
      "Epoch 49/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.3755 - accuracy: 0.8517 - val_loss: 0.3770 - val_accuracy: 0.8571\n",
      "Epoch 50/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3739 - accuracy: 0.8517 - val_loss: 0.3754 - val_accuracy: 0.8591\n",
      "Epoch 51/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3723 - accuracy: 0.8522 - val_loss: 0.3738 - val_accuracy: 0.8611\n",
      "Epoch 52/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3708 - accuracy: 0.8527 - val_loss: 0.3722 - val_accuracy: 0.8611\n",
      "Epoch 53/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3693 - accuracy: 0.8537 - val_loss: 0.3707 - val_accuracy: 0.8611\n",
      "Epoch 54/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.3679 - accuracy: 0.8532 - val_loss: 0.3693 - val_accuracy: 0.8611\n",
      "Epoch 55/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3665 - accuracy: 0.8532 - val_loss: 0.3678 - val_accuracy: 0.8611\n",
      "Epoch 56/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3651 - accuracy: 0.8537 - val_loss: 0.3664 - val_accuracy: 0.8611\n",
      "Epoch 57/250\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.3637 - accuracy: 0.8542 - val_loss: 0.3650 - val_accuracy: 0.8611\n",
      "Epoch 58/250\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.3624 - accuracy: 0.8537 - val_loss: 0.3636 - val_accuracy: 0.8611\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.3611 - accuracy: 0.8547 - val_loss: 0.3623 - val_accuracy: 0.8611\n",
      "Epoch 60/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3598 - accuracy: 0.8542 - val_loss: 0.3610 - val_accuracy: 0.8611\n",
      "Epoch 61/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3585 - accuracy: 0.8557 - val_loss: 0.3597 - val_accuracy: 0.8611\n",
      "Epoch 62/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3573 - accuracy: 0.8562 - val_loss: 0.3585 - val_accuracy: 0.8631\n",
      "Epoch 63/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3561 - accuracy: 0.8562 - val_loss: 0.3572 - val_accuracy: 0.8631\n",
      "Epoch 64/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.3549 - accuracy: 0.8566 - val_loss: 0.3560 - val_accuracy: 0.8631\n",
      "Epoch 65/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.3537 - accuracy: 0.8576 - val_loss: 0.3549 - val_accuracy: 0.8631\n",
      "Epoch 66/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.3526 - accuracy: 0.8586 - val_loss: 0.3537 - val_accuracy: 0.8631\n",
      "Epoch 67/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3514 - accuracy: 0.8581 - val_loss: 0.3526 - val_accuracy: 0.8631\n",
      "Epoch 68/250\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.3503 - accuracy: 0.8581 - val_loss: 0.3514 - val_accuracy: 0.8631\n",
      "Epoch 69/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3492 - accuracy: 0.8586 - val_loss: 0.3503 - val_accuracy: 0.8651\n",
      "Epoch 70/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3482 - accuracy: 0.8591 - val_loss: 0.3493 - val_accuracy: 0.8651\n",
      "Epoch 71/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.3471 - accuracy: 0.8621 - val_loss: 0.3482 - val_accuracy: 0.8671\n",
      "Epoch 72/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3461 - accuracy: 0.8631 - val_loss: 0.3472 - val_accuracy: 0.8671\n",
      "Epoch 73/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.3450 - accuracy: 0.8636 - val_loss: 0.3461 - val_accuracy: 0.8671\n",
      "Epoch 74/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.3440 - accuracy: 0.8641 - val_loss: 0.3451 - val_accuracy: 0.8671\n",
      "Epoch 75/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3430 - accuracy: 0.8641 - val_loss: 0.3442 - val_accuracy: 0.8690\n",
      "Epoch 76/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.3421 - accuracy: 0.8656 - val_loss: 0.3432 - val_accuracy: 0.8710\n",
      "Epoch 77/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3411 - accuracy: 0.8666 - val_loss: 0.3422 - val_accuracy: 0.8690\n",
      "Epoch 78/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3402 - accuracy: 0.8676 - val_loss: 0.3413 - val_accuracy: 0.8690\n",
      "Epoch 79/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3392 - accuracy: 0.8686 - val_loss: 0.3404 - val_accuracy: 0.8710\n",
      "Epoch 80/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3383 - accuracy: 0.8695 - val_loss: 0.3395 - val_accuracy: 0.8730\n",
      "Epoch 81/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.3374 - accuracy: 0.8710 - val_loss: 0.3386 - val_accuracy: 0.8730\n",
      "Epoch 82/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.3365 - accuracy: 0.8720 - val_loss: 0.3377 - val_accuracy: 0.8730\n",
      "Epoch 83/250\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.3356 - accuracy: 0.8725 - val_loss: 0.3368 - val_accuracy: 0.8750\n",
      "Epoch 84/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.3348 - accuracy: 0.8730 - val_loss: 0.3360 - val_accuracy: 0.8750\n",
      "Epoch 85/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3339 - accuracy: 0.8725 - val_loss: 0.3351 - val_accuracy: 0.8750\n",
      "Epoch 86/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.3331 - accuracy: 0.8730 - val_loss: 0.3343 - val_accuracy: 0.8750\n",
      "Epoch 87/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3323 - accuracy: 0.8735 - val_loss: 0.3335 - val_accuracy: 0.8750\n",
      "Epoch 88/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.3315 - accuracy: 0.8750 - val_loss: 0.3327 - val_accuracy: 0.8750\n",
      "Epoch 89/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3306 - accuracy: 0.8755 - val_loss: 0.3319 - val_accuracy: 0.8730\n",
      "Epoch 90/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.3299 - accuracy: 0.8755 - val_loss: 0.3311 - val_accuracy: 0.8730\n",
      "Epoch 91/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3291 - accuracy: 0.8755 - val_loss: 0.3304 - val_accuracy: 0.8730\n",
      "Epoch 92/250\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.3283 - accuracy: 0.8780 - val_loss: 0.3296 - val_accuracy: 0.8730\n",
      "Epoch 93/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.3275 - accuracy: 0.8785 - val_loss: 0.3288 - val_accuracy: 0.8730\n",
      "Epoch 94/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3268 - accuracy: 0.8785 - val_loss: 0.3281 - val_accuracy: 0.8730\n",
      "Epoch 95/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3260 - accuracy: 0.8795 - val_loss: 0.3274 - val_accuracy: 0.8730\n",
      "Epoch 96/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3253 - accuracy: 0.8795 - val_loss: 0.3267 - val_accuracy: 0.8730\n",
      "Epoch 97/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3246 - accuracy: 0.8800 - val_loss: 0.3260 - val_accuracy: 0.8750\n",
      "Epoch 98/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3239 - accuracy: 0.8800 - val_loss: 0.3253 - val_accuracy: 0.8750\n",
      "Epoch 99/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3231 - accuracy: 0.8805 - val_loss: 0.3246 - val_accuracy: 0.8750\n",
      "Epoch 100/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3224 - accuracy: 0.8810 - val_loss: 0.3239 - val_accuracy: 0.8750\n",
      "Epoch 101/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.3218 - accuracy: 0.8814 - val_loss: 0.3232 - val_accuracy: 0.8770\n",
      "Epoch 102/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.3211 - accuracy: 0.8819 - val_loss: 0.3225 - val_accuracy: 0.8770\n",
      "Epoch 103/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.3204 - accuracy: 0.8829 - val_loss: 0.3219 - val_accuracy: 0.8770\n",
      "Epoch 104/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3197 - accuracy: 0.8839 - val_loss: 0.3212 - val_accuracy: 0.8770\n",
      "Epoch 105/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.3191 - accuracy: 0.8844 - val_loss: 0.3206 - val_accuracy: 0.8770\n",
      "Epoch 106/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3184 - accuracy: 0.8849 - val_loss: 0.3199 - val_accuracy: 0.8790\n",
      "Epoch 107/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3178 - accuracy: 0.8854 - val_loss: 0.3193 - val_accuracy: 0.8810\n",
      "Epoch 108/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3171 - accuracy: 0.8869 - val_loss: 0.3187 - val_accuracy: 0.8810\n",
      "Epoch 109/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3165 - accuracy: 0.8884 - val_loss: 0.3181 - val_accuracy: 0.8810\n",
      "Epoch 110/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3159 - accuracy: 0.8889 - val_loss: 0.3175 - val_accuracy: 0.8810\n",
      "Epoch 111/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3153 - accuracy: 0.8894 - val_loss: 0.3169 - val_accuracy: 0.8810\n",
      "Epoch 112/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.3147 - accuracy: 0.8894 - val_loss: 0.3163 - val_accuracy: 0.8810\n",
      "Epoch 113/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.3141 - accuracy: 0.8899 - val_loss: 0.3157 - val_accuracy: 0.8810\n",
      "Epoch 114/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.3135 - accuracy: 0.8909 - val_loss: 0.3152 - val_accuracy: 0.8810\n",
      "Epoch 115/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3129 - accuracy: 0.8909 - val_loss: 0.3146 - val_accuracy: 0.8810\n",
      "Epoch 116/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3123 - accuracy: 0.8909 - val_loss: 0.3140 - val_accuracy: 0.8810\n",
      "Epoch 117/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3117 - accuracy: 0.8909 - val_loss: 0.3135 - val_accuracy: 0.8810\n",
      "Epoch 118/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.3111 - accuracy: 0.8914 - val_loss: 0.3129 - val_accuracy: 0.8810\n",
      "Epoch 119/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.3106 - accuracy: 0.8914 - val_loss: 0.3124 - val_accuracy: 0.8810\n",
      "Epoch 120/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.3100 - accuracy: 0.8924 - val_loss: 0.3118 - val_accuracy: 0.8810\n",
      "Epoch 121/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.3095 - accuracy: 0.8924 - val_loss: 0.3113 - val_accuracy: 0.8810\n",
      "Epoch 122/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.3089 - accuracy: 0.8929 - val_loss: 0.3108 - val_accuracy: 0.8810\n",
      "Epoch 123/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3084 - accuracy: 0.8929 - val_loss: 0.3103 - val_accuracy: 0.8810\n",
      "Epoch 124/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3078 - accuracy: 0.8929 - val_loss: 0.3098 - val_accuracy: 0.8810\n",
      "Epoch 125/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3073 - accuracy: 0.8929 - val_loss: 0.3092 - val_accuracy: 0.8810\n",
      "Epoch 126/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3068 - accuracy: 0.8929 - val_loss: 0.3087 - val_accuracy: 0.8810\n",
      "Epoch 127/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3063 - accuracy: 0.8929 - val_loss: 0.3082 - val_accuracy: 0.8810\n",
      "Epoch 128/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.3057 - accuracy: 0.8929 - val_loss: 0.3077 - val_accuracy: 0.8810\n",
      "Epoch 129/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3052 - accuracy: 0.8929 - val_loss: 0.3072 - val_accuracy: 0.8810\n",
      "Epoch 130/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3047 - accuracy: 0.8929 - val_loss: 0.3068 - val_accuracy: 0.8810\n",
      "Epoch 131/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3042 - accuracy: 0.8929 - val_loss: 0.3063 - val_accuracy: 0.8810\n",
      "Epoch 132/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3037 - accuracy: 0.8929 - val_loss: 0.3058 - val_accuracy: 0.8810\n",
      "Epoch 133/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3032 - accuracy: 0.8929 - val_loss: 0.3053 - val_accuracy: 0.8829\n",
      "Epoch 134/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3027 - accuracy: 0.8929 - val_loss: 0.3049 - val_accuracy: 0.8829\n",
      "Epoch 135/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3023 - accuracy: 0.8929 - val_loss: 0.3044 - val_accuracy: 0.8829\n",
      "Epoch 136/250\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.3018 - accuracy: 0.8929 - val_loss: 0.3039 - val_accuracy: 0.8829\n",
      "Epoch 137/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.3013 - accuracy: 0.8929 - val_loss: 0.3035 - val_accuracy: 0.8829\n",
      "Epoch 138/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3008 - accuracy: 0.8934 - val_loss: 0.3030 - val_accuracy: 0.8829\n",
      "Epoch 139/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3004 - accuracy: 0.8934 - val_loss: 0.3026 - val_accuracy: 0.8829\n",
      "Epoch 140/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2999 - accuracy: 0.8934 - val_loss: 0.3022 - val_accuracy: 0.8829\n",
      "Epoch 141/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2994 - accuracy: 0.8934 - val_loss: 0.3017 - val_accuracy: 0.8829\n",
      "Epoch 142/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2990 - accuracy: 0.8934 - val_loss: 0.3013 - val_accuracy: 0.8829\n",
      "Epoch 143/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2985 - accuracy: 0.8934 - val_loss: 0.3009 - val_accuracy: 0.8829\n",
      "Epoch 144/250\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.2981 - accuracy: 0.8934 - val_loss: 0.3004 - val_accuracy: 0.8849\n",
      "Epoch 145/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2976 - accuracy: 0.8938 - val_loss: 0.3000 - val_accuracy: 0.8849\n",
      "Epoch 146/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2972 - accuracy: 0.8938 - val_loss: 0.2996 - val_accuracy: 0.8849\n",
      "Epoch 147/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2968 - accuracy: 0.8938 - val_loss: 0.2992 - val_accuracy: 0.8849\n",
      "Epoch 148/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2963 - accuracy: 0.8938 - val_loss: 0.2988 - val_accuracy: 0.8849\n",
      "Epoch 149/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2959 - accuracy: 0.8943 - val_loss: 0.2984 - val_accuracy: 0.8849\n",
      "Epoch 150/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2955 - accuracy: 0.8943 - val_loss: 0.2980 - val_accuracy: 0.8849\n",
      "Epoch 151/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2951 - accuracy: 0.8943 - val_loss: 0.2976 - val_accuracy: 0.8869\n",
      "Epoch 152/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2946 - accuracy: 0.8948 - val_loss: 0.2972 - val_accuracy: 0.8869\n",
      "Epoch 153/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2942 - accuracy: 0.8948 - val_loss: 0.2968 - val_accuracy: 0.8869\n",
      "Epoch 154/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2938 - accuracy: 0.8948 - val_loss: 0.2964 - val_accuracy: 0.8869\n",
      "Epoch 155/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2934 - accuracy: 0.8948 - val_loss: 0.2960 - val_accuracy: 0.8869\n",
      "Epoch 156/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2930 - accuracy: 0.8953 - val_loss: 0.2956 - val_accuracy: 0.8869\n",
      "Epoch 157/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2926 - accuracy: 0.8953 - val_loss: 0.2952 - val_accuracy: 0.8869\n",
      "Epoch 158/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2922 - accuracy: 0.8953 - val_loss: 0.2949 - val_accuracy: 0.8869\n",
      "Epoch 159/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2918 - accuracy: 0.8953 - val_loss: 0.2945 - val_accuracy: 0.8869\n",
      "Epoch 160/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2914 - accuracy: 0.8953 - val_loss: 0.2941 - val_accuracy: 0.8869\n",
      "Epoch 161/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2910 - accuracy: 0.8953 - val_loss: 0.2938 - val_accuracy: 0.8869\n",
      "Epoch 162/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2906 - accuracy: 0.8953 - val_loss: 0.2934 - val_accuracy: 0.8869\n",
      "Epoch 163/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2903 - accuracy: 0.8953 - val_loss: 0.2931 - val_accuracy: 0.8869\n",
      "Epoch 164/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2899 - accuracy: 0.8953 - val_loss: 0.2927 - val_accuracy: 0.8869\n",
      "Epoch 165/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2895 - accuracy: 0.8953 - val_loss: 0.2923 - val_accuracy: 0.8869\n",
      "Epoch 166/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2891 - accuracy: 0.8953 - val_loss: 0.2920 - val_accuracy: 0.8869\n",
      "Epoch 167/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2888 - accuracy: 0.8953 - val_loss: 0.2917 - val_accuracy: 0.8869\n",
      "Epoch 168/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2884 - accuracy: 0.8953 - val_loss: 0.2913 - val_accuracy: 0.8869\n",
      "Epoch 169/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2880 - accuracy: 0.8953 - val_loss: 0.2910 - val_accuracy: 0.8869\n",
      "Epoch 170/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2877 - accuracy: 0.8953 - val_loss: 0.2906 - val_accuracy: 0.8869\n",
      "Epoch 171/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2873 - accuracy: 0.8958 - val_loss: 0.2903 - val_accuracy: 0.8869\n",
      "Epoch 172/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2870 - accuracy: 0.8958 - val_loss: 0.2900 - val_accuracy: 0.8869\n",
      "Epoch 173/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2866 - accuracy: 0.8958 - val_loss: 0.2896 - val_accuracy: 0.8869\n",
      "Epoch 174/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2863 - accuracy: 0.8958 - val_loss: 0.2893 - val_accuracy: 0.8869\n",
      "Epoch 175/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2859 - accuracy: 0.8958 - val_loss: 0.2890 - val_accuracy: 0.8869\n",
      "Epoch 176/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2856 - accuracy: 0.8958 - val_loss: 0.2887 - val_accuracy: 0.8869\n",
      "Epoch 177/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2853 - accuracy: 0.8958 - val_loss: 0.2884 - val_accuracy: 0.8869\n",
      "Epoch 178/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2849 - accuracy: 0.8958 - val_loss: 0.2880 - val_accuracy: 0.8869\n",
      "Epoch 179/250\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.2846 - accuracy: 0.8958 - val_loss: 0.2877 - val_accuracy: 0.8869\n",
      "Epoch 180/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2843 - accuracy: 0.8963 - val_loss: 0.2874 - val_accuracy: 0.8869\n",
      "Epoch 181/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2839 - accuracy: 0.8963 - val_loss: 0.2871 - val_accuracy: 0.8869\n",
      "Epoch 182/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2836 - accuracy: 0.8963 - val_loss: 0.2868 - val_accuracy: 0.8869\n",
      "Epoch 183/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2833 - accuracy: 0.8963 - val_loss: 0.2865 - val_accuracy: 0.8869\n",
      "Epoch 184/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2830 - accuracy: 0.8968 - val_loss: 0.2862 - val_accuracy: 0.8869\n",
      "Epoch 185/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2826 - accuracy: 0.8968 - val_loss: 0.2859 - val_accuracy: 0.8869\n",
      "Epoch 186/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2823 - accuracy: 0.8968 - val_loss: 0.2856 - val_accuracy: 0.8869\n",
      "Epoch 187/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2820 - accuracy: 0.8968 - val_loss: 0.2853 - val_accuracy: 0.8869\n",
      "Epoch 188/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2817 - accuracy: 0.8968 - val_loss: 0.2850 - val_accuracy: 0.8869\n",
      "Epoch 189/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2814 - accuracy: 0.8968 - val_loss: 0.2847 - val_accuracy: 0.8869\n",
      "Epoch 190/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2811 - accuracy: 0.8968 - val_loss: 0.2844 - val_accuracy: 0.8889\n",
      "Epoch 191/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2808 - accuracy: 0.8968 - val_loss: 0.2841 - val_accuracy: 0.8889\n",
      "Epoch 192/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2805 - accuracy: 0.8968 - val_loss: 0.2838 - val_accuracy: 0.8889\n",
      "Epoch 193/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2802 - accuracy: 0.8968 - val_loss: 0.2835 - val_accuracy: 0.8889\n",
      "Epoch 194/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2799 - accuracy: 0.8968 - val_loss: 0.2832 - val_accuracy: 0.8889\n",
      "Epoch 195/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2796 - accuracy: 0.8968 - val_loss: 0.2830 - val_accuracy: 0.8889\n",
      "Epoch 196/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2793 - accuracy: 0.8968 - val_loss: 0.2827 - val_accuracy: 0.8889\n",
      "Epoch 197/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2790 - accuracy: 0.8968 - val_loss: 0.2824 - val_accuracy: 0.8889\n",
      "Epoch 198/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2787 - accuracy: 0.8968 - val_loss: 0.2821 - val_accuracy: 0.8889\n",
      "Epoch 199/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2784 - accuracy: 0.8968 - val_loss: 0.2819 - val_accuracy: 0.8889\n",
      "Epoch 200/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2782 - accuracy: 0.8973 - val_loss: 0.2816 - val_accuracy: 0.8889\n",
      "Epoch 201/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2779 - accuracy: 0.8973 - val_loss: 0.2813 - val_accuracy: 0.8889\n",
      "Epoch 202/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2776 - accuracy: 0.8973 - val_loss: 0.2811 - val_accuracy: 0.8889\n",
      "Epoch 203/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2773 - accuracy: 0.8973 - val_loss: 0.2808 - val_accuracy: 0.8889\n",
      "Epoch 204/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2770 - accuracy: 0.8973 - val_loss: 0.2805 - val_accuracy: 0.8889\n",
      "Epoch 205/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2768 - accuracy: 0.8978 - val_loss: 0.2803 - val_accuracy: 0.8889\n",
      "Epoch 206/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2765 - accuracy: 0.8978 - val_loss: 0.2800 - val_accuracy: 0.8889\n",
      "Epoch 207/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2762 - accuracy: 0.8978 - val_loss: 0.2797 - val_accuracy: 0.8889\n",
      "Epoch 208/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2760 - accuracy: 0.8978 - val_loss: 0.2795 - val_accuracy: 0.8889\n",
      "Epoch 209/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2757 - accuracy: 0.8978 - val_loss: 0.2792 - val_accuracy: 0.8889\n",
      "Epoch 210/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2754 - accuracy: 0.8983 - val_loss: 0.2790 - val_accuracy: 0.8889\n",
      "Epoch 211/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2752 - accuracy: 0.8983 - val_loss: 0.2787 - val_accuracy: 0.8889\n",
      "Epoch 212/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2749 - accuracy: 0.8983 - val_loss: 0.2785 - val_accuracy: 0.8889\n",
      "Epoch 213/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2746 - accuracy: 0.8988 - val_loss: 0.2782 - val_accuracy: 0.8889\n",
      "Epoch 214/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2744 - accuracy: 0.8988 - val_loss: 0.2780 - val_accuracy: 0.8889\n",
      "Epoch 215/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2741 - accuracy: 0.8993 - val_loss: 0.2777 - val_accuracy: 0.8889\n",
      "Epoch 216/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2739 - accuracy: 0.8998 - val_loss: 0.2775 - val_accuracy: 0.8889\n",
      "Epoch 217/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2736 - accuracy: 0.8998 - val_loss: 0.2772 - val_accuracy: 0.8889\n",
      "Epoch 218/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2733 - accuracy: 0.8998 - val_loss: 0.2770 - val_accuracy: 0.8889\n",
      "Epoch 219/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2731 - accuracy: 0.8998 - val_loss: 0.2768 - val_accuracy: 0.8889\n",
      "Epoch 220/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2728 - accuracy: 0.8998 - val_loss: 0.2765 - val_accuracy: 0.8889\n",
      "Epoch 221/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2726 - accuracy: 0.8998 - val_loss: 0.2763 - val_accuracy: 0.8889\n",
      "Epoch 222/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2724 - accuracy: 0.8998 - val_loss: 0.2761 - val_accuracy: 0.8889\n",
      "Epoch 223/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2721 - accuracy: 0.8998 - val_loss: 0.2758 - val_accuracy: 0.8889\n",
      "Epoch 224/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2719 - accuracy: 0.8998 - val_loss: 0.2756 - val_accuracy: 0.8889\n",
      "Epoch 225/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2716 - accuracy: 0.9003 - val_loss: 0.2754 - val_accuracy: 0.8889\n",
      "Epoch 226/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2714 - accuracy: 0.9003 - val_loss: 0.2752 - val_accuracy: 0.8889\n",
      "Epoch 227/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2711 - accuracy: 0.9003 - val_loss: 0.2749 - val_accuracy: 0.8889\n",
      "Epoch 228/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2709 - accuracy: 0.9003 - val_loss: 0.2747 - val_accuracy: 0.8889\n",
      "Epoch 229/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2707 - accuracy: 0.9003 - val_loss: 0.2745 - val_accuracy: 0.8889\n",
      "Epoch 230/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2704 - accuracy: 0.9003 - val_loss: 0.2743 - val_accuracy: 0.8889\n",
      "Epoch 231/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2702 - accuracy: 0.9003 - val_loss: 0.2741 - val_accuracy: 0.8889\n",
      "Epoch 232/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2700 - accuracy: 0.9003 - val_loss: 0.2738 - val_accuracy: 0.8889\n",
      "Epoch 233/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2697 - accuracy: 0.9003 - val_loss: 0.2736 - val_accuracy: 0.8889\n",
      "Epoch 234/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2695 - accuracy: 0.9003 - val_loss: 0.2734 - val_accuracy: 0.8889\n",
      "Epoch 235/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2693 - accuracy: 0.9003 - val_loss: 0.2732 - val_accuracy: 0.8889\n",
      "Epoch 236/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2691 - accuracy: 0.9003 - val_loss: 0.2730 - val_accuracy: 0.8889\n",
      "Epoch 237/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2688 - accuracy: 0.9003 - val_loss: 0.2728 - val_accuracy: 0.8889\n",
      "Epoch 238/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2686 - accuracy: 0.9003 - val_loss: 0.2726 - val_accuracy: 0.8889\n",
      "Epoch 239/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2684 - accuracy: 0.9003 - val_loss: 0.2723 - val_accuracy: 0.8889\n",
      "Epoch 240/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2682 - accuracy: 0.9003 - val_loss: 0.2721 - val_accuracy: 0.8889\n",
      "Epoch 241/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2680 - accuracy: 0.9003 - val_loss: 0.2719 - val_accuracy: 0.8889\n",
      "Epoch 242/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2677 - accuracy: 0.9003 - val_loss: 0.2717 - val_accuracy: 0.8889\n",
      "Epoch 243/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2675 - accuracy: 0.9003 - val_loss: 0.2715 - val_accuracy: 0.8889\n",
      "Epoch 244/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2673 - accuracy: 0.9003 - val_loss: 0.2713 - val_accuracy: 0.8889\n",
      "Epoch 245/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2671 - accuracy: 0.9003 - val_loss: 0.2711 - val_accuracy: 0.8889\n",
      "Epoch 246/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2669 - accuracy: 0.9003 - val_loss: 0.2709 - val_accuracy: 0.8889\n",
      "Epoch 247/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2667 - accuracy: 0.9003 - val_loss: 0.2707 - val_accuracy: 0.8889\n",
      "Epoch 248/250\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2665 - accuracy: 0.9008 - val_loss: 0.2705 - val_accuracy: 0.8889\n",
      "Epoch 249/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2663 - accuracy: 0.9008 - val_loss: 0.2703 - val_accuracy: 0.8889\n",
      "Epoch 250/250\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2660 - accuracy: 0.9008 - val_loss: 0.2701 - val_accuracy: 0.8889\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(units=13, activation='relu', input_dim=13))\n",
    "model.add(Dense(units=7, activation='relu', input_dim=7))\n",
    "model.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "history = model.compile(loss='binary_crossentropy', optimizer= keras.optimizers.Adagrad() , metrics='accuracy')\n",
    "history = model.fit(X_train_scaled, y_train, epochs = 250, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "e1d6c8c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7803d83a0760>"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAtfklEQVR4nO3deXxU9b3/8ddnJpN9gawEAiQsgiyCGqDUX0FsWbQqtaUVtW61Wtxa7a1XvbZ2v7b13tb2XqrlWtt6q0XqdrGiqHVBWhcCssgOIcCQQBay7zP5/P6YEYaQwABJTjL5PB+PeWTmnO+Z8/ky+j5nzjnzPaKqGGOMiVwupwswxhjTvSzojTEmwlnQG2NMhLOgN8aYCGdBb4wxES7K6QI6kp6errm5uU6XYYwxfcbatWvLVTWjo3m9Muhzc3MpKChwugxjjOkzRGRvZ/Ps0I0xxkQ4C3pjjIlwFvTGGBPheuUxemNM/9Pa2orX66WpqcnpUnq12NhYcnJy8Hg8YS9jQW+M6RW8Xi9JSUnk5uYiIk6X0yupKhUVFXi9XvLy8sJezg7dGGN6haamJtLS0izkT0BESEtLO+VvPRb0xphew0L+5E7n3yiigv43f9/JOzvKnC7DGGN6lYgK+t+9s5t3tlvQG2NOT2JiotMldIuICvqkWA+1Ta1Ol2GMMb1KhAV9FLVNPqfLMMb0carKPffcw4QJE5g4cSLPPPMMACUlJcyYMYPJkyczYcIE3n33Xfx+PzfccMORtr/61a8crv54EXV5ZWJsFHXNFvTG9HU/fGkzW4pruvQ9xw1O5vuXjQ+r7fPPP8/69evZsGED5eXlTJkyhRkzZvD0008zd+5cHnjgAfx+Pw0NDaxfv54DBw7w8ccfA1BVVdWldXeFsPboRWSeiGwXkV0icl8nbS4UkfUisllE3gmZXiQim4LzunWkMjt0Y4zpCqtXr+aqq67C7XaTlZXFzJkzWbNmDVOmTOEPf/gDP/jBD9i0aRNJSUmMGDGCwsJC7rzzTl599VWSk5OdLv84J92jFxE3sBiYDXiBNSKyXFW3hLQZAPwWmKeq+0Qks93bzFLV8q4ru2NJsVF4Dzd092qMMd0s3D3v7qKqHU6fMWMGq1at4uWXX+baa6/lnnvu4brrrmPDhg2sXLmSxYsXs2zZMp544okervjEwtmjnwrsUtVCVW0BlgLz27W5GnheVfcBqGpp15YZBlVuO/g9ZjW+2uOrNsZElhkzZvDMM8/g9/spKytj1apVTJ06lb1795KZmcnNN9/MTTfdxLp16ygvL6etrY0vfelL/PjHP2bdunVOl3+ccI7RDwH2h7z2AtPatTkL8IjI20AS8GtVfTI4T4HXRESB36nqkjMruRMijKjfwIjW+G55e2NM/3HFFVfw3nvvMWnSJESEX/ziFwwaNIg//elPPPzww3g8HhITE3nyySc5cOAAN954I21tbQA89NBDDld/vHCCvqOfYbX/XhMFnA98FogD3hOR91V1B3CBqhYHD+e8LiLbVHXVcSsRuQW4BWDYsGGn0ocjmj0DSGqppdXfhscdURcUGWN6QF1dHRD49enDDz/Mww8/fMz866+/nuuvv/645XrjXnyocNLQCwwNeZ0DFHfQ5lVVrQ8ei18FTAJQ1eLg31LgBQKHgo6jqktUNV9V8zMyOrwb1km1xAxgAHXU2SWWxhhzRDhBvwYYLSJ5IhINLASWt2vzf8BnRCRKROIJHNrZKiIJIpIEICIJwBzg464r/1i+mIEMlFq7lt4YY0Kc9NCNqvpE5A5gJeAGnlDVzSKyKDj/MVXdKiKvAhuBNuBxVf1YREYALwQH4YkCnlbVbjtbqnGpDJQtVNkllsYYc0RYP5hS1RXAinbTHmv3+mHg4XbTCgkewukJEpfKAGrx2o+mjDHmiIg6Y+lKSCVBmqmrt2vpjTHmExEV9FFJ6QC01NoIlsYY84mICvroYND76iocrsQYY3qPiAr62ORA0PvrLeiNMd3rRGPXFxUVMWHChB6s5sQiKuijkwLX32uDBb0xxnwiooYpJj4VAFdjpcOFGGPOyCv3wcFNXfuegybCxT/rdPa9997L8OHDue222wD4wQ9+gIiwatUqKisraW1t5Sc/+Qnz57cf6uvEmpqauPXWWykoKCAqKopf/vKXzJo1i82bN3PjjTfS0tJCW1sbzz33HIMHD+YrX/kKXq8Xv9/P9773Pa688soz6jZEWtDHBYLe3VTlbB3GmD5n4cKF3HXXXUeCftmyZbz66qvcfffdJCcnU15ezqc+9Skuv/zyU7pB9+LFiwHYtGkT27ZtY86cOezYsYPHHnuMb33rW1xzzTW0tLTg9/tZsWIFgwcP5uWXXwagurq6S/oWWUHviaWJGDzNh52uxBhzJk6w591dzj33XEpLSykuLqasrIyBAweSnZ3N3XffzapVq3C5XBw4cIBDhw4xaNCgsN939erV3HnnnQCMHTuW4cOHs2PHDqZPn85Pf/pTvF4vX/ziFxk9ejQTJ07kO9/5Dvfeey+XXnopn/nMZ7qkbxF1jB6gzp1MTGvXbAWNMf3LggULePbZZ3nmmWdYuHAhTz31FGVlZaxdu5b169eTlZVFU1PTKb1nZ2PbX3311Sxfvpy4uDjmzp3Lm2++yVlnncXatWuZOHEi999/Pz/60Y+6olsRtkcPNEalENNa5XQZxpg+aOHChdx8882Ul5fzzjvvsGzZMjIzM/F4PLz11lvs3bv3lN9zxowZPPXUU1x00UXs2LGDffv2MWbMGAoLCxkxYgTf/OY3KSwsZOPGjYwdO5bU1FS++tWvkpiYyB//+Mcu6VfEBX1L9EAS7Bi9MeY0jB8/ntraWoYMGUJ2djbXXHMNl112Gfn5+UyePJmxY8ee8nvedtttLFq0iIkTJxIVFcUf//hHYmJieOaZZ/jzn/+Mx+Nh0KBBPPjgg6xZs4Z77rkHl8uFx+Ph0Ucf7ZJ+SWdfK5yUn5+vBQWnd3vZbY9eTeLBD0j/7g5iPe4urswY0122bt3K2Wef7XQZfUJH/1YislZV8ztqH3HH6DUxmywqKatpdLoUY4zpFSLu0I0rJRuP+KksL2Fo2minyzHGRLBNmzZx7bXXHjMtJiaGDz74wKGKOhZxQR87MAeA+rL9MMaC3pi+RFVP6Rp1p02cOJH169f36DpP53B7xB26ScgI3PWwubL93Q6NMb1ZbGwsFRUVpxVk/YWqUlFRQWxs7CktF9YevYjMA35N4A5Tj6vqcb9mEJELgUcAD1CuqjPDXbYrJQeD3l99oDtXY4zpYjk5OXi9XsrKbJjxE4mNjSUnJ+eUljlp0IuIG1gMzCZwE/A1IrJcVbeEtBkA/BaYp6r7RCQz3GW7WvSAbNoQpPZgd63CGNMNPB4PeXl5TpcRkcI5dDMV2KWqharaAiwF2o/qczXwvKruA1DV0lNYtmu5PVRJCtGNFvTGGAPhBf0QYH/Ia29wWqizgIEi8raIrBWR605hWQBE5BYRKRCRgjP96lYVlU58s339M8YYCO8YfUenwNufLYkCzgc+C8QB74nI+2EuG5iougRYAoEfTIVRV6fqozNItj16Y4wBwgt6LzA05HUO0P6SFi+BE7D1QL2IrAImhblsl2uOy2Rw3ebuXo0xxvQJ4Ry6WQOMFpE8EYkGFgLL27X5P+AzIhIlIvHANGBrmMt2ubakwaRJDXV1td29KmOM6fVOGvSq6gPuAFYSCO9lqrpZRBaJyKJgm63Aq8BG4EMCl1F+3Nmy3dOVo9xpgTP3Zft3dveqjDGm1wvrOnpVXQGsaDftsXavHwYeDmfZ7paQORKAmpKdcPZ5PblqY4zpdSLul7EAaUPPAqC5bI/DlRhjjPMiM+gzc2jUaKgscroUY4xxXEQGvcvt4qAri5i6/SdvbIwxES4igx6gMmYwKU023o0xxkRs0NfH55DhKwEbCc8Y089FbND7U4aTQBMtteVOl2KMMY6K2KB3p48A4PD+7Q5XYowxzorYoE8cHLhbe7XXhkIwxvRvERv0g/POpkXdtB7c6nQpxhjjqIgN+syUBPaRTdRhGwbBGNO/RWzQiwgHo4cxoN5+HWuM6d8iNugBapNGku4rAV+z06UYY4xjIjroNf0somijpcwO3xhj+q+IDvq47LMBqCja5HAlxhjjnIgO+rTcCfhVaNj/sdOlGGOMYyI66HOz09mj2UipBb0xpv8KK+hFZJ6IbBeRXSJyXwfzLxSRahFZH3w8GDKvSEQ2BacXdGXxJ5Mc66EoagQp1dt6crXGGNOrnPQOUyLiBhYDswnc7HuNiCxX1S3tmr6rqpd28jazVNWRQWeqkseQVrUaGqsgboATJRhjjKPC2aOfCuxS1UJVbQGWAvO7t6yuo4MmAtBabCdkjTH9UzhBPwQIvYOHNzitvekiskFEXhGR8SHTFXhNRNaKyC2drUREbhGRAhEpKCsrC6v4cCTnBe4ZW7G7R48aGWNMrxHOzcGlg2ntB3lfBwxX1ToRuQR4ERgdnHeBqhaLSCbwuohsU9VVx72h6hJgCUB+fn6XDSI/IncEZZpM8/6PuuotjTGmTwlnj94LDA15nQMUhzZQ1RpVrQs+XwF4RCQ9+Lo4+LcUeIHAoaAek5eewGYdSXz5xp5crTHG9BrhBP0aYLSI5IlINLAQWB7aQEQGiYgEn08Nvm+FiCSISFJwegIwB+jRax2j3C68CeNIayyCppqeXLUxxvQKJw16VfUBdwArga3AMlXdLCKLRGRRsNkC4GMR2QD8BlioqgpkAauD0z8EXlbVV7ujIyfSMug8XCh6YF1Pr9oYYxwXzjH6Tw7HrGg37bGQ5/8N/HcHyxUCk86wxjOWMmoa7IHKne+ROvJCp8sxxpgeFdG/jP3EuBHD2d2WTXPRB06XYowxPa5fBP3ozEQ2MZrk8o9Au+yCHmOM6RP6RdBHuV0cTJlMgq8KKnY5XY4xxvSofhH0AG3DPw1Aa+G7DldijDE9q98E/YgxkynTZGq2veN0KcYY06P6TdBPyUvlw7axeA7YCVljTP/Sb4I+LTGGwvhJJDeXQGWR0+UYY0yP6TdBD9A8/EIA2nb+3dlCjDGmB/WroM87axL72zKo29zjP841xhjH9Kug//TodN5pO4dY72rwtThdjjHG9Ih+FfTZKXFsT5xGtL8B9ttJWWNM/9Cvgh4g9qwLaVU3/p2vO12KMcb0iH4X9FPGDKegbQxNW19zuhRjjOkR/S7op49MYzWTSKjcCjUlTpdjjDHdrt8FfVKsh6rBMwDQXW84XI0xxnS/fhf0AGMnTadEU6nf9JLTpRhjTLcLK+hFZJ6IbBeRXSJyXwfzLxSRahFZH3w8GO6yTvjc+EGs8E8jruhNu72gMSbinTToRcQNLAYuBsYBV4nIuA6avquqk4OPH53isj0qOyWOrakX4dZW2P6K0+UYY0y3CmePfiqwS1ULVbUFWArMD/P9z2TZbjV04kwOaBrNG551uhRjjOlW4QT9EGB/yGtvcFp700Vkg4i8IiLjT3FZROQWESkQkYKysrIwyjozs8dns8I/jag9b0JjVbevzxhjnBJO0EsH09rfj28dMFxVJwH/Bbx4CssGJqouUdV8Vc3PyMgIo6wzc3Z2Eh/Gz8StPti+4uQLGGNMHxVO0HuBoSGvc4Di0AaqWqOqdcHnKwCPiKSHs6xTRIS8STPwajotG59zuhxjjOk24QT9GmC0iOSJSDSwEFge2kBEBomIBJ9PDb5vRTjLOumK83L4m/9TRO15G+q6/3CRMcY44aRBr6o+4A5gJbAVWKaqm0VkkYgsCjZbAHwsIhuA3wALNaDDZbujI6fj7Oxk1qV+Hpf6YMNfnC7HGGO6hah2eMjcUfn5+VpQUNAj63r83UImvX4lk1L9RH9rLUhHpxWMMaZ3E5G1qprf0bx++cvYUJdPGswy/yyiq3bDvvecLscYY7pcvw/6zORYqvI+Tx3x6No/OV2OMcZ0uX4f9ACX5o/iRd902ja/aNfUG2MijgU9MG/CIF6JnoPb3wQbn3G6HGOM6VIW9EBMlJtzp81iXdsofP9YDG1+p0syxpguY0EfdM2nhvF7/6VE1eyFbS87XY4xxnQZC/qg7JQ45OxL8ZKJ/5//5XQ5xhjTZSzoQ1z76RE83joPt/dD2L/G6XKMMaZLWNCHmJqXysaMy6glAbW9emNMhLCgDyEifO2iCfzJ9znYuhxKtzldkjHGnDEL+nYunpDNGwMW0Egs+s7PnC7HGGPOmAV9O26XcO2s8/i9by5sfhEO9Zox2Iwx5rRY0Hfg8smDeSXpizRIHPq27dUbY/o2C/oOeNwurp11Lo+3zkW2LoeSjU6XZIwxp82CvhMLzs/hjZQF1EgSba99F3rhcM7GGBMOC/pOeNwubr/4fH7ZcgWuPe/AztecLskYY05LWEEvIvNEZLuI7BKR+07QboqI+EVkQci0IhHZJCLrRaRn7ibSReaOH8TmwQvYy2DaVj4A/lanSzLGmFN20qAXETewGLgYGAdcJSLjOmn3cwK3DWxvlqpO7uzuJ72ViPCvn5/Ij1uuwlWxEwr+4HRJxhhzysLZo58K7FLVQlVtAZYC8ztodyfwHFDahfU5bkpuKtHjLuE9HY//zZ/aTcSNMX1OOEE/BNgf8tobnHaEiAwBrgAe62B5BV4TkbUicktnKxGRW0SkQEQKysp6V5h+99Lx/FS/hjbXwWvfdbocY4w5JeEEfUd3y25/CcojwL2q2tFA7heo6nkEDv3cLiIzOlqJqi5R1XxVzc/IyAijrJ4zeEAcl352Fo/6LoWNS6HwHadLMsaYsIUT9F5gaMjrHKC4XZt8YKmIFAELgN+KyBcAVLU4+LcUeIHAoaA+52sX5PHKwGs4IFm0/e1uaG1yuiRjjAlLOEG/BhgtInkiEg0sBJaHNlDVPFXNVdVc4FngNlV9UUQSRCQJQEQSgDnAx13agx4SHeXi+1ecz/3NN+A6vBtsHBxjTB9x0qBXVR9wB4GrabYCy1R1s4gsEpFFJ1k8C1gtIhuAD4GXVfXVMy3aKdNGpJE77XKe8V+I/uPXNma9MaZPEO2Fv/jMz8/XgoLeecl9fbOPL/7qFZ5svouMgQNx3foueOKcLssY08+JyNrOLmG3X8aeooSYKL6/YDrfbr4Z1+Gd8MYPnS7JGGNOyIL+NHx6VDpjpl/OH31z4INHYXufPRpljOkHLOhP070Xj+GF9EVsZzhtL9wK1QecLskYYzpkQX+aYqLc/OfV07jLfxctzQ3oc18Hv8/psowx5jgW9GdgVGYiN86fzf3NNyL7/gmvf8/pkowx5jgW9GfoK/lDiZtyDU/45sH7v4WPnnK6JGOMOYYFfRf4/mXj+Nug23lPJ9D20l12fb0xplexoO8CMVFuFl87he95vkOJDsS/9BqoKXG6LGOMASzou0x2ShyP3HgRt/q/Q3N9Df6nr4TmWqfLMsYYC/quNGFICt+6aj53tt4BBzfR9sy14GtxuixjTD9nQd/FPnt2Fhde+lXubb0ZV+Fb6Iu3Qlub02UZY/oxC/pucO30XNIuuJGHWq9CPn4WVt4PvXBMIWNM/2BB303uu3gsNefdyuO+i+GDx+BtG9bYGOMMC/puIiL85Ipz2DLhX1nmmxkYv/6th5wuyxjTD0U5XUAkc7uEX3x5Mt9s/R5sh698crOSWfc7W5gxpl8Ja49eROaJyHYR2SUi952g3RQR8YvIglNdNlJFuV08ctX5vD7qgZA9+3+3Y/bGmB5z0qAXETewmMDNvccBV4nIuE7a/ZzAnahOadlIFx3lYvFXp7Dq7AeDYf9zdOW/2dU4xpgeEc4e/VRgl6oWqmoLsBSY30G7O4HngNLTWDbiRUe5+PVV57N20g/5g28u8v5v0Re/Af5Wp0szxkS4cIJ+CLA/5LU3OO0IERkCXAE8dqrL9idul/DQlyazb+qD/KL1K8jGZbQ9fSW01DtdmjEmgoUT9NLBtPYHmB8B7lVV/2ksG2gocouIFIhIQVlZWRhl9U0ul/DgZeNJ+Ny93Nt6M+x+C98Tn4fag06XZoyJUOEEvRcYGvI6Byhu1yYfWCoiRcAC4Lci8oUwlwVAVZeoar6q5mdkZIRXfR8lItw+axSf/vLd3Ob7Nq0Ht+D73Swo2eh0acaYCBRO0K8BRotInohEAwuB5aENVDVPVXNVNRd4FrhNVV8MZ9n+bP7kIXztptu5nh9TXteM//dzYdvLTpdljIkwJw16VfUBdxC4mmYrsExVN4vIIhFZdDrLnnnZkWNqXioP3X4NdyT8B5tastGl16Bv/9yuyDHGdBnRXng9d35+vhYUFDhdRo+qaWrl3r98wJzCf+cK9z/wj5yN+0tLID7V6dKMMX2AiKxV1fyO5tkQCL1EcqyHxddfQNFnfsV3W2+kbfdbtD46A4o/cro0Y0wfZ0Hfi7hcwt1zxjDrq/fzNfkR5TUN+B+fDe8ttkM5xpjTZkHfC3327Cwevusmvjfot7zZOhFW/hu+J6+w2xMaY06LBX0vNSgllt99Yy5bZvyOB1pvwlf0T3yLp8PWl5wuzRjTx1jQ92Jul/Ct2Wcx/+vf5QbPf7K1cQA881V8L9wOTdVOl2eM6SMs6PuAqXmpLPmXq1g68fcs9l2ObHialt9MgW0rnC7NGNMHWND3EcmxHn765fOZcN0vucXzEIV10bD0KvzLboC6yB0ywhhz5izo+5iZZ2XwyL/cxJ/PeZL/aP0y/i0v0fqbfFj/tI1xb4zpkAV9H5QU6+EnC87jgq/9nEUJj7CxKQNevJXmJbNtvBxjzHEs6Puw6SPTeOzua1hz0V/4bts3qC/eRtvvZuL/279Aw2GnyzPG9BIW9H1cdJSLRReO5tZv/5Cf5P2ZP/lmQ8ETND9yHrrmCfD7nC7RGOMwC/oIMWRAHL+84UJGXb+YO5IeYX1TFvLy3TT+ZmpgREw7fm9Mv2VBH2E+MzqD/777OvZe+le+476X4soGWHo1jUvmwP41TpdnjHGAjV4ZweqbfTy+ageV7/6e2+WvZEg1DSPmET/7Acg+x+nyjDFd6ESjV1rQ9wPldc088eYmYtc8xg2ul0mWBhpHziPuc/8G2ZOcLs8Y0wUs6A0ApTVNPPHGeuI/+h9ucK0IBP6IecTNtsA3pq8746AXkXnArwE38Liq/qzd/PnAj4E2wAfcpaqrg/OKgFrAD/g6KySUBX33Kq5q5PE3PiJ5/e+50f0KKVJP3fDPkTjr2zD80yAd3dPdGNObnVHQi4gb2AHMJnCz7zXAVaq6JaRNIlCvqioi5xC4ZeDY4LwiIF9Vy8Mt2IK+ZxyoauR/395I/LrHuUZeIU1qqU8/h4QL74azLwd3lNMlGmPCdKKgD+f/5KnALlUtDL7ZUmA+cCToVbUupH0C0PuOB5njDBkQx31fmEbl7HN5avU2qt5/kqtLX2LEszfSED+E2M/cieu8ayEm0elSjTFnIJzLK4cA+0Nee4PTjiEiV4jINuBl4GshsxR4TUTWisgtna1ERG4RkQIRKSgrs0G6etLAhGjumHsO377/Z6ya8zL3ee5jc10CrpX30fzwGJpfugfKdjhdpjHmNIVz6ObLwFxV/Xrw9bXAVFW9s5P2M4AHVfVzwdeDVbVYRDKB14E7VXXVidZph26c5fO38cbWQ6x+6xXyS//KJa4PiBY/9UMuIOGCb8CYS8DtcbpMY0yIMz104wWGhrzOAYo7a6yqq0RkpIikq2q5qhYHp5eKyAsEDgWdMOiNs6LcLuZNyGbehK+xpXgBP1v1EQmbn+ZK7xskLLuOxpgMPFNuIOr8r8LAXKfLNcacRDh79FEETsZ+FjhA4GTs1aq6OaTNKGB38GTsecBLBDYI8YBLVWtFJIHAHv2PVPXVE63T9uh7n8r6FpatKaLovReZ0/A3Zro34kKpz55OwrTrYdzlEJ3gdJnG9FtdcXnlJcAjBC6vfEJVfyoiiwBU9TERuRe4DmgFGoF7VHW1iIwAXgi+TRTwtKr+9GTrs6DvvVSV9wsPs/Kfa0je8TxXyNvkuQ7R6o5Hx32B6PxrYdh0u0TTmB5mP5gy3aKqoYUX13nZ9P5KplS9ymXu90mQJhoShxEz+Urc5yyAzLFOl2lMv2BBb7qVqrLBW81La3bSvOlF5vneYrp7C26UhoFjiDv3K8iEL0LqCKdLNSZiWdCbHtPqb2PVjjL+XrCJ2B0vcbH8kymuwKWZjRmTiD33y8j4KyAlx+FKjYksFvTGEbVNrazcfIjVBR+RuX8Fl7re4xzXHgAa0ycSO/Fy5OzLIGOsHdM35gxZ0BvHldU289qWg6xbt5bMA68x27WG81y7AGhKziVmwuXI2EshZwq47DYJxpwqC3rTq1TWt/D6lkP8Y/3HpOx7jc9SwKfdW/DgoyU2DfdZc3CfNQdGzoK4gU6Xa0yfYEFveq3qxlb+vvUQb23YRfSeN5ipBcx0bSRF6mkTN/7B+XjGzoXRcyBrgh3iMaYTFvSmT2hs8fNeYTlvbSnm0NZ/MrHxQy50rWeiqwiA1vgsosbMQUZ9FnJnQEKaswUb04tY0Js+R1XZUlLDm1tLWbt5GxmHVjHTtYGZ7k0k0YAi+DIn4Bl1IYy4MPAjLftlrunHLOhNn1dW28zb20v5x46DVO76kInNH3GBazPnu3cQjY82lwdypuAaOQvyZsLgcyEq2umyjekxFvQmorS1Bfb2391Zzgfb9yP732cam/h/7s2MkyJcKG3uWMjJx5V7QWBvf+hU2+M3Ec2C3kS0hhYfH+45zLs7y1m/fTcZFQVMdW1jmns7Z8teXLSh4kazJ+MaPj1wu8Rh0yE+1enSjekyFvSmXymtaeKDPYd5v7CCTYVeBlZ8xBTXNqa7t3OO7MZDKwCaPhYZmh+4dj9nSuCHWy63w9Ubc3os6E2/VlbbzIfB4F9XWEJC2QamuLYzJWon57t2kaS1AKgnAck5/2jwD8mHxAyHqzcmPBb0xoSoqAsE/4dFh1lXdJi6kh2cw07Ode1iWnQho9qKcOMHQAcMR3KmwJDzYfBkGHSO3UPX9EoW9MacQGOLn43eKtbuq2RtUSWb9x4kp2kH57p2MdWzm/Pdu0n1lwOgCJI+GrInQfbko+Efm+xoH4yxoDfmFKgqheX1rN1bybq9lRTsraS6dD8TXEVMlD1Mjd3HeClkoK/86EKpIwOhnz05uBGYBHEDHOqB6Y+64g5T84BfE7jD1OOq+rN28+cDPwbaAB9wl6quDmfZjljQm96mpqmVj73VbPBWs9FbxUZvNc1VB5ng2sMEVxGfit3HONlDauuhowulDIOs8SGPCYEx+d3h3KrZmFNzRkEvIm4C94ydTeBG4WuAq1R1S0ibRKA+eM/Yc4Blqjo2nGU7YkFv+oLyuuYjob8xuAHw15UzwVXEOa4izo8r4WzXPrJa9uNSX2ChqNjA1T1ZE47dANhwDuYMnSjow9m1mArsUtXC4JstBeYDR8JaVetC2icAGu6yxvRV6YkxXDQ2i4vGZgGBQz7F1U1s3F/FxgPVPFlSw+biGqob6xglBxgr+8h3lzCpyktu+QoS1v/56JslDgrcdjFjLGSMCfxNH2MbANMlwgn6IcD+kNdeYFr7RiJyBfAQkAl8/lSWDS5/C3ALwLBhw8Ioy5jeRUQYMiCOIQPiuHhi9pHppbVNbC2pZUtxDe+V1PD74moKq+pJ02rGuPYxOfoAU/3FjDp4gMy9H+DxNx590/j0kPAfc3QjkJhlI3masIUT9B3913Tc8R5VfQF4QURmEDhe/7lwlw0uvwRYAoFDN2HUZUyfkJkUS2ZSLDPPOnpNfkOLj+0Ha9lcXMOWkhp+VVzDtoM1NLf6yOYwo10HyE8oZZLrICMqDpBZ/FeiW2uOvmlsSmCPP/0sSBsJaaMCf1NHgCfOgV6a3iycoPcCQ0Ne5wDFnTVW1VUiMlJE0k91WWP6i/joKM4dNpBzhx29sYq/Tdl/uIHth2rZcbCWHaV1/O1gLYXldbT628igijGuA0xNLGdS9EFG1uwnvexVYpvLj33z5Jxg+Ac3AKnBvwOHg9vTwz01vUE4Qb8GGC0iecABYCFwdWgDERkF7A6ejD0PiAYqgKqTLWuMCXC7hNz0BHLTE5g7ftCR6a3+NorK6wMbgEN1bDlYy4uHaimqqKdNIZEGRroPMSXpMBPiKhjlOkh2ZTEpB54jqqX66ArEHQj7T4I/NQ8G5gYeA4bZN4EIdtKgV1WfiNwBrCRwieQTqrpZRBYF5z8GfAm4TkRagUbgSg1cztPhst3UF2MiksftYnRWEqOzko6Z3tTqZ3dZHTsP1bH9UC2FZXW8U1bP3tIGWvxtAAyglklxZeQnVTIuppThcpDMci+JRf/A5Ws4dkVJ2UeDv/3Dzgn0afaDKWMijM/fhreykcLyOgrL6tldVsfusnoKy+opr2sOtlIyXbVMGVDDpIRKRnsqGCqHSG8tIbHBi7uuBAk9nRYVCwOGHxv+A4ZCytDAt4G4gbYhcNiZXl5pjOlDotyuI4eALhp77LzqxlYKywIbgMLyOnaX1vNceT17D9bT1Np2pF2cy8e5ybVMTqxibGwFua4ysvwHSTm8n5i9/0Ba6o59Y0/C0eBPyQk+H3Z0WtIgGxnUQRb0xvQjKXGe404CQ+A3AGW1zRRVNLC3op69FQ3sPdzA6op6/uytp6bJF9qaMUmtTE6pZXxcFXmeSrIpJ813iMSaEqIOrEUaDx+7YlcUJA8J7P2n5AS/CQwNTEseAsmDbbygbmRBb4xBRMhMjiUzOZapecffkKWqoeXYjUBFA7sr6vl7SUPI4aCAaLeLkSnKxKR6xsZVkRdVwWApJ91fSlJTCZ49q5DaEtC2Y1cSnRgI/OTBkDT46PPkIZCcHfgbn2aHiE6DBb0x5qQGxEczOT6ayUMHHDevscXPgapGvJUNeCsbg48GdlQ28qZ3IOV1g49pH+12MTQlionJDYyJryXXU8Vg12HS9TApraXENx3CVf4O1B4E9R+7MndMIPSP2RCEbBySsgInjqNiuvFfo++xoDfGnJG4aDejMhMZldnxOP2dbQiKKuNZvS+B8rqBQN4xywyI9zA42cPYpCZGx9Uw3FPFYFcVGVpOSmtZYGNwYC1sfQn8zcevNHZA4LxAYjD4k7ICw0yEPk/KgpjkfvENwYLeGNOtTrYhaGr1c6imiZLqJkqqGymuauJg8Pm2qijeKnZT2ZBI4PeWR6UmRJOdHMPopBZGx9aQG1NNtruGDKpI8VcQ31xOVEMZ7H8fag91vEGIioPEzOBGIfPoBuCTDURCOiRkBB59+HcGFvTGGEfFetwMT0tgeFpCp22aWv2BDUFV49ENQvD1tmp4a38i1Y0xBIbaOiopJorM5BiysmLITfSRG1NLjqeWbFcV6VSS7D9MQksFUfWHoGwH7FkFTdUdFxGddGzwhz5PzAiZnhG43LQXXWVkQW+M6fViPW7y0hPIS+98Y9DQ4gtuDJo4VNPEodomSmuaKa1t4lBNM6v2t/JsrdDiSwSO/YaQHBtFVnIsmekx5CQIubH15MTUMchdS4bUMECrSfRVEtVUAXWlUFkE3jXQUH78SWUAcQVOHB/ZIGSGPE8PDFYXnxZ8nhY41ORydfU/2xEW9MaYiBAfHcXIjERGZnR+T19VpbqxlUM1zRyqaaK0Nvi3JrAxKK1tYnV5M8/XNtHqdwMDgo+AhGg36UkxpCfGkD4omvQED0Nim8nx1JLlriUtuFFI8lUS3XwYqS+D+jIoXgf15dBc03Fh4ob4VBiYB19/vSv/WQALemNMPyIiDIiPZkB8NGMGJXXaTlWpbGg98m3gUE0T5XXNlNe2BP7WNbOnvJ41RS1UNrQQGGDAA6QFHxAT5QpsEJJiyEiJJn1IDFnxMCS6gUGeOjJcdQykhpS2GmJbK5GG8sA3gW5gQW+MMe2ICKkJ0aQmRDN20Inb+vxtHK5voayumfK6Fsprm49sDMrrAhsGb2Uj6/dXc7i+mbYjI0sc3TB43CNITYhmWGo8f+2G/ljQG2PMGYhyu4782Oxk/G1KZUPLcd8OKupbqKhrxtVNl3pa0BtjTA9xuyRwOCcxBk7yTaErdd9pXmOMMb2CBb0xxkQ4C3pjjIlwYQW9iMwTke0isktE7utg/jUisjH4+KeITAqZVyQim0RkvYjY3USMMaaHnfRkrIi4gcXAbAI3+14jIstVdUtIsz3ATFWtFJGLgSXAtJD5s1S13R2MjTHG9IRw9uinArtUtVBVW4ClwPzQBqr6T1WtDL58n/ajDxljjHFMOEE/BNgf8tobnNaZm4BXQl4r8JqIrBWRWzpbSERuEZECESkoKysLoyxjjDHhCOc6+o6u4O/wjuIiMotA0P+/kMkXqGqxiGQCr4vINlVdddwbqi4hcMiH/Pz83nfHcmOM6aPCCXovMDTkdQ5Q3L6RiJwDPA5crKoVn0xX1eLg31IReYHAoaDjgj7U2rVry0Vkbxi1dSQd6G/nA6zP/YP1uX843T4P72xGOEG/BhgtInnAAWAhcHVoAxEZBjwPXKuqO0KmJwAuVa0NPp8D/OhkK1TVjDDq6pCIFKhq/uku3xdZn/sH63P/0B19PmnQq6pPRO4AVgJu4AlV3Swii4LzHwMeJDA6z28lMFaDL1hoFvBCcFoU8LSqvtqVHTDGGHNiYY11o6orgBXtpj0W8vzrwNc7WK4QmNR+ujHGmJ4Tib+MXeJ0AQ6wPvcP1uf+ocv7LKp2gYsxxkSySNyjN8YYE8KC3hhjIlzEBP3JBl6LFB0NEiciqSLyuojsDP4d6HSdZ0pEnhCRUhH5OGRap/0UkfuDn/12EZnrTNVnppM+/0BEDgQ/7/UicknIvD7dZxEZKiJvichWEdksIt8KTo/0z7mzfnffZ62qff5B4LLP3cAIIBrYAIxzuq5u6msRkN5u2i+A+4LP7wN+7nSdXdDPGcB5wMcn6ycwLviZxwB5wf8W3E73oYv6/APgOx207fN9BrKB84LPk4AdwX5F+ufcWb+77bOOlD36kw68FuHmA38KPv8T8AXnSukaGhgm43C7yZ31cz6wVFWbVXUPsIvAfxN9Sid97kyf77OqlqjquuDzWmArgXG0Iv1z7qzfnTnjfkdK0J/qwGt9WUeDxGWpagkE/iMCMh2rrnt11s9I//zvCN7r4YmQwxgR1WcRyQXOBT6gH33O7foN3fRZR0rQhz3wWgS4QFXPAy4GbheRGU4X1AtE8uf/KDASmAyUAP8ZnB4xfRaRROA54C5VrTlR0w6m9ck+Q4f97rbPOlKCPqyB1yKBhgwSB3wySNwhEckGCP4tda7CbtVZPyP281fVQ6rqV9U24H84+pU9IvosIh4CYfeUqj4fnBzxn3NH/e7OzzpSgv7IwGsiEk1g4LXlDtfU5UQkQUSSPnlOYJC4jwn09fpgs+uB/3Omwm7XWT+XAwtFJCY4+N5o4EMH6utynwRe0BUEPm+IgD5LYBCs3wNbVfWXIbMi+nPurN/d+lk7fQa6C89kX0Lg7PVu4AGn6+mmPo4gcPZ9A7D5k34SGFDu78DO4N9Up2vtgr7+hcDX11YCezQ3naifwAPBz347gaGyHe9DF/X5f4FNwMbg//DZkdJnAvet0GDf1gcfl/SDz7mzfnfbZ21DIBhjTISLlEM3xhhjOmFBb4wxEc6C3hhjIpwFvTHGRDgLemOMiXAW9MYYE+Es6I0xJsL9f8i44yCjL2r2AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'], label ='loss')\n",
    "plt.plot(history.history['val_loss'], label='val_loss')\n",
    "\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "40a1f16c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7803b8124ee0>"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
    "\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "6870a6dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "y_log = model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "46a6b6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.where(y_log > 0.5, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "aabb78da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95.24 % accuracy\n"
     ]
    }
   ],
   "source": [
    "result_unbalanced = accuracy_score(y_test, y_pred)*100\n",
    "print('%.2f' % result_unbalanced, \"% accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "e1934297",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc.append(result_unbalanced)\n",
    "model.append('Single_Layer Perceptron')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf27b0f",
   "metadata": {},
   "source": [
    "## handling imbalanced dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "3f069aff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Call  Failure</th>\n",
       "      <th>Complains</th>\n",
       "      <th>Subscription  Length</th>\n",
       "      <th>Charge  Amount</th>\n",
       "      <th>Seconds of Use</th>\n",
       "      <th>Frequency of use</th>\n",
       "      <th>Frequency of SMS</th>\n",
       "      <th>Distinct Called Numbers</th>\n",
       "      <th>Age Group</th>\n",
       "      <th>Tariff Plan</th>\n",
       "      <th>Status</th>\n",
       "      <th>Age</th>\n",
       "      <th>Customer Value</th>\n",
       "      <th>Churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4370.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>197.640</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>318.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>46.035</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2453.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>359.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1536.520</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4198.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>240.020</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2393.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>145.805</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1408.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>57.000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2978</th>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1148.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>106.680</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2027</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1963.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>188.040</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>777.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>31.400</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3128</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>438.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>45.840</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5310 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Call  Failure  Complains  Subscription  Length  Charge  Amount  \\\n",
       "0               8.0        0.0                  38.0             0.0   \n",
       "1               0.0        0.0                  39.0             0.0   \n",
       "2              10.0        0.0                  37.0             0.0   \n",
       "3              10.0        0.0                  38.0             0.0   \n",
       "4               3.0        0.0                  38.0             0.0   \n",
       "...             ...        ...                   ...             ...   \n",
       "249             2.0        0.0                   5.0             0.0   \n",
       "2978           11.0        0.0                  39.0             0.0   \n",
       "2027            4.0        1.0                  34.0             0.0   \n",
       "949             0.0        0.0                   8.0             0.0   \n",
       "3128            5.0        0.0                  38.0             0.0   \n",
       "\n",
       "      Seconds of Use  Frequency of use  Frequency of SMS  \\\n",
       "0             4370.0              71.0               5.0   \n",
       "1              318.0               5.0               7.0   \n",
       "2             2453.0              60.0             359.0   \n",
       "3             4198.0              66.0               1.0   \n",
       "4             2393.0              58.0               2.0   \n",
       "...              ...               ...               ...   \n",
       "249           1408.0              17.0               0.0   \n",
       "2978          1148.0              19.0              15.0   \n",
       "2027          1963.0              38.0              27.0   \n",
       "949            777.0               8.0               0.0   \n",
       "3128           438.0               8.0               7.0   \n",
       "\n",
       "      Distinct Called Numbers  Age Group  Tariff Plan  Status   Age  \\\n",
       "0                        17.0        3.0          1.0     1.0  30.0   \n",
       "1                         4.0        2.0          1.0     2.0  25.0   \n",
       "2                        24.0        3.0          1.0     1.0  30.0   \n",
       "3                        35.0        1.0          1.0     1.0  15.0   \n",
       "4                        33.0        1.0          1.0     1.0  15.0   \n",
       "...                       ...        ...          ...     ...   ...   \n",
       "249                       3.0        3.0          1.0     1.0  30.0   \n",
       "2978                      4.0        3.0          1.0     2.0  30.0   \n",
       "2027                     29.0        3.0          1.0     2.0  30.0   \n",
       "949                       7.0        3.0          1.0     1.0  30.0   \n",
       "3128                      4.0        3.0          1.0     2.0  30.0   \n",
       "\n",
       "      Customer Value  Churn  \n",
       "0            197.640    0.0  \n",
       "1             46.035    0.0  \n",
       "2           1536.520    0.0  \n",
       "3            240.020    0.0  \n",
       "4            145.805    0.0  \n",
       "...              ...    ...  \n",
       "249           57.000    1.0  \n",
       "2978         106.680    1.0  \n",
       "2027         188.040    1.0  \n",
       "949           31.400    1.0  \n",
       "3128          45.840    1.0  \n",
       "\n",
       "[5310 rows x 14 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "# Separate majority and minority classes\n",
    "majority_class = df[df['Churn'] == 0]\n",
    "minority_class = df[df['Churn'] == 1]\n",
    "\n",
    "# Upsample the minority class\n",
    "upsampled_minority = resample(minority_class,\n",
    "                              replace=True,  # Sample with replacement\n",
    "                              n_samples=len(majority_class),  # Match the number of majority class samples\n",
    "                              random_state=0)  # Set random state for reproducibility\n",
    "\n",
    "# Combine the upsampled minority class with the majority class\n",
    "balanced_data = pd.concat([majority_class, upsampled_minority])\n",
    "balanced_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "cdfb301c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    2655\n",
       "1.0    2655\n",
       "Name: Churn, dtype: int64"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(balanced_data['Churn'].unique(), balanced_data['Churn'].value_counts())\n",
    "balanced_data.Churn.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "d6ad820d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = balanced_data['Churn']\n",
    "X = balanced_data.drop('Churn',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "134d9d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "e845eee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "77e82dfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train Shape :  (4248, 13)\n",
      "X_test Shape :  (1062, 13)\n",
      "y_train Shape :  (4248,)\n",
      "y_test Shape :  (1062,)\n"
     ]
    }
   ],
   "source": [
    "# check the shape of X_train & X_test, y_train & y_test\n",
    "print(\"X_train Shape : \", X_train.shape)\n",
    "print(\"X_test Shape : \", X_test.shape)\n",
    "print(\"y_train Shape : \", y_train.shape)\n",
    "print(\"y_test Shape : \", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "4b84871d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "107/107 [==============================] - 1s 3ms/step - loss: 0.7701 - accuracy: 0.5291 - val_loss: 0.7349 - val_accuracy: 0.5318\n",
      "Epoch 2/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.7313 - accuracy: 0.5412 - val_loss: 0.7073 - val_accuracy: 0.5576\n",
      "Epoch 3/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.7069 - accuracy: 0.5568 - val_loss: 0.6873 - val_accuracy: 0.5706\n",
      "Epoch 4/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.6884 - accuracy: 0.5706 - val_loss: 0.6718 - val_accuracy: 0.5788\n",
      "Epoch 5/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.6735 - accuracy: 0.5818 - val_loss: 0.6590 - val_accuracy: 0.5871\n",
      "Epoch 6/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.6612 - accuracy: 0.6004 - val_loss: 0.6481 - val_accuracy: 0.6012\n",
      "Epoch 7/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.6504 - accuracy: 0.6157 - val_loss: 0.6388 - val_accuracy: 0.6094\n",
      "Epoch 8/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.6411 - accuracy: 0.6271 - val_loss: 0.6304 - val_accuracy: 0.6212\n",
      "Epoch 9/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.6327 - accuracy: 0.6398 - val_loss: 0.6229 - val_accuracy: 0.6341\n",
      "Epoch 10/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.6250 - accuracy: 0.6477 - val_loss: 0.6160 - val_accuracy: 0.6412\n",
      "Epoch 11/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.6179 - accuracy: 0.6598 - val_loss: 0.6096 - val_accuracy: 0.6494\n",
      "Epoch 12/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.6114 - accuracy: 0.6680 - val_loss: 0.6037 - val_accuracy: 0.6576\n",
      "Epoch 13/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.6052 - accuracy: 0.6810 - val_loss: 0.5982 - val_accuracy: 0.6788\n",
      "Epoch 14/250\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.5994 - accuracy: 0.6966 - val_loss: 0.5929 - val_accuracy: 0.6859\n",
      "Epoch 15/250\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.5939 - accuracy: 0.7051 - val_loss: 0.5879 - val_accuracy: 0.6976\n",
      "Epoch 16/250\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.5887 - accuracy: 0.7134 - val_loss: 0.5831 - val_accuracy: 0.7082\n",
      "Epoch 17/250\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.5838 - accuracy: 0.7204 - val_loss: 0.5786 - val_accuracy: 0.7153\n",
      "Epoch 18/250\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.5791 - accuracy: 0.7287 - val_loss: 0.5744 - val_accuracy: 0.7200\n",
      "Epoch 19/250\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.5745 - accuracy: 0.7331 - val_loss: 0.5703 - val_accuracy: 0.7329\n",
      "Epoch 20/250\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.5702 - accuracy: 0.7398 - val_loss: 0.5664 - val_accuracy: 0.7365\n",
      "Epoch 21/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.5660 - accuracy: 0.7451 - val_loss: 0.5627 - val_accuracy: 0.7482\n",
      "Epoch 22/250\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.5620 - accuracy: 0.7534 - val_loss: 0.5591 - val_accuracy: 0.7529\n",
      "Epoch 23/250\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.5582 - accuracy: 0.7616 - val_loss: 0.5556 - val_accuracy: 0.7588\n",
      "Epoch 24/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.5544 - accuracy: 0.7678 - val_loss: 0.5522 - val_accuracy: 0.7624\n",
      "Epoch 25/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.5508 - accuracy: 0.7696 - val_loss: 0.5489 - val_accuracy: 0.7659\n",
      "Epoch 26/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.5472 - accuracy: 0.7737 - val_loss: 0.5457 - val_accuracy: 0.7659\n",
      "Epoch 27/250\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.5436 - accuracy: 0.7805 - val_loss: 0.5425 - val_accuracy: 0.7706\n",
      "Epoch 28/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.5401 - accuracy: 0.7855 - val_loss: 0.5394 - val_accuracy: 0.7729\n",
      "Epoch 29/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.5367 - accuracy: 0.7875 - val_loss: 0.5363 - val_accuracy: 0.7718\n",
      "Epoch 30/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.5333 - accuracy: 0.7913 - val_loss: 0.5332 - val_accuracy: 0.7741\n",
      "Epoch 31/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.5299 - accuracy: 0.7937 - val_loss: 0.5302 - val_accuracy: 0.7776\n",
      "Epoch 32/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.5266 - accuracy: 0.7958 - val_loss: 0.5272 - val_accuracy: 0.7800\n",
      "Epoch 33/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.5233 - accuracy: 0.7987 - val_loss: 0.5242 - val_accuracy: 0.7800\n",
      "Epoch 34/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.5200 - accuracy: 0.8022 - val_loss: 0.5213 - val_accuracy: 0.7800\n",
      "Epoch 35/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.5168 - accuracy: 0.8040 - val_loss: 0.5185 - val_accuracy: 0.7824\n",
      "Epoch 36/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.5136 - accuracy: 0.8052 - val_loss: 0.5157 - val_accuracy: 0.7835\n",
      "Epoch 37/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.5104 - accuracy: 0.8052 - val_loss: 0.5130 - val_accuracy: 0.7847\n",
      "Epoch 38/250\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.5074 - accuracy: 0.8072 - val_loss: 0.5103 - val_accuracy: 0.7847\n",
      "Epoch 39/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.8087 - val_loss: 0.5077 - val_accuracy: 0.7882\n",
      "Epoch 40/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.5014 - accuracy: 0.8090 - val_loss: 0.5050 - val_accuracy: 0.7906\n",
      "Epoch 41/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.4984 - accuracy: 0.8102 - val_loss: 0.5023 - val_accuracy: 0.7929\n",
      "Epoch 42/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.4954 - accuracy: 0.8105 - val_loss: 0.4997 - val_accuracy: 0.7953\n",
      "Epoch 43/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.4924 - accuracy: 0.8125 - val_loss: 0.4971 - val_accuracy: 0.7976\n",
      "Epoch 44/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.4895 - accuracy: 0.8164 - val_loss: 0.4945 - val_accuracy: 0.8000\n",
      "Epoch 45/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.4867 - accuracy: 0.8172 - val_loss: 0.4919 - val_accuracy: 0.8024\n",
      "Epoch 46/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.4839 - accuracy: 0.8190 - val_loss: 0.4895 - val_accuracy: 0.8000\n",
      "Epoch 47/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.4811 - accuracy: 0.8214 - val_loss: 0.4871 - val_accuracy: 0.8000\n",
      "Epoch 48/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.4784 - accuracy: 0.8228 - val_loss: 0.4847 - val_accuracy: 0.8000\n",
      "Epoch 49/250\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4758 - accuracy: 0.8234 - val_loss: 0.4824 - val_accuracy: 0.7988\n",
      "Epoch 50/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.4733 - accuracy: 0.8240 - val_loss: 0.4802 - val_accuracy: 0.8000\n",
      "Epoch 51/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.4708 - accuracy: 0.8258 - val_loss: 0.4780 - val_accuracy: 0.8012\n",
      "Epoch 52/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.4683 - accuracy: 0.8270 - val_loss: 0.4759 - val_accuracy: 0.8012\n",
      "Epoch 53/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.4659 - accuracy: 0.8278 - val_loss: 0.4738 - val_accuracy: 0.8024\n",
      "Epoch 54/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.4635 - accuracy: 0.8273 - val_loss: 0.4718 - val_accuracy: 0.8024\n",
      "Epoch 55/250\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4612 - accuracy: 0.8264 - val_loss: 0.4697 - val_accuracy: 0.8035\n",
      "Epoch 56/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.4588 - accuracy: 0.8273 - val_loss: 0.4677 - val_accuracy: 0.8071\n",
      "Epoch 57/250\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4565 - accuracy: 0.8275 - val_loss: 0.4657 - val_accuracy: 0.8071\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/250\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4542 - accuracy: 0.8290 - val_loss: 0.4637 - val_accuracy: 0.8094\n",
      "Epoch 59/250\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4520 - accuracy: 0.8293 - val_loss: 0.4617 - val_accuracy: 0.8106\n",
      "Epoch 60/250\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4497 - accuracy: 0.8296 - val_loss: 0.4598 - val_accuracy: 0.8118\n",
      "Epoch 61/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.4476 - accuracy: 0.8314 - val_loss: 0.4579 - val_accuracy: 0.8118\n",
      "Epoch 62/250\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.4454 - accuracy: 0.8305 - val_loss: 0.4560 - val_accuracy: 0.8118\n",
      "Epoch 63/250\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.4432 - accuracy: 0.8311 - val_loss: 0.4541 - val_accuracy: 0.8129\n",
      "Epoch 64/250\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.4411 - accuracy: 0.8323 - val_loss: 0.4523 - val_accuracy: 0.8129\n",
      "Epoch 65/250\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4391 - accuracy: 0.8325 - val_loss: 0.4505 - val_accuracy: 0.8141\n",
      "Epoch 66/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.4371 - accuracy: 0.8331 - val_loss: 0.4487 - val_accuracy: 0.8153\n",
      "Epoch 67/250\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4351 - accuracy: 0.8334 - val_loss: 0.4470 - val_accuracy: 0.8165\n",
      "Epoch 68/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.4332 - accuracy: 0.8320 - val_loss: 0.4453 - val_accuracy: 0.8165\n",
      "Epoch 69/250\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4313 - accuracy: 0.8331 - val_loss: 0.4437 - val_accuracy: 0.8188\n",
      "Epoch 70/250\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4294 - accuracy: 0.8343 - val_loss: 0.4421 - val_accuracy: 0.8200\n",
      "Epoch 71/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.4277 - accuracy: 0.8352 - val_loss: 0.4405 - val_accuracy: 0.8188\n",
      "Epoch 72/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.4259 - accuracy: 0.8343 - val_loss: 0.4390 - val_accuracy: 0.8188\n",
      "Epoch 73/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.4242 - accuracy: 0.8343 - val_loss: 0.4375 - val_accuracy: 0.8212\n",
      "Epoch 74/250\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4226 - accuracy: 0.8334 - val_loss: 0.4360 - val_accuracy: 0.8188\n",
      "Epoch 75/250\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4210 - accuracy: 0.8337 - val_loss: 0.4346 - val_accuracy: 0.8188\n",
      "Epoch 76/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.4194 - accuracy: 0.8340 - val_loss: 0.4332 - val_accuracy: 0.8188\n",
      "Epoch 77/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.4178 - accuracy: 0.8346 - val_loss: 0.4318 - val_accuracy: 0.8212\n",
      "Epoch 78/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.4163 - accuracy: 0.8346 - val_loss: 0.4305 - val_accuracy: 0.8224\n",
      "Epoch 79/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.4149 - accuracy: 0.8370 - val_loss: 0.4292 - val_accuracy: 0.8224\n",
      "Epoch 80/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.4134 - accuracy: 0.8381 - val_loss: 0.4279 - val_accuracy: 0.8224\n",
      "Epoch 81/250\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.4120 - accuracy: 0.8381 - val_loss: 0.4266 - val_accuracy: 0.8224\n",
      "Epoch 82/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.4107 - accuracy: 0.8381 - val_loss: 0.4254 - val_accuracy: 0.8224\n",
      "Epoch 83/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.4093 - accuracy: 0.8381 - val_loss: 0.4242 - val_accuracy: 0.8224\n",
      "Epoch 84/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.4080 - accuracy: 0.8384 - val_loss: 0.4230 - val_accuracy: 0.8235\n",
      "Epoch 85/250\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4067 - accuracy: 0.8387 - val_loss: 0.4219 - val_accuracy: 0.8247\n",
      "Epoch 86/250\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4055 - accuracy: 0.8387 - val_loss: 0.4207 - val_accuracy: 0.8247\n",
      "Epoch 87/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.4042 - accuracy: 0.8390 - val_loss: 0.4196 - val_accuracy: 0.8235\n",
      "Epoch 88/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.4030 - accuracy: 0.8393 - val_loss: 0.4185 - val_accuracy: 0.8235\n",
      "Epoch 89/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.4019 - accuracy: 0.8393 - val_loss: 0.4175 - val_accuracy: 0.8235\n",
      "Epoch 90/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.4007 - accuracy: 0.8393 - val_loss: 0.4164 - val_accuracy: 0.8224\n",
      "Epoch 91/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3996 - accuracy: 0.8393 - val_loss: 0.4154 - val_accuracy: 0.8224\n",
      "Epoch 92/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3984 - accuracy: 0.8393 - val_loss: 0.4144 - val_accuracy: 0.8224\n",
      "Epoch 93/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3974 - accuracy: 0.8393 - val_loss: 0.4134 - val_accuracy: 0.8224\n",
      "Epoch 94/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3963 - accuracy: 0.8393 - val_loss: 0.4124 - val_accuracy: 0.8235\n",
      "Epoch 95/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3952 - accuracy: 0.8402 - val_loss: 0.4114 - val_accuracy: 0.8247\n",
      "Epoch 96/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3942 - accuracy: 0.8405 - val_loss: 0.4105 - val_accuracy: 0.8259\n",
      "Epoch 97/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3931 - accuracy: 0.8411 - val_loss: 0.4096 - val_accuracy: 0.8282\n",
      "Epoch 98/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3921 - accuracy: 0.8414 - val_loss: 0.4086 - val_accuracy: 0.8282\n",
      "Epoch 99/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3911 - accuracy: 0.8414 - val_loss: 0.4077 - val_accuracy: 0.8282\n",
      "Epoch 100/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3901 - accuracy: 0.8420 - val_loss: 0.4069 - val_accuracy: 0.8271\n",
      "Epoch 101/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3892 - accuracy: 0.8417 - val_loss: 0.4060 - val_accuracy: 0.8271\n",
      "Epoch 102/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3882 - accuracy: 0.8420 - val_loss: 0.4051 - val_accuracy: 0.8282\n",
      "Epoch 103/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3873 - accuracy: 0.8420 - val_loss: 0.4043 - val_accuracy: 0.8282\n",
      "Epoch 104/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3864 - accuracy: 0.8420 - val_loss: 0.4035 - val_accuracy: 0.8282\n",
      "Epoch 105/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3855 - accuracy: 0.8423 - val_loss: 0.4027 - val_accuracy: 0.8282\n",
      "Epoch 106/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3846 - accuracy: 0.8414 - val_loss: 0.4019 - val_accuracy: 0.8282\n",
      "Epoch 107/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3838 - accuracy: 0.8414 - val_loss: 0.4011 - val_accuracy: 0.8271\n",
      "Epoch 108/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3830 - accuracy: 0.8414 - val_loss: 0.4004 - val_accuracy: 0.8282\n",
      "Epoch 109/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3821 - accuracy: 0.8414 - val_loss: 0.3996 - val_accuracy: 0.8282\n",
      "Epoch 110/250\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3813 - accuracy: 0.8414 - val_loss: 0.3989 - val_accuracy: 0.8282\n",
      "Epoch 111/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3805 - accuracy: 0.8414 - val_loss: 0.3981 - val_accuracy: 0.8271\n",
      "Epoch 112/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3797 - accuracy: 0.8411 - val_loss: 0.3974 - val_accuracy: 0.8282\n",
      "Epoch 113/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3789 - accuracy: 0.8411 - val_loss: 0.3967 - val_accuracy: 0.8282\n",
      "Epoch 114/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3782 - accuracy: 0.8411 - val_loss: 0.3960 - val_accuracy: 0.8282\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3774 - accuracy: 0.8411 - val_loss: 0.3953 - val_accuracy: 0.8282\n",
      "Epoch 116/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3767 - accuracy: 0.8411 - val_loss: 0.3946 - val_accuracy: 0.8282\n",
      "Epoch 117/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3760 - accuracy: 0.8411 - val_loss: 0.3940 - val_accuracy: 0.8282\n",
      "Epoch 118/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3752 - accuracy: 0.8411 - val_loss: 0.3933 - val_accuracy: 0.8282\n",
      "Epoch 119/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3746 - accuracy: 0.8411 - val_loss: 0.3927 - val_accuracy: 0.8282\n",
      "Epoch 120/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3739 - accuracy: 0.8411 - val_loss: 0.3920 - val_accuracy: 0.8282\n",
      "Epoch 121/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3732 - accuracy: 0.8411 - val_loss: 0.3914 - val_accuracy: 0.8282\n",
      "Epoch 122/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3725 - accuracy: 0.8414 - val_loss: 0.3908 - val_accuracy: 0.8282\n",
      "Epoch 123/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3719 - accuracy: 0.8417 - val_loss: 0.3902 - val_accuracy: 0.8282\n",
      "Epoch 124/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3712 - accuracy: 0.8417 - val_loss: 0.3896 - val_accuracy: 0.8282\n",
      "Epoch 125/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3706 - accuracy: 0.8420 - val_loss: 0.3890 - val_accuracy: 0.8294\n",
      "Epoch 126/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3700 - accuracy: 0.8420 - val_loss: 0.3884 - val_accuracy: 0.8294\n",
      "Epoch 127/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3694 - accuracy: 0.8423 - val_loss: 0.3879 - val_accuracy: 0.8294\n",
      "Epoch 128/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3688 - accuracy: 0.8428 - val_loss: 0.3873 - val_accuracy: 0.8294\n",
      "Epoch 129/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3682 - accuracy: 0.8428 - val_loss: 0.3867 - val_accuracy: 0.8294\n",
      "Epoch 130/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3676 - accuracy: 0.8428 - val_loss: 0.3861 - val_accuracy: 0.8294\n",
      "Epoch 131/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3670 - accuracy: 0.8428 - val_loss: 0.3856 - val_accuracy: 0.8294\n",
      "Epoch 132/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3664 - accuracy: 0.8428 - val_loss: 0.3850 - val_accuracy: 0.8306\n",
      "Epoch 133/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3658 - accuracy: 0.8428 - val_loss: 0.3845 - val_accuracy: 0.8306\n",
      "Epoch 134/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3653 - accuracy: 0.8434 - val_loss: 0.3840 - val_accuracy: 0.8318\n",
      "Epoch 135/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3647 - accuracy: 0.8446 - val_loss: 0.3834 - val_accuracy: 0.8318\n",
      "Epoch 136/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3642 - accuracy: 0.8452 - val_loss: 0.3829 - val_accuracy: 0.8318\n",
      "Epoch 137/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3636 - accuracy: 0.8452 - val_loss: 0.3824 - val_accuracy: 0.8318\n",
      "Epoch 138/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3631 - accuracy: 0.8455 - val_loss: 0.3819 - val_accuracy: 0.8318\n",
      "Epoch 139/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3625 - accuracy: 0.8455 - val_loss: 0.3814 - val_accuracy: 0.8318\n",
      "Epoch 140/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3620 - accuracy: 0.8458 - val_loss: 0.3809 - val_accuracy: 0.8318\n",
      "Epoch 141/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3615 - accuracy: 0.8458 - val_loss: 0.3804 - val_accuracy: 0.8318\n",
      "Epoch 142/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3610 - accuracy: 0.8458 - val_loss: 0.3799 - val_accuracy: 0.8318\n",
      "Epoch 143/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3605 - accuracy: 0.8458 - val_loss: 0.3794 - val_accuracy: 0.8318\n",
      "Epoch 144/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3600 - accuracy: 0.8458 - val_loss: 0.3789 - val_accuracy: 0.8318\n",
      "Epoch 145/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3595 - accuracy: 0.8461 - val_loss: 0.3785 - val_accuracy: 0.8318\n",
      "Epoch 146/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3590 - accuracy: 0.8464 - val_loss: 0.3780 - val_accuracy: 0.8318\n",
      "Epoch 147/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3586 - accuracy: 0.8464 - val_loss: 0.3776 - val_accuracy: 0.8318\n",
      "Epoch 148/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3581 - accuracy: 0.8464 - val_loss: 0.3771 - val_accuracy: 0.8318\n",
      "Epoch 149/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3576 - accuracy: 0.8464 - val_loss: 0.3767 - val_accuracy: 0.8318\n",
      "Epoch 150/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3572 - accuracy: 0.8464 - val_loss: 0.3762 - val_accuracy: 0.8318\n",
      "Epoch 151/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3567 - accuracy: 0.8467 - val_loss: 0.3758 - val_accuracy: 0.8318\n",
      "Epoch 152/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3563 - accuracy: 0.8470 - val_loss: 0.3753 - val_accuracy: 0.8318\n",
      "Epoch 153/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3558 - accuracy: 0.8473 - val_loss: 0.3749 - val_accuracy: 0.8318\n",
      "Epoch 154/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3554 - accuracy: 0.8473 - val_loss: 0.3745 - val_accuracy: 0.8318\n",
      "Epoch 155/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3550 - accuracy: 0.8473 - val_loss: 0.3741 - val_accuracy: 0.8341\n",
      "Epoch 156/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3545 - accuracy: 0.8473 - val_loss: 0.3736 - val_accuracy: 0.8341\n",
      "Epoch 157/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3541 - accuracy: 0.8487 - val_loss: 0.3732 - val_accuracy: 0.8365\n",
      "Epoch 158/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3537 - accuracy: 0.8490 - val_loss: 0.3728 - val_accuracy: 0.8365\n",
      "Epoch 159/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3533 - accuracy: 0.8493 - val_loss: 0.3724 - val_accuracy: 0.8365\n",
      "Epoch 160/250\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3529 - accuracy: 0.8496 - val_loss: 0.3720 - val_accuracy: 0.8376\n",
      "Epoch 161/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3524 - accuracy: 0.8499 - val_loss: 0.3716 - val_accuracy: 0.8376\n",
      "Epoch 162/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3520 - accuracy: 0.8505 - val_loss: 0.3712 - val_accuracy: 0.8412\n",
      "Epoch 163/250\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3516 - accuracy: 0.8508 - val_loss: 0.3708 - val_accuracy: 0.8412\n",
      "Epoch 164/250\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3512 - accuracy: 0.8508 - val_loss: 0.3704 - val_accuracy: 0.8412\n",
      "Epoch 165/250\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3508 - accuracy: 0.8508 - val_loss: 0.3701 - val_accuracy: 0.8424\n",
      "Epoch 166/250\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3505 - accuracy: 0.8511 - val_loss: 0.3697 - val_accuracy: 0.8424\n",
      "Epoch 167/250\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3501 - accuracy: 0.8511 - val_loss: 0.3693 - val_accuracy: 0.8424\n",
      "Epoch 168/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3497 - accuracy: 0.8520 - val_loss: 0.3689 - val_accuracy: 0.8424\n",
      "Epoch 169/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3493 - accuracy: 0.8540 - val_loss: 0.3685 - val_accuracy: 0.8424\n",
      "Epoch 170/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3489 - accuracy: 0.8543 - val_loss: 0.3682 - val_accuracy: 0.8424\n",
      "Epoch 171/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3485 - accuracy: 0.8549 - val_loss: 0.3678 - val_accuracy: 0.8424\n",
      "Epoch 172/250\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3482 - accuracy: 0.8552 - val_loss: 0.3675 - val_accuracy: 0.8424\n",
      "Epoch 173/250\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3478 - accuracy: 0.8552 - val_loss: 0.3671 - val_accuracy: 0.8424\n",
      "Epoch 174/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3474 - accuracy: 0.8558 - val_loss: 0.3668 - val_accuracy: 0.8424\n",
      "Epoch 175/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3471 - accuracy: 0.8558 - val_loss: 0.3664 - val_accuracy: 0.8435\n",
      "Epoch 176/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3467 - accuracy: 0.8564 - val_loss: 0.3661 - val_accuracy: 0.8435\n",
      "Epoch 177/250\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3463 - accuracy: 0.8567 - val_loss: 0.3657 - val_accuracy: 0.8435\n",
      "Epoch 178/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3460 - accuracy: 0.8570 - val_loss: 0.3654 - val_accuracy: 0.8435\n",
      "Epoch 179/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3456 - accuracy: 0.8570 - val_loss: 0.3650 - val_accuracy: 0.8435\n",
      "Epoch 180/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3453 - accuracy: 0.8570 - val_loss: 0.3647 - val_accuracy: 0.8435\n",
      "Epoch 181/250\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3449 - accuracy: 0.8570 - val_loss: 0.3644 - val_accuracy: 0.8447\n",
      "Epoch 182/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3446 - accuracy: 0.8570 - val_loss: 0.3640 - val_accuracy: 0.8447\n",
      "Epoch 183/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3443 - accuracy: 0.8573 - val_loss: 0.3637 - val_accuracy: 0.8447\n",
      "Epoch 184/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3439 - accuracy: 0.8573 - val_loss: 0.3634 - val_accuracy: 0.8447\n",
      "Epoch 185/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3436 - accuracy: 0.8576 - val_loss: 0.3631 - val_accuracy: 0.8447\n",
      "Epoch 186/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3433 - accuracy: 0.8582 - val_loss: 0.3627 - val_accuracy: 0.8447\n",
      "Epoch 187/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3430 - accuracy: 0.8582 - val_loss: 0.3624 - val_accuracy: 0.8447\n",
      "Epoch 188/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3426 - accuracy: 0.8582 - val_loss: 0.3621 - val_accuracy: 0.8424\n",
      "Epoch 189/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3423 - accuracy: 0.8582 - val_loss: 0.3618 - val_accuracy: 0.8424\n",
      "Epoch 190/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3420 - accuracy: 0.8584 - val_loss: 0.3615 - val_accuracy: 0.8424\n",
      "Epoch 191/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3417 - accuracy: 0.8584 - val_loss: 0.3612 - val_accuracy: 0.8424\n",
      "Epoch 192/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3414 - accuracy: 0.8587 - val_loss: 0.3609 - val_accuracy: 0.8424\n",
      "Epoch 193/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3411 - accuracy: 0.8587 - val_loss: 0.3606 - val_accuracy: 0.8424\n",
      "Epoch 194/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3408 - accuracy: 0.8587 - val_loss: 0.3604 - val_accuracy: 0.8424\n",
      "Epoch 195/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3405 - accuracy: 0.8587 - val_loss: 0.3601 - val_accuracy: 0.8424\n",
      "Epoch 196/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3402 - accuracy: 0.8593 - val_loss: 0.3598 - val_accuracy: 0.8435\n",
      "Epoch 197/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3399 - accuracy: 0.8593 - val_loss: 0.3595 - val_accuracy: 0.8435\n",
      "Epoch 198/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3396 - accuracy: 0.8593 - val_loss: 0.3592 - val_accuracy: 0.8447\n",
      "Epoch 199/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3393 - accuracy: 0.8596 - val_loss: 0.3589 - val_accuracy: 0.8447\n",
      "Epoch 200/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3390 - accuracy: 0.8596 - val_loss: 0.3587 - val_accuracy: 0.8459\n",
      "Epoch 201/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3388 - accuracy: 0.8596 - val_loss: 0.3584 - val_accuracy: 0.8459\n",
      "Epoch 202/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3385 - accuracy: 0.8599 - val_loss: 0.3581 - val_accuracy: 0.8471\n",
      "Epoch 203/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3382 - accuracy: 0.8599 - val_loss: 0.3578 - val_accuracy: 0.8471\n",
      "Epoch 204/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3379 - accuracy: 0.8599 - val_loss: 0.3576 - val_accuracy: 0.8471\n",
      "Epoch 205/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3376 - accuracy: 0.8599 - val_loss: 0.3573 - val_accuracy: 0.8471\n",
      "Epoch 206/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3374 - accuracy: 0.8599 - val_loss: 0.3570 - val_accuracy: 0.8471\n",
      "Epoch 207/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3371 - accuracy: 0.8599 - val_loss: 0.3568 - val_accuracy: 0.8471\n",
      "Epoch 208/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3368 - accuracy: 0.8599 - val_loss: 0.3565 - val_accuracy: 0.8471\n",
      "Epoch 209/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3366 - accuracy: 0.8599 - val_loss: 0.3563 - val_accuracy: 0.8471\n",
      "Epoch 210/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3363 - accuracy: 0.8599 - val_loss: 0.3560 - val_accuracy: 0.8471\n",
      "Epoch 211/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3360 - accuracy: 0.8602 - val_loss: 0.3558 - val_accuracy: 0.8471\n",
      "Epoch 212/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3358 - accuracy: 0.8602 - val_loss: 0.3555 - val_accuracy: 0.8471\n",
      "Epoch 213/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3355 - accuracy: 0.8602 - val_loss: 0.3553 - val_accuracy: 0.8471\n",
      "Epoch 214/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3353 - accuracy: 0.8602 - val_loss: 0.3550 - val_accuracy: 0.8471\n",
      "Epoch 215/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3350 - accuracy: 0.8605 - val_loss: 0.3548 - val_accuracy: 0.8471\n",
      "Epoch 216/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3348 - accuracy: 0.8605 - val_loss: 0.3546 - val_accuracy: 0.8471\n",
      "Epoch 217/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3345 - accuracy: 0.8605 - val_loss: 0.3543 - val_accuracy: 0.8482\n",
      "Epoch 218/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3343 - accuracy: 0.8608 - val_loss: 0.3541 - val_accuracy: 0.8482\n",
      "Epoch 219/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3341 - accuracy: 0.8602 - val_loss: 0.3539 - val_accuracy: 0.8482\n",
      "Epoch 220/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3338 - accuracy: 0.8596 - val_loss: 0.3536 - val_accuracy: 0.8482\n",
      "Epoch 221/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3336 - accuracy: 0.8599 - val_loss: 0.3534 - val_accuracy: 0.8482\n",
      "Epoch 222/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3334 - accuracy: 0.8599 - val_loss: 0.3532 - val_accuracy: 0.8482\n",
      "Epoch 223/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3331 - accuracy: 0.8599 - val_loss: 0.3530 - val_accuracy: 0.8482\n",
      "Epoch 224/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3329 - accuracy: 0.8602 - val_loss: 0.3528 - val_accuracy: 0.8482\n",
      "Epoch 225/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3327 - accuracy: 0.8602 - val_loss: 0.3525 - val_accuracy: 0.8482\n",
      "Epoch 226/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3324 - accuracy: 0.8590 - val_loss: 0.3523 - val_accuracy: 0.8482\n",
      "Epoch 227/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3322 - accuracy: 0.8590 - val_loss: 0.3521 - val_accuracy: 0.8482\n",
      "Epoch 228/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3320 - accuracy: 0.8593 - val_loss: 0.3519 - val_accuracy: 0.8482\n",
      "Epoch 229/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3318 - accuracy: 0.8593 - val_loss: 0.3517 - val_accuracy: 0.8482\n",
      "Epoch 230/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3316 - accuracy: 0.8593 - val_loss: 0.3514 - val_accuracy: 0.8482\n",
      "Epoch 231/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3313 - accuracy: 0.8602 - val_loss: 0.3512 - val_accuracy: 0.8482\n",
      "Epoch 232/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3311 - accuracy: 0.8602 - val_loss: 0.3510 - val_accuracy: 0.8482\n",
      "Epoch 233/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3309 - accuracy: 0.8605 - val_loss: 0.3508 - val_accuracy: 0.8482\n",
      "Epoch 234/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3307 - accuracy: 0.8608 - val_loss: 0.3506 - val_accuracy: 0.8482\n",
      "Epoch 235/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3305 - accuracy: 0.8611 - val_loss: 0.3504 - val_accuracy: 0.8482\n",
      "Epoch 236/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3303 - accuracy: 0.8614 - val_loss: 0.3502 - val_accuracy: 0.8482\n",
      "Epoch 237/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3301 - accuracy: 0.8614 - val_loss: 0.3500 - val_accuracy: 0.8482\n",
      "Epoch 238/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3299 - accuracy: 0.8614 - val_loss: 0.3498 - val_accuracy: 0.8482\n",
      "Epoch 239/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3297 - accuracy: 0.8614 - val_loss: 0.3496 - val_accuracy: 0.8482\n",
      "Epoch 240/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3294 - accuracy: 0.8617 - val_loss: 0.3494 - val_accuracy: 0.8482\n",
      "Epoch 241/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3292 - accuracy: 0.8617 - val_loss: 0.3492 - val_accuracy: 0.8482\n",
      "Epoch 242/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3290 - accuracy: 0.8620 - val_loss: 0.3490 - val_accuracy: 0.8482\n",
      "Epoch 243/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3288 - accuracy: 0.8620 - val_loss: 0.3488 - val_accuracy: 0.8482\n",
      "Epoch 244/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3286 - accuracy: 0.8620 - val_loss: 0.3486 - val_accuracy: 0.8482\n",
      "Epoch 245/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3284 - accuracy: 0.8623 - val_loss: 0.3484 - val_accuracy: 0.8482\n",
      "Epoch 246/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3282 - accuracy: 0.8620 - val_loss: 0.3482 - val_accuracy: 0.8471\n",
      "Epoch 247/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3280 - accuracy: 0.8608 - val_loss: 0.3480 - val_accuracy: 0.8471\n",
      "Epoch 248/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3278 - accuracy: 0.8614 - val_loss: 0.3478 - val_accuracy: 0.8471\n",
      "Epoch 249/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3276 - accuracy: 0.8620 - val_loss: 0.3476 - val_accuracy: 0.8471\n",
      "Epoch 250/250\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3275 - accuracy: 0.8620 - val_loss: 0.3475 - val_accuracy: 0.8471\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(units=13, activation='relu', input_dim=13))\n",
    "model.add(Dense(units=7, activation='relu', input_dim=7))\n",
    "model.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "history = model.compile(loss='binary_crossentropy', optimizer= keras.optimizers.Adagrad() , metrics='accuracy')\n",
    "history = model.fit(X_train_scaled, y_train, epochs = 250, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "f11ae1a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7803d81662f0>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'], label ='loss')\n",
    "plt.plot(history.history['val_loss'], label='val_loss')\n",
    "\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "aa150266",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7803784a9d50>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
    "\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "23db13ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 0s 1ms/step\n",
      "86.63 % accuracy\n"
     ]
    }
   ],
   "source": [
    "y_log = model.predict(X_test_scaled)\n",
    "y_pred = np.where(y_log > 0.5, 1, 0)\n",
    "result_balanced = accuracy_score(y_test, y_pred)*100\n",
    "print('%.2f' % result_balanced, \"% accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d340cc",
   "metadata": {},
   "source": [
    "## ML Algorithms Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "217478c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = []\n",
    "model = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "36d2ed6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc.append(result_unbalanced*100)\n",
    "model.append('Single-layer Perceptron')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "08875304",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report , confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "18b88e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['Churn']\n",
    "X = df.drop('Churn',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "c743fc16",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3749c128",
   "metadata": {},
   "source": [
    "## Logistic Regression (LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "2db46589",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialising Logistic regression model and generating a prediction\n",
    "logreg = LogisticRegression(random_state=42)\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "# Generating prediction\n",
    "predicted_values = logreg.predict(X_test)\n",
    "\n",
    "x = metrics.accuracy_score(y_test, predicted_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "20ccce9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression's Accuracy is:  0.846031746031746 %\n",
      " \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.98      0.91       521\n",
      "         1.0       0.69      0.20      0.31       109\n",
      "\n",
      "    accuracy                           0.85       630\n",
      "   macro avg       0.77      0.59      0.61       630\n",
      "weighted avg       0.83      0.85      0.81       630\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Logistic Regression's Accuracy is: \", x , \"%\")\n",
    "print(\" \")\n",
    "print(classification_report(y_test,predicted_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "846870ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA2YAAAN0CAYAAADfyztuAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAud0lEQVR4nO3dfbitdVkv+u/N4k1BVECUAIWMMrAtdQg1Tx58OYnVierKwl4Oe8dJO+lp165d2O7Uri46nt3L7nTcVJTuqHYanTLpTTR2ppaFIGSCIhgKBIKAb6CCa87f+WMOdIprzTUfeea612B+Ptc1rjnGM54xnt96/ljX+q77vn+zxhgBAACgz37dCwAAANjuBDMAAIBmghkAAEAzwQwAAKCZYAYAANBMMAMAAGi2f/cCAACAh5bnPeuQceddK93L2LQr3nnvJWOMMzrXIJgBAACzuvOulVx2yeO7l7FpO46+7sjuNWhlBAAAaKZiBgAAzGokWc1q9zKWiooZAABAM8EMAACgmWAGAADQzIwZAAAws5GVYcZsChUzAACAZoIZAABAM62MAADArNa2yx/dy1gqKmYAAADNBDMAAIBmghkAAEAzM2YAAMDsVmO7/ClUzAAAAPagqt5fVf9UVVdV1eWLY4dX1Rur6rrFz0evO/9lVXV9VV1bVc/b0/cLZgAAAJvzrDHGKWOMUxevz01y6RjjxCSXLl6nqk5KclaSk5OckeT8qtqx0RdrZQQAAGY1MrIytsV2+WcmOX3x/MIkb0ry44vjrxlj3Jvkhqq6PslpSd62uy9SMQMAANizkeQNVXVFVb1oceyxY4xbk2Tx86jF8WOS3LTuszcvju2WihkAALDdHXn/3NjCBWOMCx5wzjPGGLdU1VFJ3lhV79ng+2oXxzYsIQpmAADA7FY3ziH7mjvWzY3t0hjjlsXP26vqtVlrTbytqo4eY9xaVUcnuX1x+s1Jjlv38WOT3LLR92tlBAAA2EBVHVJVj7j/eZKvS/KuJBcnOXtx2tlJXrd4fnGSs6rqoKo6IcmJSS7b6BoqZgAAABt7bJLXVlWylqF+f4zx+qp6e5KLquqcJDcmeUGSjDGurqqLklyTZGeSl4wxVja6gGAGAACwgTHGPyd5yi6O35nkObv5zHlJztvsNQQzAABgViPJynLNmLUzYwYAANBMMAMAAGimlREAAJjdkm2X307FDAAAoJlgBgAA0EwwAwAAaGbGDAAAmNVIsjLMmE2hYgYAANBMMAMAAGimlREAAJjdavcCloyKGQAAQDPBDAAAoJlWRgAAYFYjIyuxK+MUKmYAAADNBDMAAIBmghkAAEAzM2YAAMC8RrJixGwSFTMAAIBmghkAAEAzrYwAAMCsRpLV7kUsGRUzAACAZoIZAABAM8EMAACgmRkzAABgZpWVVPciloqKGQAAQDPBDAAAoJlWRgAAYFYjyeroXsVyUTEDAABoJpgBAAA008oIAADMzq6M06iYAQAANBPMAAAAmglmAAAAzcyYAQAAsxoxYzaVihkAAEAzwQwAAKCZVkYAAGB2q0Mr4xQqZgAAAM0EMwAAgGaCGQAAQDMzZgAAwKxslz+dihkAAEAzwQwAAKCZVkYAAGBWI5UVNaBJ3C0AAIBmghkAAEAzrYwAAMDsVoddGadQMQMAAGgmmAEAADQTzAAAAJqZMQMAAGY1kqzEjNkUKmYAAADNBDMAAIBm+1Qr45GH7xjHH3dA9zIASPLedz68ewkALHwq9+S+ce8S9QZWVoYa0BT7VDA7/rgDctklx3UvA4Akz/uiU7qXAMDCP4xLu5fAFhNjAQAAmglmAAAAzfapVkYAAGD5jSSrakCTuFsAAADNBDMAAIBmWhkBAIDZrWSJdvffB6iYAQAANBPMAAAAmmllBAAAZjVGZWWoAU3hbgEAADQTzAAAAJoJZgAAAM3MmAEAALNbtV3+JCpmAAAAzQQzAACAZloZAQCAWY0kK2pAk7hbAAAAzQQzAACAZoIZAABAMzNmAADAzCorQw1oCncLAACgmWAGAADQTCsjAAAwq5FkVQ1oEncLAACgmWAGAADQTCsjAAAwu5VR3UtYKipmAAAAzQQzAACAZoIZAABAMzNmAADArEYqK2pAk7hbAAAAzQQzAACAZloZAQCA2a0ONaAp3C0AAIBmghkAAEAzwQwAAKCZGTMAAGBWI7Fd/kTuFgAAQDPBDAAAoJlWRgAAYFYjlZVR3ctYKipmAAAAzQQzAACAZloZAQCA2a2qAU3ibgEAADQTzAAAAJoJZgAAAM3MmAEAALMaI1kZakBTuFsAAADNBDMAAIBmWhkBAICZVVZT3YtYKipmAAAAzQQzAACAZoIZAABAMzNmAADArEZslz+VuwUAANBMMAMAAGimlREAAJjdihrQJO4WAABAM8EMAACgmVZGAABgViOV1VHdy1gqKmYAAADNBDMAAIBmghkAAEAzM2YAAMDsbJc/jbsFAADQTDADAABoppURAACY1UiyOtSApnC3AAAAmglmAAAAzQQzAACAZmbMAACAmVVWUt2LWCoqZgAAAM0EMwAAgGZaGQEAgFnZLn86dwsAAKCZYAYAANBMKyMAADA7uzJOo2IGAADQTDADAABoJpgBAAA0M2MGAADMaoyyXf5E7hYAAEAzwQwAAKCZVkYAAGB2K1oZJ3G3AAAAmglmAAAAzQQzAACAZmbMAACAWY0kq6nuZSwVFTMAAIBmghkAAEAzrYwAAMDMynb5E7lbAAAAzQQzAACAZloZAQCAWY0kq8OujFOomAEAADQTzAAAAJoJZgAAAM3MmAEAALNbUQOaxN0CAABoJpgBAAA008oIAADMaqRslz+RihkAAEAzwQwAAKCZYAYAANDMjBkAADC7VTWgSdwtAACAZoIZAABAM62MAADArMZIVmyXP4mKGQAAQDPBDAAAYA+qakdVXVlVf7Z4fXhVvbGqrlv8fPS6c19WVddX1bVV9bzNfL9gBgAAzG511NI8NunfJnn3utfnJrl0jHFikksXr1NVJyU5K8nJSc5Icn5V7djTlwtmAAAAG6iqY5N8Q5LfWnf4zCQXLp5fmOSb1x1/zRjj3jHGDUmuT3Lanq4hmAEAAGzsV5L8WJLVdcceO8a4NUkWP49aHD8myU3rzrt5cWxDghkAALDdHVlVl697vOj+N6rqG5PcPsa4YpPftaveyLGnD9kuHwAAmNVIZXUsVQ3ojjHGqbt57xlJvqmqvj7JwUkOq6rfS3JbVR09xri1qo5Ocvvi/JuTHLfu88cmuWVPC1iquwUAALA3jTFeNsY4doxxfNY29fjvY4zvTnJxkrMXp52d5HWL5xcnOauqDqqqE5KcmOSyPV1HxQwAAGC6lye5qKrOSXJjkhckyRjj6qq6KMk1SXYmeckYY2VPXyaYAQAAs1vZ5ajVchtjvCnJmxbP70zynN2cd16S86Z8t1ZGAACAZoIZAABAM62MAADArEaS1fHQa2XcSipmAAAAzQQzAACAZoIZAABAMzNmAADAzCqrQw1oCncLAACgmWAGAADQTCsjAAAwu9XYLn8KFTMAAIBmghkAAEAzwQwAAKCZGTMAAGBWYyQrw4zZFCpmAAAAzQQzAACAZloZAQCA2a0ONaAp3C0AAIBmghkAAEAzrYwAAMCsRiqrdmWcRMUMAACgmWAGAADQTDADAABoZsYMAACY3WrMmE2hYgYAANBMMAMAAGimlREAAJjVSGyXP5GKGQAAQDPBDAAAoJlgBgAA0MyMGQAAMLvVoQY0hbsFAADQTDADAABoppURAACY1yjb5U+kYgYAANBMMAMAAGimlREAAJjVSLIarYxTqJgBAAA0E8wAAACaCWYAAADNzJgBAACzs13+NCpmAAAAzQQzAACAZloZAQCAWY1oZZxKxQwAAKCZYAYAANBMMAMAAGhmxgwAAJidGbNpVMwAAACaCWYAAADNtDICAACzGimtjBOpmAEAADQTzAAAAJppZQQAAGa3Gq2MUwhmMNH/etpJedihK9lvv2TH/iOveP178+Y/fWR+95cel5uuOzi/+hfvzZc+5ZNJko/dtSM/96Lj896rHp7/+dvvykt//l+aVw/w0PXvfvnGPPW5H89H7tg/L372lyVJHvGonfmJX/9AHnvsfbnt5gNz3oufkLs/6p8/wL5nS1sZq+qMqrq2qq6vqnO38lqwN/2nP7w+v/ZX1+YVr39vkuT4J30qP/Vb789XPO2ezznvwINHzv73H8z3/dQtHcsE2Fbe8AeH5z981wmfc+zbX3p7rnzrofne//HLc+VbD813vPT2ptUBbGzLgllV7UjyX5I8P8lJSV5YVSdt1fWg0+NPvDfHfcm9n3f84Iev5slPvScHHjQaVgWwvbzrHw7Nxz/8udWwpz/vY/mriw5PkvzVRYfn6Wd8rGNpAHu0lbX805JcP8b45ySpqtckOTPJNVt4Tdh6NfITL3xiUsk3fM+d+frvvrN7RQDsxqOP/HTuuv2AJMldtx+QRx2xs3lFsE2M2C5/oq0MZsckuWnd65uTPPWBJ1XVi5K8KEkef4yeb/Z9//l11+WIx+3MR+7YP+ee9cQc9yWf+rwWRgAAmGIrZ8x2FZE/r59rjHHBGOPUMcapjzlixxYuB+ZxxOPW/rf1UUfuzDPO+Gjec+XDm1cEwO58+I4DcvhRn06SHH7Up/ORO/0nMLBv2spgdnOS49a9PjaJHRBYap/6xH75xN37feb5FX/ziBz/pE81rwqA3fn7NxyW5377XUmS5377XXnbJYc1rwi2h5G1VsZleewLtvK/jd6e5MSqOiHJvyQ5K8l3buH1YMt9+EP752fOWdvxa2Vn8qxv+Ui++lkfz9/+5SNz/k8ek4/euX/+z+/54jzx5E/m51/9z0nWtte/5+79svO+ytsueWR+/tXvyxO+9PM3CgHgwTn3/A/kXz397jzy8J35vcuvye/+0mPzB684Kv/h1z+QM866K7f/y9p2+QD7oi0LZmOMnVX10iSXJNmR5FVjjKu36nqwNxz9hPvy63917ecdf8bzP5pnPP+ju/zM71xmvxuAveHlP7Dr0HXudzxxL68EYLotbbQeY/xFkr/YymsAAAAsOxOwAADA7PaV2a1lsZWbfwAAALAJghkAAEAzrYwAAMCsRvadbeiXhYoZAABAM8EMAACgmVZGAABgdkMr4yQqZgAAAM0EMwAAgGaCGQAAQDMzZgAAwOxWY8ZsChUzAACAZoIZAABAM62MAADArMZIVm2XP4mKGQAAQDPBDAAAoJlgBgAA0MyMGQAAMLthxmwSFTMAAIBmghkAAEAzrYwAAMDMynb5E6mYAQAANBPMAAAAmmllBAAAZmdXxmlUzAAAAJoJZgAAAM0EMwAAgGZmzAAAgFmNxHb5E6mYAQAANBPMAAAAmmllBAAA5jWSMboXsVxUzAAAAJoJZgAAAM0EMwAAgGZmzAAAgNmtxnb5U6iYAQAANBPMAAAAmmllBAAAZjWSjKGVcQoVMwAAgGaCGQAAQDOtjAAAwMwqq1oZJ1ExAwAAaCaYAQAANBPMAAAAmpkxAwAAZjdG9wqWi4oZAABAM8EMAACgmVZGAABgdsN2+ZOomAEAADQTzAAAAJoJZgAAAM3MmAEAALMaw4zZVCpmAAAAzQQzAACAZloZAQCA2a1qZZxExQwAAKCZYAYAANBMKyMAADC7MbpXsFxUzAAAAJoJZgAAAM0EMwAAgGZmzAAAgNkN2+VPomIGAADQTDADAABoppURAACY1UhpZZxIxQwAAKCZYAYAANBMMAMAAGhmxgwAAJjd6F7AklExAwAAaCaYAQAANNPKCAAAzGvEdvkTqZgBAAA0E8wAAACaaWUEAADmZ1vGSVTMAAAAmglmAAAAzQQzAACAZmbMAACA2dkufxoVMwAAgGaCGQAAQDOtjAAAwOyG7fInUTEDAABoJpgBAAA0E8wAAACamTEDAABmNWK7/KlUzAAAAJoJZgAAAM20MgIAAPMaSbQyTqJiBgAA0EwwAwAAaKaVEQAAmN0Y3StYLipmAAAAzQQzAACAZoIZAABAMzNmAADA/MyYTaJiBgAA0EwwAwAAaKaVEQAAmFlljOpexFJRMQMAAGgmmAEAADQTzAAAADZQVQdX1WVV9Y9VdXVV/czi+OFV9caqum7x89HrPvOyqrq+qq6tquft6RqCGQAAML+xRI89uzfJs8cYT0lySpIzquppSc5NcukY48Qkly5ep6pOSnJWkpOTnJHk/KrasdEFBDMAAIANjDV3L14esHiMJGcmuXBx/MIk37x4fmaS14wx7h1j3JDk+iSnbXQNwQwAANjujqyqy9c9XvTAE6pqR1VdleT2JG8cY/xDkseOMW5NksXPoxanH5PkpnUfv3lxbLdslw8AAMxrZNm2y79jjHHqRieMMVaSnFJVj0ry2qp68gan7+oPv2HTpIoZAADAJo0xPpLkTVmbHbutqo5OksXP2xen3ZzkuHUfOzbJLRt9r2AGAACwgap6zKJSlqp6WJLnJnlPkouTnL047ewkr1s8vzjJWVV1UFWdkOTEJJdtdA2tjAAAwPw2t9vhsjg6yYWLnRX3S3LRGOPPquptSS6qqnOS3JjkBUkyxri6qi5Kck2SnUlesmiF3C3BDAAAYANjjHcm+cpdHL8zyXN285nzkpy32WtoZQQAAGgmmAEAADTTyggAAGyBpdouv52KGQAAQDPBDAAAoJlWRgAAYH4Pre3yt5yKGQAAQDPBDAAAoJlgBgAA0MyMGQAAMD8zZpOomAEAADQTzAAAAJppZQQAAOY1kozqXsVSUTEDAABoJpgBAAA008oIAADMbtiVcRIVMwAAgGaCGQAAQDPBDAAAoJkZMwAAYH5mzCZRMQMAAGgmmAEAADTTyggAAMxvVPcKloqKGQAAQDPBDAAAoJlgBgAA0MyMGQAAMLuyXf4kKmYAAADNBDMAAIBmWhkBAIB5jcWDTVMxAwAAaCaYAQAANNPKCAAAzKySUd2LWCoqZgAAAM0EMwAAgGaCGQAAQDMzZgAAwPxslz+JihkAAEAzwQwAAKCZVkYAAGB+Whkn2W0wq6r/NxvczjHGD27JigAAALaZjSpml++1VQAAAGxjuw1mY4wL17+uqkPGGPds/ZIAAAC2lz1u/lFVT6+qa5K8e/H6KVV1/pavDAAAWF5jiR77gM3syvgrSZ6X5M4kGWP8Y5JnbuGaAAAAtpVNbZc/xrjpAYdWtmAtAAAA29Jmtsu/qaq+JsmoqgOT/GAWbY0AAACfZyQZ1b2KpbKZitn3J3lJkmOS/EuSUxavAQAAmMEeK2ZjjDuSfNdeWAsAAMC2tJldGb+4qv60qj5UVbdX1euq6ov3xuIAAIDlVGN5HvuCzbQy/n6Si5IcneSLkvxhkldv5aIAAAC2k80Esxpj/O4YY+fi8XvZZ3b7BwAAWH67nTGrqsMXT/+6qs5N8pqsBbLvSPLne2FtAAAA28JGm39ckbUgdv8+ly9e995I8nNbtSgAAGDJ6bGbZLfBbIxxwt5cCAAAwHa1mV8wnap6cpKTkhx8/7Exxu9s1aIAAAC2kz0Gs6r66SSnZy2Y/UWS5yd5axLBDAAAYAab2ZXx25I8J8kHxxj/JslTkhy0pasCAADYRjYTzD45xlhNsrOqDktyexK/YBoAAGAmm5kxu7yqHpXkN7O2U+PdSS7bykUBAABsJ3sMZmOMH1g8/fWqen2Sw8YY79zaZQEAAMusbJc/yUa/YPqrNnpvjPGOrVkSAADA9rJRxeyXNnhvJHn2zGvJe68/PGd803fP/bUAfAH2O/j67iUAsFCfqu4lsMU2+gXTz9qbCwEAAB5ChjA5xWZ2ZQQAAGALCWYAAADNNrNdPgAAwOaNxYNN22PFrNZ8d1X91OL146vqtK1fGgAAwPawmVbG85M8PckLF68/nuS/bNmKAAAAtpnNtDI+dYzxVVV1ZZKMMT5cVQdu8boAAAC2jc0Es09X1Y4sukSr6jFJVrd0VQAAwHIzYzbJZloZfzXJa5McVVXnJXlrkp/f0lUBAABsI3usmI0x/ltVXZHkOUkqyTePMd695SsDAADYJvYYzKrq8Uk+keRP1x8bY9y4lQsDAACWV2llnGQzM2Z/nrUO0UpycJITklyb5OQtXBcAAMC2sZlWxq9Y/7qqvirJi7dsRQAAANvMZjb/+BxjjHck+eotWAsAAMC2tJkZs3+37uV+Sb4qyYe2bEUAAMDyM2M2yWZmzB6x7vnOrM2c/dHWLAcAAGD72TCYLX6x9KFjjH+/l9YDAACw7ew2mFXV/mOMnYvNPgAAADZPK+MkG1XMLsvaPNlVVXVxkj9Mcs/9b44x/niL1wYAALAtbGbG7PAkdyZ5dj77+8xGEsEMAABgBhsFs6MWOzK+K58NZPdTmAQAAHapxtqDzdsomO1Icmg+N5Ddz20GAACYyUbB7NYxxs/utZUAAABsU/tt8N6uKmUAAADMbKOK2XP22ioAAICHlqHOM8VuK2ZjjLv25kIAAAC2q41aGQEAANgLNvN7zAAAAKaxj/skKmYAAADNBDMAAIBmWhkBAIDZlVbGSVTMAAAAmglmAAAAzQQzAACAZmbMAACA+Zkxm0TFDAAAoJlgBgAA0EwrIwAAMK9hu/ypVMwAAACaCWYAAADNBDMAAIBmZswAAID5mTGbRMUMAACgmWAGAADQTCsjAAAwP62Mk6iYAQAANBPMAAAAmmllBAAAZldaGSdRMQMAAGgmmAEAADQTzAAAAJoJZgAAAM0EMwAAgGaCGQAAQDPb5QMAAPOzXf4kKmYAAADNBDMAAIBmghkAAEAzM2YAAMC8RlJmzCZRMQMAAGgmmAEAADTTyggAAMxPK+MkKmYAAADNBDMAAIBmWhkBAID5aWWcRMUMAACgmWAGAADQTDADAABoZsYMAACYVSUpM2aTqJgBAAA0E8wAAACaaWUEAADmp5VxEhUzAACAZoIZAABAM8EMAACgmRkzAABgXsN2+VOpmAEAADQTzAAAAJppZQQAAOanlXESFTMAAIBmghkAAEAzrYwAAMD8tDJOomIGAADQTDADAABoJpgBAAA0M2MGAADMrsyYTaJiBgAA0EwwAwAAaKaVEQAAmJ9WxklUzAAAAJoJZgAAAM0EMwAAgGZmzAAAgHmNmDGbSMUMAACgmWAGAADQTCsjAAAwu9LKOImKGQAAQDPBDAAAoJlWRgAAYH5aGSdRMQMAAGgmmAEAADQTzAAAADZQVcdV1V9X1bur6uqq+reL44dX1Rur6rrFz0ev+8zLqur6qrq2qp63p2sIZgAAwOxqLM9jE3Ym+ZExxpcneVqSl1TVSUnOTXLpGOPEJJcuXmfx3llJTk5yRpLzq2rHRhcQzAAAADYwxrh1jPGOxfOPJ3l3kmOSnJnkwsVpFyb55sXzM5O8Zoxx7xjjhiTXJzlto2sIZgAAAJtUVccn+cok/5DksWOMW5O18JbkqMVpxyS5ad3Hbl4c2y3b5QMAAPNbru3yj6yqy9e9vmCMccEDT6qqQ5P8UZIfGmN8rKp29327emPDOyKYAQAA290dY4xTNzqhqg7IWij7b2OMP14cvq2qjh5j3FpVRye5fXH85iTHrfv4sUlu2ej7tTICAABsoNZKY69M8u4xxi+ve+viJGcvnp+d5HXrjp9VVQdV1QlJTkxy2UbXUDEDAADY2DOSfE+Sf6qqqxbHfiLJy5NcVFXnJLkxyQuSZIxxdVVdlOSarO3o+JIxxspGFxDMAACAeY0s24zZhsYYb82u58aS5Dm7+cx5Sc7b7DW0MgIAADQTzAAAAJppZQQAAGZV2X3fH7umYgYAANBMMAMAAGimlREAAJjfQ2hXxr1BxQwAAKCZYAYAANBMMAMAAGhmxgwAAJhdmTGbRMUMAACgmWAGAADQTCsjAAAwP62Mk6iYAQAANBPMAAAAmglmAAAAzcyYAQAA8zNjNomKGQAAQDPBDAAAoJlWRgAAYF4jKa2Mk6iYAQAANBPMAAAAmmllBAAA5qeVcRIVMwAAgGaCGQAAQDPBDAAAoJkZMwAAYHa2y59GxQwAAKCZYAYAANBMKyMAADA/rYyTqJgBAAA0E8wAAACaCWYAAADNzJgBAACzs13+NCpmAAAAzQQzAACAZloZAQCAeY3YLn8iFTMAAIBmghkAAEAzrYwAAMD8tDJOomIGAADQTDADAABoJpgBAAA0M2MGAADMqpKUGbNJVMwAAACaCWYAAADNtDICAADz08o4iYoZAABAM8EMAACgmWAGAADQzIwZAAAwuxqGzKZQMQMAAGgmmAEAADTTyggAAMxrxHb5E6mYAQAANBPMAAAAmmllBAAAZldaGSdRMQMAAGgmmAEAADQTzAAAAJqZMQMAAOZnxmwSFTMAAIBmghkAAEAzrYwAAMDsbJc/jWAGD8K3fNO7c8bXvS9jJO//wKPyS//P0/OjP/R3OfaYjydJDj3kvtx9z4F5yQ99ffNKAR76jjz63vzoL74vj37MpzNWK3/5mqPyut9+XM4598Y89Tkfzs5PV279wMH55R/74tzzcf8EAvYtW/a3UlW9Ksk3Jrl9jPHkrboOdDni8E/kzP/l2rzoJd+Y++7bPz/xY2/J6V/7/vxfv/C1nznn+773itxzz4GNqwTYPlZ2Vn7z55+Q9119SB52yEp+9eJ35cq3HpYr33pY/usvHJfVlcr3/viN+Y4fuCWv+r8f371cgM+xlTNmv53kjC38fmi3Y7+RAw9cyX77reagg3bmzrsevu7dkWc+48a86c1PaFsfwHby4Q8dmPddfUiS5JP37MhN1x+cIx736bzjrY/K6kolSd5z5aE58nH3dS4TYJe2rGI2xnhzVR2/Vd8P3e686+H5//7ky/O7r/yT3HvfjrzjyqPzjquO/sz7Tz759nz4IwfnllsPa1wlwPZ01DH35oknfyLXXnXI5xz/uhd8KH/zZ0c0rQq2GTNmk7TvylhVL6qqy6vq8k/v/ET3cmDTDj3k3jz9qTfnX3/fmfmuf/2tOfjgnXn26Td85v3Tn/mBvOktx/ctEGCbOvjhK/nJ89+b3/i5J+QTd3/2/6DP+oF/ycrOyl+/TjAD9j3twWyMccEY49QxxqkH7P/wPX8A9hFfecoHc9tth+ajHzs4Kyv75W/fdly+/EkfSpLst99qnvH0m/Lmt2hjBNibduy/mp88/7r89cVH5u8uOfwzx5/7rR/Kac/+SP7TDz8xSfUtEGA3bEkEX6DbP3RInvRld+SgA3fm3vt25JSnfDDXXbf2v7BfecoHc9PNh+WOO/1nA8DeM/JDL78hN73vYXntKz/bWv4/PPMjecGLb8mPvfCk3PupHY3rg21k2C5/KsEMvkDXvvfIvOVvH59X/MpfZmWl8r5/fnT+8pIvSZKc/rUfsOkHwF528ql357nfekdueM/D8oo/+6ckyYW/eFy+/6fenwMOHDnvd96TJHnPVYfmFT95QudSAT5PjbE1UbaqXp3k9CRHJrktyU+PMV650WcOO+SLxtNOfvGWrAeAaepd13cvAYCFv//UX+Sjq3cuTR/uIUccN578DT/cvYxNu+x3f+SKMcapnWvYyl0ZX7hV3w0AAOzjtDJO0r75BwAAwHYnmAEAADQTzAAAAJrZlREAAJhVxXb5U6mYAQAANBPMAAAAmmllBAAA5rdFvy/5oUrFDAAAoJlgBgAA0EwwAwAAaGbGDAAAmJ3t8qdRMQMAAGgmmAEAADTTyggAAMxrLB5smooZAABAM8EMAACgmVZGAABgdrXavYLlomIGAADQTDADAABoJpgBAAA0M2MGAADMz3b5k6iYAQAANBPMAAAAmmllBAAAZldaGSdRMQMAAGgmmAEAADQTzAAAAJqZMQMAAOY1kgxDZlOomAEAADQTzAAAAJppZQQAAGZnu/xpVMwAAACaCWYAAADNtDICAADz08o4iYoZAABAM8EMAACgmWAGAADQzIwZAAAwq4rt8qdSMQMAAGgmmAEAADTTyggAAMxrjLUHm6ZiBgAA0EwwAwAAaCaYAQAANDNjBgAAzM52+dOomAEAADQTzAAAAJppZQQAAOanlXESFTMAAIBmghkAAEAzrYwAAMDs7Mo4jYoZAABAM8EMAACgmWAGAADQzIwZAAAwr5Fk1ZDZFCpmAAAAzQQzAACAZloZAQCA+elknETFDAAAoJlgBgAA0EwwAwAAaGbGDAAAmF2ZMZtExQwAAKCZYAYAANBMKyMAADC/oZdxChUzAACAZoIZAABAM62MAADA7OzKOI2KGQAAQDPBDAAAoJlgBgAA0MyMGQAAMK+xeLBpKmYAAADNBDMAAIBmWhkBAIBZVZIaehmnUDEDAABoJpgBAAA0E8wAAACamTEDAADmt9q9gOWiYgYAANBMMAMAAGimlREAAJid7fKnUTEDAABoJpgBAAA008oIAADMaywebJqKGQAAQDPBDAAAoJlgBgAA0MyMGQAAMLOR2C5/EhUzAACAZoIZAABAM8EMAACYXY3leezxz1L1qqq6varete7Y4VX1xqq6bvHz0evee1lVXV9V11bV8zZzvwQzAACAjf12kjMecOzcJJeOMU5McunidarqpCRnJTl58Znzq2rHni4gmAEAAGxgjPHmJHc94PCZSS5cPL8wyTevO/6aMca9Y4wbklyf5LQ9XUMwAwAAmO6xY4xbk2Tx86jF8WOS3LTuvJsXxzZku3wAAGB+y7Vd/pFVdfm61xeMMS74Ar+rdnFsjzdDMAMAALa7O8YYp078zG1VdfQY49aqOjrJ7YvjNyc5bt15xya5ZU9fppURAABguouTnL14fnaS1607flZVHVRVJyQ5Mclle/oyFTMAAGBeI6nV7kXMp6peneT0rLU83pzkp5O8PMlFVXVOkhuTvCBJxhhXV9VFSa5JsjPJS8YYK3u6hmAGAACwgTHGC3fz1nN2c/55Sc6bcg2tjAAAAM1UzAAAgPkt166M7VTMAAAAmglmAAAAzQQzAACAZmbMAACA+Rkxm0TFDAAAoJlgBgAA0EwrIwAAMLuyXf4kKmYAAADNBDMAAIBmghkAAEAzM2YAAMD8zJhNomIGAADQTDADAABoppURAACY10iy2r2I5aJiBgAA0EwwAwAAaKaVEQAAmFVlpOzKOImKGQAAQDPBDAAAoJlgBgAA0MyMGQAAMD8zZpOomAEAADQTzAAAAJppZQQAAOanlXESFTMAAIBmghkAAEAzrYwAAMC8RpLV7kUsFxUzAACAZoIZAABAM8EMAACgmRkzAABgdmW7/ElUzAAAAJoJZgAAAM20MgIAAPPTyjiJihkAAEAzwQwAAKCZYAYAANDMjBkAADCzYcZsIhUzAACAZoIZAABAM62MAADAvEa0Mk6kYgYAANBMMAMAAGimlREAAJjfavcClouKGQAAQDPBDAAAoJlgBgAA0MyMGQAAMLuyXf4kKmYAAADNBDMAAIBmWhkBAID5aWWcRMUMAACgmWAGAADQTDADAABoZsYMAACY10iyasZsChUzAACAZoIZAABAM62MAADAzIbt8idSMQMAAGgmmAEAADTTyggAAMxPK+MkKmYAAADNBDMAAIBmghkAAEAzM2YAAMD8zJhNomIGAADQTDADAABoppURAACY10iyqpVxChUzAACAZoIZAABAM8EMAACg2T41Y/bxT9x6xxvf/h8/0L0OeJCOTHJH9yIASOLvZB46ntC9gGlGMla7F7FU9qlgNsZ4TPca4MGqqsvHGKd2rwMAfycDy0MrIwAAQLN9qmIGAAA8RAzb5U+hYgbzu6B7AQB8hr+TgaUgmMHMxhj+EQCwj/B3MrAstDICAADzGklWtTJOoWIGAADQTDADAABoppURHqSqelKSM5Mck7XC/S1JLh5jvLt1YQAALA0VM3gQqurHk7wmSSW5LMnbF89fXVXndq4NgM+qqn/TvQbYdsZYnsc+QMUMHpxzkpw8xvj0+oNV9ctJrk7y8pZVAfBAP5Pkv3YvAmB3BDN4cFaTfFGSDzzg+NGL9wDYS6rqnbt7K8lj9+ZaAKYSzODB+aEkl1bVdUluWhx7fJIvSfLSrkUBbFOPTfK8JB9+wPFK8nd7fzmwze0jLYLLQjCDB2GM8fqq+tIkp2Vt849KcnOSt48xVloXB7D9/FmSQ8cYVz3wjap6015fDcAEghk8SGOM1SR/370OgO1ujHHOBu99595cC8BUdmUEAABopmIGAADMbN/Zhn5ZqJgB7COqaqWqrqqqd1XVH1bVwx/Ed/12VX3b4vlvVdVJG5x7elV9zRdwjfdX1ZGbPf6Ac+6eeK3/WFU/OnWNALAsBDOAfccnxxinjDGenOS+JN+//s2q2vGFfOkY438bY1yzwSmnJ5kczACA+QhmAPumtyT5kkU166+r6veT/FNV7aiqX6iqt1fVO6vqxUlSa15RVddU1Z8nOer+L6qqN1XVqYvnZ1TVO6rqH6vq0qo6PmsB8IcX1bqvrarHVNUfLa7x9qp6xuKzR1TVG6rqyqr6jaztQrqhqvqTqrqiqq6uqhc94L1fWqzl0qp6zOLYE6vq9YvPvKWqnjTL3QRg7xpJVleX57EPMGMGsI+pqv2TPD/J6xeHTkvy5DHGDYtw89ExxldX1UFJ/raq3pDkK5N8WZKvyNrvcromyase8L2PSfKbSZ65+K7Dxxh3VdWvJ7l7jPGLi/N+P8l/HmO8taoen+SSJF+e5KeTvHWM8bNV9Q1JPido7cb3Lq7xsCRvr6o/GmPcmeSQJO8YY/xIVf3U4rtfmuSCJN8/xriuqp6a5Pwkz/4CbiMALBXBDGDf8bCqumrx/C1JXpm1FsPLxhg3LI5/XZJ/df/8WJJHJjkxyTOTvHrx+/Nuqar/vovvf1qSN9//XWOMu3azjucmOanqMwWxw6rqEYtrfOvis39eVQ/8Jb678oNV9S2L58ct1npnktUkf7A4/ntJ/riqDl38ef9w3bUP2sQ1AGDpCWYA+45PjjFOWX9gEVDuWX8oyf8xxrjkAed9fdYaRzZSmzgnWWtzf/oY45O7WMumt9iqqtOzFvKePsb4xOIX/B68m9PH4rofeeA9AGBJ2ZVxEjNmAMvlkiT/e1UdkCRV9aVVdUiSNyc5azGDdnSSZ+3is29L8j9V1QmLzx6+OP7xJI9Yd94bstZWmMV5pyyevjnJdy2OPT/Jo/ew1kcm+fAilD0paxW7++2X5P6q33dmrUXyY0luqKoXLK5RVfWUPVwDAB4SBDOA5fJbWZsfe0dVvSvJb2St++G1Sa5L8k9Jfi3J3zzwg2OMD2VtLuyPq+of89lWwj9N8i33b/6R5AeTnLrYXOSafHZ3yJ9J8syqekfWWipv3MNaX59k/6p6Z5KfS/L36967J8nJVXVF1mbIfnZx/LuSnLNY39VJztzEPQGApVdDiREAAJjRIw84anzNEd+25xP3Ea+/7deuGGOc2rkGM2YAAMD8FIAm0coIAADQTDADAABoppURAACY2UhWtTJOoWIGAADQTDADAABoJpgBAAA0M2MGAADMayRjrHavYqmomAEAADQTzAAAAJppZQQAAOZnu/xJVMwAAACaCWYAAADNtDICAADzG1oZp1AxAwAAaCaYAQAANBPMAAAAmpkxAwAA5jVGsrravYqlomIGAADQTDADAABoppURAACYn+3yJ1ExAwAAaCaYAQAANBPMAAAAmpkxAwAAZjdslz+JihkAAEAzwQwAAKCZVkYAAGBmw3b5E6mYAQAANBPMAAAAmmllBAAA5jWSrGplnELFDAAAoJlgBgAA0EwwAwAAaGbGDAAAmN9Y7V7BUlExAwAAaCaYAQAANNPKCAAAzGokGbbLn0TFDAAAoJlgBgAA0EwwAwAAaGbGDAAAmNcYtsufSMUMAACgmWAGAADQTCsjAAAwO9vlT6NiBgAA0EwwAwAAaKaVEQAAmJ9dGSdRMQMAAGgmmAEAADQTzAAAAJrVGLaxBAAA5lNVr09yZPc6JrhjjHFG5wIEMwAAgGZaGQEAAJoJZgAAAM0EMwAAgGaCGQAAQDPBDAAAoNn/D/40RRGxkkE9AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1152x1152 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# list of the crop labels\n",
    "crop_list = data['Churn'].unique()\n",
    "\n",
    "# Confusion matrix for logistic regression model\n",
    "cm = confusion_matrix(y_test, predicted_values)\n",
    "cmp = ConfusionMatrixDisplay(cm, display_labels=crop_list)\n",
    "fig, ax = plt.subplots(figsize=(16,16))\n",
    "\n",
    "cmp.plot(ax=ax)\n",
    "\n",
    "plt.xticks(rotation = 90)\n",
    "print(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "4b0ac74a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation score:  [0.84444444 0.84761905 0.84603175 0.85555556 0.86031746]\n"
     ]
    }
   ],
   "source": [
    "# Cross validation score (Logistic Regression)\n",
    "score = cross_val_score(logreg, X, y, cv=5)\n",
    "print('Cross validation score: ',score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "55b1aa98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8507936507936508"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "e2ea6ac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy =  0.8555555555555555\n",
      "Testing accuracy =  0.846031746031746\n"
     ]
    }
   ],
   "source": [
    "#Print Train Accuracy\n",
    "lr_train_accuracy = metrics.accuracy_score(y_train, logreg.predict(X_train))\n",
    "print(\"Training accuracy = \",metrics.accuracy_score(y_train, logreg.predict(X_train)))\n",
    "#Print Test Accuracy\n",
    "lr_test_accuracy = metrics.accuracy_score(y_test, logreg.predict(X_test))\n",
    "print(\"Testing accuracy = \",metrics.accuracy_score(y_test, logreg.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abfc326d",
   "metadata": {},
   "source": [
    "## Optimizing Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "b5b12f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialising lists of hyperparameters to test for the optimal settings\n",
    "solvers = ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\n",
    "penalty = ['none','l1','l2']\n",
    "c_values = [100, 10, 1.0, 0.1, 0.01]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "117883d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/home/hduser/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/hduser/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/hduser/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/hduser/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hduser/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/hduser/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/hduser/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hduser/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hduser/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hduser/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hduser/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/hduser/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/hduser/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/hduser/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/hduser/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/hduser/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/hduser/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/hduser/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/hduser/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/hduser/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/hduser/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/hduser/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hduser/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/hduser/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hduser/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/hduser/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hduser/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hduser/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/hduser/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/hduser/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/hduser/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/hduser/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/hduser/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/hduser/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/hduser/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/hduser/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hduser/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/hduser/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hduser/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/hduser/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/hduser/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/hduser/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/hduser/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/hduser/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/hduser/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/hduser/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hduser/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/hduser/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hduser/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hduser/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/hduser/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hduser/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/hduser/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/hduser/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hduser/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/hduser/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/hduser/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hduser/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/hduser/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hduser/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/hduser/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/hduser/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/hduser/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/hduser/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/hduser/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/hduser/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/hduser/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/hduser/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/hduser/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/hduser/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/hduser/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/hduser/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/hduser/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/hduser/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hduser/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/hduser/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/hduser/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/hduser/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/hduser/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hduser/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hduser/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hduser/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hduser/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/hduser/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hduser/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/hduser/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hduser/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/hduser/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/hduser/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/hduser/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hduser/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hduser/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/hduser/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/hduser/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/hduser/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/hduser/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/hduser/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/hduser/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/hduser/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hduser/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Using GridSearchCV to test for hyperparameter setting\n",
    "grid = dict(solver=solvers,penalty=penalty,C=c_values)\n",
    "grid_search = GridSearchCV(estimator=logreg, param_grid=grid, n_jobs=-1, scoring='accuracy',error_score=0)\n",
    "grid_result = grid_search.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "26adc0a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.893968 using {'C': 0.1, 'penalty': 'l1', 'solver': 'liblinear'}\n"
     ]
    }
   ],
   "source": [
    "# Printing out the optimal hyperparameters\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "1e68ba65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88.09523809523809"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialise logreg model with optimised hyperparameters & fitting the data\n",
    "logreg = LogisticRegression(C=0.1, penalty='l1', solver='liblinear')\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# Generating prediction\n",
    "predicted_values = logreg.predict(X_test)\n",
    "\n",
    "# Storing the accuracy score to be used later in model comparison\n",
    "x = metrics.accuracy_score(y_test, predicted_values)*100\n",
    "acc.append(x)\n",
    "model.append('Logistic Regression')\n",
    "\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "bd3a37cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.98      0.93       521\n",
      "         1.0       0.81      0.40      0.54       109\n",
      "\n",
      "    accuracy                           0.88       630\n",
      "   macro avg       0.85      0.69      0.74       630\n",
      "weighted avg       0.87      0.88      0.86       630\n",
      "\n",
      "AxesSubplot(0.125,0.125;0.775x0.755)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(classification_report(y_test, predicted_values))\n",
    "print(sns.heatmap(confusion_matrix(y_test, predicted_values), annot=True, fmt='.4g',                 \n",
    "                 xticklabels=['Normal behaviour (0 class)','Otherwise (1 class)'],                \n",
    "                 yticklabels=['Normal behaviour (0 class)','Otherwise (1 class)'],                  \n",
    "                 cbar=False, cmap='Blues'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "a4e03875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy =  0.8964285714285715\n",
      "Testing accuracy =  0.8809523809523809\n"
     ]
    }
   ],
   "source": [
    "#Print Train Accuracy\n",
    "lr_train_accuracy = metrics.accuracy_score(y_train, logreg.predict(X_train))\n",
    "print(\"Training accuracy = \",metrics.accuracy_score(y_train, logreg.predict(X_train)))\n",
    "#Print Test Accuracy\n",
    "lr_test_accuracy = metrics.accuracy_score(y_test, logreg.predict(X_test))\n",
    "print(\"Testing accuracy = \",metrics.accuracy_score(y_test, logreg.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "3d494623",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation score:  [0.9047619  0.87777778 0.89365079 0.89365079 0.9       ]\n"
     ]
    }
   ],
   "source": [
    "# Performing Cross validation\n",
    "# Cross validation score (Logistic Regression)\n",
    "score = cross_val_score(logreg, X, y, cv=5)\n",
    "print('Cross validation score: ',score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "7c9e944b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.893968253968254"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mean accuracy score\n",
    "score.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c87c2d",
   "metadata": {},
   "source": [
    "## Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "9838bb16",
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM = SVC(gamma='auto')\n",
    "\n",
    "SVM.fit(X_train,y_train)\n",
    "\n",
    "predicted_values = SVM.predict(X_test)\n",
    "\n",
    "x = metrics.accuracy_score(y_test, predicted_values)*100\n",
    "acc.append(x)\n",
    "model.append('SVM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "dd84b0f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "SVM's Accuracy is:  0.8539682539682539\n",
      " \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.99      0.92       521\n",
      "         1.0       0.84      0.19      0.31       109\n",
      "\n",
      "    accuracy                           0.85       630\n",
      "   macro avg       0.85      0.59      0.62       630\n",
      "weighted avg       0.85      0.85      0.81       630\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\" \")\n",
    "print(\"SVM's Accuracy is: \", x)\n",
    "print(\" \")\n",
    "print(classification_report(y_test,predicted_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "f942bc08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation score:  [0.86507937 0.88253968 0.85079365 0.87619048 0.87460317]\n"
     ]
    }
   ],
   "source": [
    "# Cross validation score (SVM)\n",
    "score = cross_val_score(SVM, X, y,cv=5)\n",
    "print('Cross validation score: ',score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "cbbedb99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.86984126984127"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "5c0ddd22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy =  0.9857142857142858\n",
      "Testing accuracy =  0.8539682539682539\n"
     ]
    }
   ],
   "source": [
    "#Print Train Accuracy\n",
    "SVM_train_accuracy = metrics.accuracy_score(y_train, SVM.predict(X_train))\n",
    "print(\"Training accuracy = \",metrics.accuracy_score(y_train, SVM.predict(X_train)))\n",
    "#Print Test Accuracy\n",
    "SVM_test_accuracy = metrics.accuracy_score(y_test, SVM.predict(X_test))\n",
    "print(\"Testing accuracy = \",metrics.accuracy_score(y_test, SVM.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb73a64",
   "metadata": {},
   "source": [
    "## Random Forest Classifier (RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "03b42055",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57\n"
     ]
    }
   ],
   "source": [
    "# Using a similar approach to logistic regrestion, I will run multiple tests to find the optimal n_estimator value\n",
    "# Random_state= 0 is used to maintain continuity of results across multiple runs\n",
    "rf_range = range(1, 80)\n",
    "rf_scores = []\n",
    "rf_max = 0\n",
    "rf_max_score = 0\n",
    "\n",
    "for f in rf_range:\n",
    "    RF = RandomForestClassifier(n_estimators=f, random_state=0)\n",
    "    scores = cross_val_score(RF, X_train, y_train, scoring='accuracy')\n",
    "    rf_scores.append(scores.mean())\n",
    "    if scores.mean() > rf_max_score:\n",
    "        rf_max = f\n",
    "        rf_max_score = scores.mean()\n",
    "\n",
    "plt.plot(rf_range, rf_scores)\n",
    "plt.xlabel('Value of f for RF')\n",
    "plt.ylabel('Cross-Validated Accuracy')\n",
    "plt.show()\n",
    "\n",
    "print(rf_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "01c3ca47",
   "metadata": {},
   "outputs": [],
   "source": [
    "RF = RandomForestClassifier(n_estimators=57, random_state=0)\n",
    "RF.fit(X_train, y_train)\n",
    "\n",
    "predicted_values = RF.predict(X_test)\n",
    "\n",
    "x = metrics.accuracy_score(y_test, predicted_values)*100\n",
    "acc.append(x)\n",
    "model.append('Random Forest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "8b71a296",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.98      0.97       521\n",
      "         1.0       0.89      0.78      0.83       109\n",
      "\n",
      "    accuracy                           0.95       630\n",
      "   macro avg       0.92      0.88      0.90       630\n",
      "weighted avg       0.94      0.95      0.94       630\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Classification report and breakdown\n",
    "print(classification_report( y_test,predicted_values))\n",
    "\n",
    "y_pred = RF.predict(X_test)\n",
    "y_true = y_test\n",
    "\n",
    "cm_RF = confusion_matrix(y_true,y_pred)\n",
    "\n",
    "f, ax = plt.subplots(figsize=(10,8))\n",
    "sns.heatmap(cm_RF, annot=True, linewidth=0.5, fmt=\".0f\",cmap='viridis', ax = ax)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Actual vs. Predicted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "30518ceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy =  0.9920634920634921\n",
      "Testing accuracy =  0.946031746031746\n"
     ]
    }
   ],
   "source": [
    "# Storing the accuracy values for model results comparison later\n",
    "\n",
    "#Print Train Accuracy\n",
    "rf_train_accuracy = metrics.accuracy_score(y_train, RF.predict(X_train))\n",
    "print(\"Training accuracy = \",metrics.accuracy_score(y_train, RF.predict(X_train)))\n",
    "\n",
    "#Print Test Accuracy\n",
    "rf_test_accuracy = metrics.accuracy_score(y_test, RF.predict(X_test))\n",
    "print(\"Testing accuracy = \",metrics.accuracy_score(y_test, RF.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "93c2e546",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation score:  [0.95079365 0.96031746 0.94444444 0.95873016 0.95396825]\n"
     ]
    }
   ],
   "source": [
    "# Cross validation on dataset\n",
    "score = cross_val_score(RF, X, y, cv=5)\n",
    "print('Cross validation score: ',score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "04427481",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9536507936507936"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mean score\n",
    "score.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "934f377b",
   "metadata": {},
   "source": [
    "## AdaBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "abedd50f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZUAAAEWCAYAAACufwpNAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAABU7UlEQVR4nO2deXxdZZn4v0/2fU+atmnalC5pQWhLKSAFpagsIigzjuACFFCZwRnUWQT9zbj9nHF+Do6jKIhSNgXEUUdQxg2k7JTudEm6pU3SNluz36w3eX5/nHNu7r25SW5Kbpb2+X4+95N73ve85zwnTe9zn/fZRFUxDMMwjIkgbqoFMAzDME4dTKkYhmEYE4YpFcMwDGPCMKViGIZhTBimVAzDMIwJw5SKYRiGMWGYUjEMwzAmDFMqhjEBiMhaEXlVRNpEpFlEXhGR84Lm00WkU0SejbD2sIj0iUhB2Ph2EVERWeAeP+weXxN23nfc8Zvd45tFZMC9X/BrTiye3TCCMaViGG8TEckCfgN8D8gD5gJfBXqDTvtL9/h9IjI7wmWqgBuCrvkOIDXCefuAm4LOSwA+DBwMO+81Vc0Iex0b98MZxjgxpWIYb58lAKr6hKoOqGq3qv5BVXcGnXMTcD+wE/hYhGs8BtwYdv6jEc57BrhIRHLd4yvca9a9zWcwjAnBlIphvH32AQMi8oiIXBn0gQ+AiJQC7wZ+6r5uHH4JXgeyRGSZiMQDHwF+EuG8HuBp4Hr3+EYiKx/DmBJMqRjG20RV24G1gAI/AhpF5GkRmeWeciOwU1X3AE8AZ4rIygiX8qyV9wIVwNERbvkocKOIZAPvAv4nwjkXiEhr0Ct8e8wwYoIpFcOYAFR1r6rerKolwFnAHOA77vSNOBYKrl9jI0F+kSAeAz4K3Mwo1oeqvgwUAv8H+I2qdkc47XVVzQl6nXFSD2YY48SUimFMMKpaATwMnCUi7wQWA3eLSJ2I1AHnAze4TvbgdUdwHPZXAb8c4zY/Af4e2/oyphmmVAzjbSIi5SLy9yJS4h7Pw4nkeh3HIvkjsBxY4b7OAtKAKyNc7lZgnar6xrjtd3G2yV6cgEcwjAkjYexTDMMYgw4c6+PzIpIDtOKEGP8jcAS4UVVDorNE5DEchfNM8LiqRuX7UNVm4LlRTrlQRDrDxi5V1Tejub5hnCxiTboMwzCMicK2vwzDMIwJw5SKYRiGMWGYUjEMwzAmDFMqhmEYxoRxWkd/FRQU6IIFC6ZaDMMwjBnFli1bmlS1MNLcaa1UFixYwObNm6daDMMwjBmFiBwZac62vwzDMIwJw5SKYRiGMWGYUjEMwzAmDFMqhmEYxoQRU6UiIleISKWIHBCRuyLM54rIr0Rkp4hsEpGzguY2iEiDiOwKW5MnIn8Ukf3uz9ygubvde1WKyOWxfDbDMAxjODFTKm73uu/jVGJdjlPqe3nYaV8Etqvq2Tg9J/4raO5hnFap4dwFPKeqi3EK6t3l3m85Tje8M911P3BlMAzDMCaJWFoqa4ADqnpIVfuAJ4Frw85Zjltp1e1BscDrlqeqLwLNEa57LfCI+/4R4INB40+qaq+qVgEHXBkMwzCMSSKWSmUuUBN0XOuOBbMDuA5ARNYA84GSMa47S1WPA7g/i8ZxP0TkUyKyWUQ2NzY2RvkohmEYM5ctR5p59WDTpNwrlkpFIoyF19n/JpArItuBvwW2Af4Y3g9VfUBVV6vq6sLCiAmhhmEYpxT/97d7uWnDJl45EHvFEkulUgvMCzouAY4Fn6Cq7aq6XlVX4PhUCnHaqY5GvYjMBnB/NkR7P8MwjNORY63d9A8on35sC3uOtcf0XrFUKm8Ci0WkTESScJzoTwefICI57hzAbcCLqjrWEz+N0zEP9+evg8avF5FkESnD6Qu+aQKewzAMY8bSPzBIQ0cvHz63hIzkBNY/vImjrd0xu1/MlIqq+oHPAL8H9gJPqepuEbldRG53T1sG7BaRCpwosTu99SLyBPAasFREakXkVnfqm8B7RWQ/To/ub7r32w08BewBfgfcoaoDsXo+wzCM6cLgoNI/MBhxrqGjF1VYNT+Xh285j66+AW7asInWrr6YyHJatxNevXq1WkFJwzBmOj944QA/e7OGjf946bC5LUea+Yv7XuOh9edx6dIiXjt4gps2bOLixQU8ePN5J3U/EdmiqqsjzZ3WVYoNwzBOBV4/1MyRE120dfWTnZYYMne8rQeAOdmpAFx4Rj7fvWElCwrSYiKLKRXDMIwZTsVxxxVd09JFdlp2yNzxVkepFGenBMauOKs4ZrJY7S/DMIwZTIuvj4aOXgBqW7qGzR9v6yEtKZ6slMmxIUypGIZhzGAq6joC72tbhkd1HW/rZnZ2CiKRUvkmHlMqhmEYM5iKOmfrKyFOqGmObKnMdv0pk4EpFcMwjBlMZV0HuWmJLCrKiGip1LX1MDvInxJrzFFvGIYxg9lb10F5cRYZKQkcOeELmfMPDNLQMblKxSwVwzCMGcrgoLKvroOlxZnMy02jtqWb4NzDho5eBhVm59j2l2EYhjEG1c1ddPcPsGx2JiW5qXT1DdDsG8qUP97mbIcVm6ViGIZhjIUX+bW0OIt5eU4yY7BfxUt8tO0vwzAMY0wq6toRgSWzMijJdba4aoJyVeoCSsW2vwzDMIwxqKzrYH5eGmlJCQGlEmypHGud3MRHMKViGIYx5dS19fC+/9zIliOROqiPTIUb+QWQmZJITlpiSK5KXfvkJj6CKRXDMIwp56FXq9hX38l3nzsQ9ZruvgEOn/CxtDgzMOZFgHkca53cxEcwpWIYhjGl+Hr9PP5GNWlJ8Wzc18j++o6xFwH76jtQhWWzh5RKSW7qMJ/KZEZ+gSkVwzCMKeW/t9TS0ePnezesJDkhjg2vjNVR3aEyKPLLY15eGkfdXBUv8XGOKRXDMIzY09M/wMOvVI3YMXEyGBhUNrxSxcrSHC5bNou/OLeEX2w9yonO3jHX7q1rJzUxntK8ob4oJbmp9PoHaezoDSQ+Ftv2l2EYRux5obKRrzyzhz9XNEyZDH/aW8+RE13ctnYhALdcVEaff5CfvF495trKug6WzMogPm7ICT8v11EwNS3dQzkqOWapGIZhxBwvSmprdeuUyfDgS1XMzUnl8jNnAbCoKINLlxby2OuH6ekfGHGdqoZEfnkMhRV3BbLpJzPxEWKsVETkChGpFJEDInJXhPlcEfmViOwUkU0ictZYa0XkZyKy3X0dFpHt7vgCEekOmrs/ls9mGMbMxmtotbW6ZUruv7O2lU2Hm1l/0QIS4oc+im+7eCFNnX08vePYiGsbO3tp9vWFRH4BlOQOZdVPReIjxLBKsYjEA98H3gvUAm+KyNOquifotC8C21X1QyJS7p5/2WhrVfUjQfe4B2gLut5BVV0Rq2cyDOPUocYNvd1Z24p/YDDkg30yePDlKjKSE/jIefNCxt95Rj7lxZk8+FIVHz63JGKOieekL58dqlRSk+IpyEiiprmL9OSESU98hNhaKmuAA6p6SFX7gCeBa8POWQ48B6CqFcACEZkVzVpxftN/BTwRw2cwDOMUpbali6SEOHr6B0O6J04GLb4+frvzOB85bx6ZKYkhcyLCrWvLqKzvGNGK2nPMacwVvv0FjrVS29LN8bZuiic58RFiq1TmAjVBx7XuWDA7gOsARGQNMB8oiXLtxUC9qu4PGisTkW0islFELo4klIh8SkQ2i8jmxsbG8T6TYRinAKpKTXM365YWAZO/BfbCvgb8g8q1K+ZEnF9X7sj15uHIcm2vaWVeXip56UnD5rxcleNtPcyZ5K0viK1SiaQeNez4m0Cu6xf5W2Ab4I9y7Q2EWinHgVJVXQl8HnhcRIapcVV9QFVXq+rqwsLCqB7EMIxTi2ZfH939A6wpy6MoM5mtRyZXqTy3t4HCzGTOmpMdcT4/I5kF+WkR5VJVtla3sKo0N+LaeXlpHGvt5mhL96QnPkJsOz/WAsGbhSVAiOdJVduB9RDYzqpyX2mjrRWRBBwL59yga/UCve77LSJyEFgCbJ6wJzIM45TA86fMy0tjZWnOpEaA9Q8MsnFfI1eeVUxc3MhbU6tKc3lxfxOqGrKFdayth/r23hGVSkluKv0DSkNH76QnPkJsLZU3gcUiUiYiScD1wNPBJ4hIjjsHcBvwoqtoxlr7HqBCVWuDrlXoOvgRkYXAYuBQjJ7NMIwZjBf5NS8vlVWluVQ3d9EURcJhMI+/Uc19Lxwccf7bf6jk19uPDhvfcqSFjh4/68pnjXr9laU5NHX2Dus771kvIyuVoWTIyU58hBhaKqrqF5HPAL8H4oENqrpbRG535+8HlgGPisgAsAe4dbS1QZe/nuEO+kuAr4mIHxgAblfV8ZX8NAzjtKCm2fmgLslNY9V858N5W3Ur710++ge9x1Oba/jir95CBK56RzHz89ND5ivrOvju8wcoyEjmirOKSU6ID8w9X9FAUnwcaxcXjHqPla7S2FrdEmjA5R2nJMYNi/zymJc7pEgmO/ERYpynoqrPquoSVT1DVb/hjt3vKhRU9TVVXayq5ap6naq2jLY2aO5m7xpBY79Q1TNV9RxVXaWqz8Ty2QzDmLnUtnSRm5ZIRnIC75ibTUKcRO2s/3NlA3f/8i3WLMgjIU546JXDw87Z8HIVItDU2cvT20PzTZ7bW8/5C/PISB79O315cSZpSfFsC9ua21rdytlzc0gcIQR6TlA/+slOfATLqDcM4zSkpqU7sE2UkhjPmXOyonLW76xt5Y6fbqW8OJMN68/jA+fM4anNNbR19wfOaers5Vfbj3L9eaVOvsnLVag6cUaHm3wcbPRxmRvdNRoJ8XGcXZIdoux6+gfYc6yNlfNzRlyXkhjPrKxkAGZnnVrRX4ZhGNOS2pYu5uUNfeCuLM1lZ20b/lGKS1af6OKWh98kNy2Jh24+j4zkBG5dW0ZX3wBPbhqq1fWT14/Q5x/k1rVl3LK2jIq6Dl49eAJwtr6AMf0pHqtKc9lzrD1QsmXX0Tb6B3REf4pHSW6ak/iYOrmJj2BKxTCM04zBQaU2yFIBWDU/l+7+gVGTIL/2m930+gd55JY1FGU520pnzsnmwoX5PPzqYfoHBunpH+Cx146wrryIRUUZXLtiDgUZyfz4JSdm6M+VDSwqyqA0P23E+wSzqjQX/6Cys9YpHOJZLWMplbNLslk+O2vSEx/BlIphGKcZTZ299PkHQxzaK+flACMnQR5q7ORPextYf1EZi4oyQuZuu7iM4209PPvWcZ7efowTvj5uW1sGQHJCPJ+4YD5/rmxke00rrx86EdXWV0Cu0lC5tlU7SY+FmcmjrvvSVct4/JMXRH2ficSUimEYpxVeZ8RgS6Uk1/mgDneKezz0ymGS4uP4xAXzh81durSIhQXp/PilKn788iGWzc7iwjPyA/Mfv6CUpIQ4/u6JbfQPaCBbPhq8JMht1S1jJj0GkxAfR1LC1Hy8j3lXEfkPETlzMoQxDMOINV44cbBPRURYVZoT0VJp7erj51tq+ODKOREthLg4Yf3aMt462sa++k5uXVsWsu2Un5HMX6yaS3VzF1kpCZw7f2ylEMzK0ly2VrcGkh49q2q6Eo0qqwAeEJE3ROR2EYlcV8AwjFOSmx/aNGKSX1NnL5fd8wKvHmyKOL+vvoN3f+vPgWTD6YAny9ycUL/GqtJcjpzoYtfRtpDxn75RTU//ILe4W1qR+ItVc8lJS6QwM5kPnDN72PwtFzlrL1lSOO5qyKtKc2js6OUZtxT+qnEqpclmzKdT1R+r6kXAjcACYKeIPC4il8ZaOMMwppae/gE27mvkBy8coLPXP2z+J68f4WCjj9fc6KZw3jh0gsMnuvjdrrpYixo1Nc3dFGQkk5oUHzL+oVVzmZOdwvqH3ww08OrzD/Loa4e5eHFBxIrAHmlJCfzgo6u494aVIYmOHotnZfLdG1byD+9bOm55vSTIh185TEpiHMtmjyzHdCAqlemWPyl3X0041YU/LyJPxlA2wzCmmCMnulCFjh4/P99cEzLnRToBHGryRVzvjT+3d+pa9oZT29oV6JAYTFFmCg/fsobe/gFufmgTrV19/PatY9S393LrKFaKxzsXFXD+wvwR5685Zw4LCtJHnB8JLwmyrr1n1KTH6UI0PpVvA5XAVcC/quq5qvrvqvoBYGWsBTQMY+qoauoEoCAjiQ2vVDEwOFQs/Nfbj3LC10dBRhJVjZGVSpWrVN483BySIDiV1DR3h5Q9CWbJrEweuHE1Nc3d3PrIZh54sYrFRRm8a8nUVTT3kiCBUZMepwvRqLxdwNmq+mlV3RQ2tyYGMhmGMYm8cegEL1RGtiQ8S+OfriinprmbP+6pB5zy6w++XEV5cSYfOGcOVU2+QNZ4MFVNPubmpOIfVF7aP/7+Ra8ebBp16+x/th1l2whhwIODygMvHuRY61BBxoFB5Vhrd0RLxeOChfl8+yPnsLW6hb3H27klzPE+FXgRX9FEfk010SiVFiDQmsytLPxBAFVtG2mRYRgzg3v+sI8vP7074lxVo4/CzGSuWzmXktxUHnzZSeJ7aX8T++o7ue3ihSwsSKe7f4D69tAqv33+QWqau/jgyjnkpCXy/Di3wPoHBvn8z3bwuZ9tp7Wrb9h8bUsXn39qO1/4xc6ICu35igb+9dkKvvX7ysBYXXsP/kFlXu7oyYdXnz2Hr197FhcuzOdDK8P7A04+V541m3fMzeaCspG316YL0SiVLwcrD1VtBb4cM4kMw5hUalq6qG7uwhfBEV/V5KOsIJ2E+DjWX1TGm4db2FHTyo9frgpEOpUVOMmAh9ytMo/q5i4GFRYVZXDp0iJe2NcYsn02Fs++dZy69h66+wd4PKgMiscjrx5mUGFffScv7R8effbgy1UAPLPjGHVtPQDUNns5KmPXxPr4BfN54lMXkJI43PE+2byjJJtn/nYt2WmJY588xUSjVCKdM/kFZQzDmHD6/IPUtfeg6oT/hnP4hI+FrnP5r1aXkJGcwFee2c2L+xq56cL5JCfEU1bozFeFOeu947KCDC4tL6LZ18f2mtao5FJVfvTSIRYWprN2UQGPvHqYPv9QXa6Onn6e3FTDFWcWU5iZzI9dBeKx62gbrx06wccvKGVAlUdfOwwMNeeKRqkYJ0c0SmWziHxbRM4QkYUi8p/AllgLZhhG7DnW2o23c1QZVveqrbufps4+ylylkpmSyPXnzWNbdSspiXF89Hwnu3x2VgrJCXEcDlMq3nFZfjrvWlxIfJzwfEV9yDmDg0qLb/jW1qaqZnYdbefWtWXcdnEZ9e29/PatoRLyT22upaPXz99cegY3XTifF/c1hijFDS9XkZ4Uzz9eXs7ly4t5fFM1XX3+oRwVUyoxIxql8rdAH/Az4OdAD3BHLIUyDGNyCO4qGF5MMaAUgsJgb75oAQlxwl+sKiEv3WnaGhcnlBWkD7NUDjX5yEtPIjstkey0RFbPzw0JLR4YVP76p1u44N+eY1NVaD+9H79cRW5aItetLOFdSwpZVJQRKCE/MKg89EoV5y3I5eySHD56/nxSEuPY4For9e09PL3jGB9ePY/s1ERuu7iM1q5+frH1KDXN3czKSo6YS2JMDNEkP/pU9S5VXe2GE9+tqpHjBw3DmFF4dbBmZSVTUdceMucpiYWFQ0qlJDeN3/zdWr70/mUh55YVpA/LValq6gxRSJctK6KiroOjrd2oKl95eje/311PenICn3x0M/tdS+Nwk48/7a3nY+fPJzUpHhHh1rVl7DrazhtVzfxhdx21Ld3cunYhAHnpSVy3qoRfbjtKU2cvj752mAHVQBb7ufNzOackmw0vV1HT3DWmk954e0STp1IoIt8SkWdF5HnvNRnCGYYRW2pbukiIE961pJCKuo6QKKpDTT7ihGE5HeXFWaQlhbpVywrSqT7RFdKPxHPye3g9RJ6vaOC+jQd57PUjfPqShfz6jotISojj5ofepL69h4deqSIhTrjxwqHijR9aOZe89CQefLmKH79cRWleWkjr31suKqPPP8iPXjrET9+o5n3LZwXKy4sIt168kKomH28eaTZ/SoyJZvvrpzj1v8qArwKHgTdjKJNhGJNETXM3s3NSOHNONq1d/TR0DIUFVzX5KMlNi2qrqKwgHb/bpwTA1+unvr03RKmcUZjO/Pw0fvDnA/y/31Vy7Yo5fOGKcublpfHQzefR2tXHTRs28dTmWq45Z26gZwk43Qw/fn4pf9xTz5YjLay/aAHxcUO5I4uKMlhXXsQPNx6itauf2y5eGCLflWcVMyc7BdXhStKYWKJRKvmq+iDQr6obVfUWIKpC/SJyhYhUisgBEbkrwnyuiPxKRHaKyCYROWustSLyFRE5KiLb3ddVQXN3u+dXisjl0choGKcztS3OdtDS4kwA9h4f2gIL374ajYVhEWCBrbOg9SLCuvIijrf18M4z8vnWX55DnKsYzpqbzX0fP5cDDZ109w9ELIvy8QvnkxQfR2ZKAh9ePW/YvNfD5JySbFaHFV1MjI/j5osWABb5FWuiCQ32aiscF5H3A8eAkrEWufXCvg+8F6gF3hSRp1V1T9BpXwS2q+qHRKTcPf+yKNb+p6r+R9j9lgPXA2cCc4A/icgSVR2I4hkN47SkpqWbS5cWUu4qlcq6Dt69tAhVparRx+r5eVFdZ0G+ozwONfm4lKBw4sJQpeT5OT733iXD+n1csqSQ+z5+LvsbOlg+Z3jRxKLMFP75A8vJSI4nI3n4R9eFZ+Tz6Xct5D3LZkXMgP/o+fM5cqKLS5dG38/EGD/RKJX/65a7/3vge0AW8Lko1q0BDqjqIQC3+OS1QLBSWQ78G4CqVojIAhGZBSyMYm041wJPqmovUCUiB1wZXotCVsM47ejpH6Cxo5d5uWnkpCVRnJUSiABr7OjF1zcQtaWSl55EVkpCoFaYp1Q8ZeMxLy+NL39g5PZM710+K8RXEk6kJlkeIsLdVy4bcT4jOYFvfOgdI84bE8Oo21+uxbBYVdtUdZeqXupGgD0dxbXnAsFlTWvdsWB2ANe591oDzMexgsZa+xl3y2yDiHh2bjT3Q0Q+JSKbRWRzY+P4axEZxqmC5/8ocZtVlc/ODCiVqgjhxKMhIpQVZoRsf83JTpkW2ejG5DKqUnG3jq45yWtHqsAWXqPhm0CuiGzHyYfZBvjHWHsfcAawAjgO3DOO+6GqD7jh0asLC6eu8qhhTBYtvj62HBledNFLBPRCbJcWZ3KgoYP+gcFxKxVw/CdeteJDTb5hW1/G6UE0jvpXReReEblYRFZ5ryjW1QLB3rQSHH9MAFVtV9X1qroCpwlYIVA12lpVrVfVAVUdBH7EUKXkMe9nGKcjD716mI/88LVhTbaGSpY4SmVZcRb9A0pVk4+qJh9JCXHMyYneqV1WkM6xth56+geoaozeyW+cWkTjU3mn+/NrQWMKrBtj3ZvAYhEpA47iONE/GnyCiOQAXaraB9wGvKiq7SIy4loRma2qx91LfAinND/A08Djbv+XOcBiILxUv2Gcdpzo7MU/qOyoaeWiRQWB8dqWLpLi4yhy+64HR4AdavKxID8tJGx3LDwlsrW6hfYef6DQpHF6MaZSUdWTahusqn4R+QzweyAe2KCqu0Xkdnf+fmAZ8KiIDOA44W8dba176f8nIitwFNth4NPumt0i8pR7HT9wh0V+GQa09zgWyrbqllCl0tzN3NzUQFjvGYUZJMQJlXUdVDX5OGOc21eeUvFK3C80S+W0ZEylIiL/EmlcVb8WaTzsnGeBZ8PG7g96/xqORRHVWnf8E6Pc7xvAN8aSyzBOJ7yOi1urW0PGa1tC2+omJcRxRmEGu4+1c+SEj/csGzkKKxIBpVLREHJsnF5E41PxBb0GgCuBBTGUyTCMCaTdVSrbqltCyrDUtHQH/Cke5bMzef3QCfoHdNyWRnpyArOykjnU5CMhTizJ8DQlmu2ve4KPReQ/cPwXhmHMANp7+okTaOnqp6rJx8LCDHy9fpp9fczLC/3gX1qcya+3O/EtC07C0liQn059ey+l+WkkxEfzndU41TiZf/U0nOREwzBmAO3d/kBvc28LrDYs8svDy6yHk9u+8sq1lOXb1tfpSjRVit9yEw13ishuoBL4r9iLZhjG20VVae/u59z5uWQmJ7C12slXGcpRCbVUyoud8iiZyQkUZCSN+36eIjJ/yulLNCHFVwe99wP1qjq8mbVhGNOOXv8gfQODZKclsqI0h61uEmRNoFd7qKUyOzuFzJQEygrSI9bPGgsvjNgSH09fotn+mg00q+oRVT0KpIjI+TGWyzCMCcBz0menJrKyNJd99R109vqpbekmJTFumDUiInx0TSnXnDPnpO537vxcVs/PZW1Q6LJxehGNpXIfEJxB3xVhzDCMaUh7j6NUslISmZuTyqDCzppWalq6KMlNi2iN3H3VyEUZxyIvPYn//ut3jn2iccoSjaUiGhSH6JZHiUYZGYYxxXg5Klmpiayc5znrW6ht6R7mTzGMiSAapXJIRP5ORBLd153AoVgLZhjG26e923F/ZqUkkJ2WyKKiDLZWt1LT3DXMn2IYE0E0SuV2nPpfR3GKNp4PfCqWQhmGMTF421/ZqYkArJyXwxuHTtDe4x+Wo2IYE0E0yY8NOAUdDcOYYbQHbX8BrJqfy8+31ALDI78MYyKIJk/lEbeasHecKyIbYiqVYRgTgudTyUxxvj96SZAw1EfFMCaSaLa/zlbVVu9AVVuAlTGTyDCMCaO9x09KYhzJCU4HxsVFGWS6/d2tNpcRC6JRKnFBLXsRkTws+sswZgTt3f1kpSQGjuPihBWlOWQkJ5CTljjKSsM4OaJRDvfgdH/8b/f4w8C/xk4kwzAmivae/oCT3uNv3r2IA42dJ5UxbxhjEY2j/lER2YzT6VGA61R1T8wlMwzjbdPW3R9w0ntceEY+F56RP0USGac6UVUpVtU9qnovTtOs60Rk11hrDMOYetq7/WSl2G61MXlEE/01W0Q+KyKbgN047X1viLlkhmG8bdp7hlsqhhFLRlQqIvJJEXke2AgUALcBx1X1q6r6VjQXF5ErRKRSRA6IyF0R5nNF5FduWf1NInLWWGtF5FsiUuGu+ZUX7iwiC0SkW0S2u6/7w+9nGKcb7d3DfSqGEUtGs1S+j2OVfFRV/4+q7gR0lPNDEJF49xpXAsuBG0RkedhpXwS2q+rZwI24fVrGWPtH4Cx3zT7g7qDrHVTVFe7r9mhlNYxTEVWlvccfEv1lGLFmNKUyB3gS+LZrMXwdGM9f5xrggKoeUtU+91rXhp2zHHgOQFUrgAUiMmu0tar6h6B+Lq8DJeOQyTBOG3x9AwwMKlmp5lMxJo8RlYqqNqnqfap6CXAZ0AY0iMheEYkmpHguUBN0XOuOBbMDuA5ARNYA83GURDRrAW4B/jfouExEtonIRhG5OJJQIvIpEdksIpsbGxujeAzDmJkESrSYpWJMItFGf9Wq6n+o6rnAB4HeKJZFCoIP3z77JpArItuBvwW24XSXHHOtiHzJPfen7tBxoFRVVwKfBx4XkawIz/KAqq5W1dWFhYVRPIZhzEzaukOLSRrGZDBuu1hVK4GvRnFqLTAv6LgEOBZ2rXZgPYA4mVhV7itttLUichNOm+PLvF4vqtqLq+xUdYuIHASWAJvH8XiGccoQXkzSMCaDqCyVk+RNYLGIlIlIEk6l46eDTxCRHHcOnOiyF11FM+JaEbkC+AJwjap2BV2r0HXwIyILgcVY3xfjNKa9x+ulYkrFmDxi5sFTVb+IfAb4PU4U2QZV3S0it7vz9wPLgEdFZADYA9w62lr30vcCycAf3TITr7uRXpcAXxMRPzAA3K6qzbF6PsOY7gxZKuaoNyaPEf/aRGTUHvSqunWsi6vqszhZ+MFj9we9fw3HoohqrTu+aITzfwH8YiyZDON0wXwqxlQw2leYe9yfKcBqnEgtAc4G3gDWxlY0wzDeDl7Xx4xks1SMyWO0kOJLVfVS4Aiwyo2YOhenl8qByRLQMIyTo73bT0ZyAgnxsXSdGkYo0fy1lQeXZVHVXcCKmElkGMaE0N7Tb8UkjUknmr+4vSLyY+AnOLkiHwf2xlQqwzDeNpHK3htGrIlGqawH/hq40z1+EbgvZhIZhjEhtJtSMaaAaJp09bgVf591Ex8Nw5gBtPf4mZtjfeiNySWafirXANuB37nHK0Tk6VEXGYYx5TiWivlUjMklGkf9l3GqBrcCqOp2YEHMJDIMY0Jo7+63bHpj0olGqfhVtS3mkhiGMWEMDCodvX5LfDQmnWhs410i8lEgXkQWA38HvBpbsQzDeDt0enW/TKkYk0w0lsrfAmfiVAB+HKevyp2jrjAMY0rxsuktT8WYbKL5i3u/qn4J+JI3ICIfBn4eM6kMw3hbtFnZe2OKiMZSuTvKMcMwpgntVkzSmCJGq1J8JXAVMFdEvhs0lYXTcdEwjGnK0PaXKRVjchlt++sYTtfEa4AtQeMdwOdiKZRhGG+P9m7PUW8+FWNyGfEvTlV3ADtE5HFV7Z9EmQzDeJuYT8WYKqL5GrNARP4NWI7TWwUAVV0YM6kMw3hbtPf0EyeQkWSWijG5ROOofwingKQfuBR4FHgslkIZxkznW7+v4PoHXpuy+7d395OZkkhcnEyZDMbpSTRKJVVVnwNEVY+o6leAdbEVyzBmNnuOtbPnWPuU3b+9x2/+FGNKiEap9IhIHLBfRD4jIh8CiqK5uIhcISKVInJARO6KMJ8rIr8SkZ0isklEzhprrYjkicgfRWS/+zM3aO5u9/xKEbk8GhkNIxY0+/po7/HTPzA4Jfdvs7pfxhQRjVL5LJCGU57lXOATwE1jLRKReOD7wJU4/pgbRGR52GlfBLar6tnAjcB/RbH2LuA5VV0MPOce485fj5P9fwXwA/c6hjHpnPD1AdDi/pxs2rv7LUfFmBLGVCqq+qaqdqpqraquV9XrVPX1KK69BjigqodUtQ94Erg27JzlOIoBVa3ACQqYNcbaa4FH3PePAB8MGn9SVXtVtQo44F7HMCYdT5k0d028UunuG+ArT+8ORHhFwmklbErFmHxGS358Bqd9cERU9Zoxrj0XqAk6rgXODztnB3Ad8LKIrAHmAyVjrJ2lqsddGY6LiLcVNxd4PWzN3HChRORTwKcASktLx3gEwxg/Pf0D+PoGAGjunHilsrW6hYdfPcy583P5wDlzIp7T3m0+FWNqGM1S+Q/gHqAK6AZ+5L46gV1RXDtS2Em4kvomkCsi23EKV27DiTKLZu3J3A9VfUBVV6vq6sLCwjEuaRjjpzloy+tEDLa/vGvWtnSPeI75VIypYrTkx40AIvJ1Vb0kaOoZEXkximvXAvOCjktwsvSD79EOrHfvIzgKrArHhzPS2noRme1aKbOBhmjvZxiTQbBSaYnB9ldzZy8ANS1dEef7/IN09w+YT8WYEqJx1BeKSCDRUUTKgGi+4r8JLBaRMhFJwnGih7QhFpEcdw7gNuBFV9GMtvZphgIFbgJ+HTR+vYgkuzIuBjZFIadhTCghlsoI21/H27pP2onf3OX4UkayVDp6LJvemDqi2XT9HPCCiBxyjxcAnx5rkar6ReQzwO+BeGCDqu4Wkdvd+fuBZcCjIjIA7AFuHW2te+lvAk+JyK1ANfBhd81uEXnKvY4fuENVB6J4PsOYUIKtk+YRFMenHt1CaX4a3//oqnFfv9nnWCq1zZEtlfYeq/tlTB1j/tWp6u/cjo/l7lCFqvZGc3FVfRZ4Nmzs/qD3r+FYFFGtdcdPAJeNsOYbwDeikc0wYoVnneSlJ40Y/XX4hI/W7pO0VDyfSms3g4M6LGs+UPfLfCrGFDBa9Nc6VX1eRK4LmzpDRFDVX8ZYNsOYkTT7+ogTWJCfFjH6q7tvgI4ePx09fjp7/WQkj8+i8JRKn3+Qxs5eZmWlhMy3WzFJYwoZ7a/5XcDzwAcizClgSsUwItDc1UduWhIFGckcOTF8i6qhoyfwvrKug3Pn5w47Z9Tr+/pITYynu3+A2pau4Uqlxxp0GVPHiI56Vf2y+3N9hNctkyeiYcwsmjv7yEtPIj8j8vZXQ8fQ7nFF3fD6YP6BQT7x4Bts3NcY+fq+Pt4xNxuAmubhznpv+yvT+tMbU8Bo21+fH22hqn574sUxjJlPs6+P3PQkctOSaPH1oao4EfMODe1DSqWyrmPY+oq6Dl7a38Sy2Vm8a0looOXgoNLS1c87SrLZdLiZ2ghhxVWNPpIT4ijKTBk2ZxixZrSvMpmTJoVhnEI0d/WxuCiDvPQk/INKe7ef7LShrShv+2thQToVx4crlW3VLc557T3D5tp7+hkYVObkpFKQkRzRUqms72DJrEzirey9MQWMlvz41ckUxDBOFZp9Q9tf4CiZYKVS395LYrxw/sJ8frvz2DBLZmt1a+C8cLxs+rz0ROblpVLbOtxSqajrGGbhGMZkMWbyo4ikiMgdIvIDEdngvSZDOMOYaQwMKi1dfeS7218wlFfi0dDRQ1FmCstnZ9Le4+d4W6hFstWzVDqGWyotAaWSTElu2jBL5URnL40dvZQX20aDMTVEk1H/GFAMXA5sxCl/MtxmNwyDtu5+VCE3PYn89GRgeFZ9Y0cvhZnJLC3OAkL9Kk2dvRw50UVivIQ49D08SyU/PYl5uakca+1mYHCoxJ13rXL32oYx2USjVBap6j8DPlV9BHg/8I7YimUYMxPPKslLTyLP2/4Ky6qvb++hKDOZpa41sTcoAmy7u/W1dlEBHT1+uvtCi0I0+4YSK0ty0/APKnVBvpe9rlJZapaKMUVEo1S8pg2tbmfGbJxSLYZhhOFZJfnpyeSlDflUgmnocBIWs1MTmZOdEmKpbK1uISFOWLdslntu6BZYsFKZl5cKhJZrqaxrpyAjicLM5Al+MsOIjmiUygNuy95/xinauAf495hKZUwZg4OKf4pa4J4KeHW/ctMTSU2KJzUxPiSrvtc/QGtXP0Xuh3757KyQCLCt1S0sn5PF/Lw0gGFbYM2+PtKS4klJjKck1zmnJqiwZEVdh1kpxpQyolIRkT0i8iXgz6raoqobVXWhqhap6g8nUUZjErlv40Gu/t7LUy3GjGXI5+Eojbz0pJDtr0ZXSRRlOfNLizM52NhJn38Q/8AgO2raWDkvJzDf0D5cqeSlOxbQnJwURAjkqgwMKvvqO8yfYkwpo1kqNwAZwB9E5A0R+azbv8Q4hamo6+BgYyeqY/VEMyLhWSW56U4IcXhRSS9M2EtMLC/OxD+oHGzspKKug+7+AVbNzw3MR9r+8pRKckI8szJTAhFgR0746OkfNEvFmFJGK9OyQ1XvVtUzgDtxWv2+ISLPi8gnJ01CY1Jp9vXSP6D0+m0L7GRo7uojIzmB5IR4IJKl4igJzxIpD4oA21bTCsCq0lxy0xJJjJdhuSrBSgVwclVcS8XzzSwzS8WYQqLxqaCqr6vq54AbgVzg3phKZUwZzT4nLsMrSmiMj/AP/fz0pJCQYs9H4lkiCwvTSYwX9ta1s+1ICwUZyZTkpiIiFGWmjGqpAJTkpgWade2t6yBOYPGsjJg9n2GMRTTJj+eJyLdF5AjwVeABYG7MJTOmBC8ktsNt9GSMj/AP/dz0pJCmXfXtPcTHCfnuOYnxcZxRmEFlXQdbq1tYVZoTyK4vzEwO+GBCrp8WZKnkpnK8rZv+gUEq69pZUJBOSmJ8LB/RMEZltIKS/wp8BGgBngQuUtXayRLMmHxUNbBVY0rl5Gj29YWUos9LT6Krb4Ce/gFSEuNpaO+lICMppLHWstlZ/GlvPR09fq5fUxoYL8oMLZ3f3TdAd/9AIP8FHEtlUOF4aw+VdR0sn2NbX8bUMpql0gtcqaqrVfU/VLVWRK6eLMGMyaez10//gOOg77Dtr5Mi0vYXDEWFeTkqwSwtzgwo8VWlQ71VirKSqQ/a/jrhWpH5wdtfbq7KvvoOjjR3WeSXMeWM5qj/qqruCxv+WozlMaaQYIdye7dZKuNFVTnh6wv50M9137cEKZWisMREr05XQpxwdkl2YLwoM4XWrn56/U5Wvffvkxuy/eXkqjxX0YCqZdIbU09UjvogxlVLW0SuEJFKETkgIndFmM8WkWdEZIeI7BaR9UFzd4rILnf8s0HjPxOR7e7rsIhsd8cXiEh30Nz943y2054TQUrlZC2VAw0dp62V09U3QJ9/MKBIIIKl0t5DYVifE8+6WD4nK8QfMsuNEPP8Kp5SyQ/a/pqdnUJ8nPDc3nrAIr+MqWe8SuXT0Z4oIvHA94ErgeXADSKyPOy0O4A9qnoO8G7gHhFJcsvBfBJYA5wDXC0iiwFU9SOqukJVVwC/ILSt8UFvTlVvH+eznfa0hCiV8Vsqg4PKB7//Kj/ceGgixZoxBJdQ8fDeO6Hag5zw9Q2zVGZlORFfaxcVhIwP5aqEKpW89KH1CfFxFGel0NDRS1pSPCW5qRP8VIYxPqKJ/vqwiHg29eUi8ksRWRXFtdcAB1T1kKr24Tj7rw07R4FMccJdMoBmwA8sA15X1S5V9eNUR/5QmFwC/BXwRBSyGFHwdi2Vlq4+Onv9HD7hm0ixZgzBFYQ9hpRKP02djnII96mICL/77CV87r1LQsa9+l1es66AUgna/gICNcCWFmeGBAAYxlQQjaXyz6raISJrgfcCjwD3RbFuLlATdFzL8FDke3EUyDHgLeBOVR0EdgGXiEi+iKQBVwHzwtZeDNSr6v6gsTIR2SYiG0Xk4khCicinRGSziGxubIzcA/x0xfvQSowX2k/CUvG+Ude1De8DcjrgWXrB219ZKYnExwnNvt5AyZVwSwUgIzmBxPjQ/46BUi1BlkpCnJCVGhq06dUAsx4qxnQgGqXi1d5+P3C/qv4aSBrlfI9IX5nCa39cDmwH5gArgHtFJEtV9+IUrfwj8DtgB44FE8wNhFopx4FSVV0JfB54XESGbTCr6gNuRNvqwkLrjhdMi6+PJLe3+clsf9W736jDm06dLkSyVOLihNw0J6ve+/14ymIs8tOTiY+TgDJq9vWRm54U0iUShpz1FvllTAeiUSpHReSHOFtNz4pIcpTragm1LkpwLJJg1gO/VIcDQBVQDqCqD6rqKlW9BGdbLGCRiEgCcB3wM29MVXtV9YT7fgtwEAjdTzBGxYtcykxJOKmMeu8bdX17T0jjqNOF4F4qweSlJ9Ls6wv8fsK3v0YiPk4oyEgKZNWfCEt89Aje/jKMqSYa5fBXwO+BK1S1FcgD/jGKdW8Ci0WkTESSgOtxSucHUw1cBiAis4ClwCH3uMj9WYqjQIKtkvcAFcHJmCJS6AYHICILgcXetYzo8HIsMlMSTsqn4kUp+QeVE53Duxae6jT7+kmKjyMjOXR7yqv/1dDRi0ioJTMWRZkpgfpfLWE5MB6Xn1nMP1+9nPMW5L29BzCMCWDEjPogZgO/VdVeEXk3cDbw6FiLVNUvIp/BUUjxwAZV3S0it7vz9wNfBx4Wkbdwtsu+oKpN7iV+ISL5OE3C7lDVlqDLX89wB/0lwNdExI+zZXe7qjZH8XyGi6dUkuLjQroJRktD0JpjbT0URfmN/FSh2ddLbnrisO2p/PRk9ta109DeQ356Mgnx0QddFmUmc6xtyFG/LELGfHpyAreuLXt7whvGBBGNUvkFsFpEFgEP4lgbj+M4z0dFVZ8Fng0buz/o/THgfSOsjehod+dujjD2C1dW4yRp9vUxPz8NAfY3nIxPpZf4OGFgUKlr64Z5ORMu43TGUcrD/SW56Ym0uJZKJCf9aBRlpbCjthUYefvLMKYT0XxlGnTDeq8DvuNWK7a+KqcgQ9tfiSe1/dXQ0cOSWc6+/rHW089Z3xyWTe+Rl55Ma3c/x9t6AgmN0VKUmcwJXx89/QO0dfdH3P4yjOlEVD3qReQGnLL3v3HHEmMnkjEV9PoH6Oz1k5fm+VT8427U1dDRy9JZGSQlnNz22UzHi84KJz89CVU42NgZSGiMlqKsZFThQEOnc60MUyrG9CYapbIeuBD4hqpWiUgZ8JPYimVMNi1uH5W8DMdS8Q8qPf3RN+pS1UCxxNnZKadlWHF43S8PT9H0+QejDif28JTQ3uPtzrVs+8uY5oypVFR1D/APwFtu+ZRaVf1mzCUzJpXgCriZKY6rbTxhxW3d/fT5BynMTHaUSmt3TOScrvQPDNLR44+4PRWsaMbrU/G2yyrcro7jiRwzjKkgmjIt78bJEfk+8ANgn4hcEluxjMkmuAKup1TG41cJzsGYnZ162lkqkbLpPYKti/FGxHmWSkWdY6nk2faXMc2JJvrrHuB9qloJICJLcMJ5z42lYMbkElwBt6vfKaIwnlItwSVIZmenBBIg40+TWlTNXcOz6T2C/SDjtVQKMpIQgYrjjqVi0V/GdCcan0qip1AA3B4r5qg/xQiugJsVsFTGoVQ6vBIkjk/ldEuAbO4cXqHY4+1YKgnxcU6f+1EsIcOYTkSjVLaIyIMi8m739SNgS6wFMyaXZl8fIpCdmkhmivOdYTzbX/UhlopTNuR02gI74RtZqSQlxJHpZtkXZozPUoGhLbCslOFFJw1juhHNX+jtwG7g74A7gT3umHEK0ezrIzctifg4CfKpjM9SyUhOID05geJs50PweNvp46xv6RpZqYDjC8lLTyIpYfxKwYsYsxwVYyYwqk9FROKALap6FvDtyRFp+nOgoYO7f/nWqOcUZabwnetXzJhvlsG91T1Lpb17fI56z18wO6BUZq6l0uLr4yvP7ObLHzgzqg/zoy3diEBOauSd4bz0JFKDujqOB+/3akrFmAmM+onn9jbZ4RZ1NAIIifFxI746ewf47VvHAwlrM4HgEiDpSfHEyTgtlfaeQFMp7xv5TFYqL+5v5Nfbj7FxX8OY5760v5EHX67iXUsKR6zrdeOF87nlopOrz+Vtf0UqAWMY041oC0ruFpFNQKCln6peEzOppjmLijJ4/JMXjDi/62gbV3/vZaqafCybPTN6XLT4+jijMANwOhFmJI+vUnFDRy/nlOQE1s/0BMhKNy/Eyw8ZiV1H27j9sS0sKsrguzesHPG8D60sOWlZhra/LD7GmP5Eo1S+GnMpTjHKCtIBqGqaOW11m319nFcW1LEwNTFqS0VVaWgPLZY4OzvFKSo5Q/GUiRfKG4ma5i7WP/wm2amJPLx+DVkpsfnQN0vFmEmMqFTcqsSzVHVj2PglwNFYCzaTSU9OYFZWMocaZ4ZSGRxUWrpCS4xkpiRGnafS2eunu38gpATJ7OxUNlVNr84Du462MTcnNaqwXM9SqRzBUmnt6uPmhzbR2z/AT//6nYHghFjg/V4tm96YCYzmU/kOEOl/VJc7Z4xCWUE6VU0zw6fS1t3PoIbmU4ynUddQOPHQB6uXADk4TTpADgwqH/nha3zzfyvGPLetu5+jrd0UZCRR195DqxvZFcxP36jmYKOPH924OlCZOVYsyE8nNTGeRbMyYnofw5gIRlMqC1R1Z/igqm4GFsRMolOEsoKMGbP9dSIom94jy61UHA1DiY+h21/+QaVpmiRAHmvtxtc3wHMV9WMqun31znepq8+eA0T2q2w+3MziogzOX5g/8cKGkZeexLZ/eS/vXlIY83sZxttlNKUymj2fOtGCnGosLEinpas/4rfc6UZzhMQ9Z/srOkvFayMcbKkUT7MESE/BN3X28dbRtlHPrXArAn9w5dyQYw9VZVtNK6tKc2MgaWRSEuOHdZQ0jOnIaErlTRH5ZPigiNyKZdSPyUxy1gcXk/TIHI+l4m1/hVkqMH0SIIP/HZ6rGD1MuKKug6yUBM4pySY3LZHK+lBL5VCTj9auflaW5sRCVMOY0YymVD4LrBeRF0TkHve1EbgNJ7N+TETkChGpFJEDInJXhPlsEXlGRHaIyG4RWR80d6eI7HLHPxs0/hUROSoi293XVUFzd7v3qhSRy6ORMVaUFU6OUuns9fOeb2/khcqx8ylGojni9lcinb3RNeqqb+8hJXGoFAlMTQLkV57ezVef2R1xrqrJR3pSPKvn5/J8Rf2o16mo66C8OAsRYWlxJnvDIsC2VbcCsGr+5FkqhjFTGFGpqGq9qr4TJ6T4sPv6qqpeqKp1Y11YROJxyuVfCSwHbhCR5WGn3QHsUdVzgHcD94hIktu35ZPAGuAc4GoRWRy07j9VdYX7eta933LgeuBM4ArgB64MU8K83DTi4yTmSmVbdQsHGjr5+Zbak75Gs9tLJdxSGRhUuvoGxlzvNecK3p7xEiDrJlGpPPvWcX63K/Kf5qEmH2WF6axbVsSuo+0jyqWqVNZ1UD7bcb6XF2exr74jxA+ztbqFzJQEFhWa49wwwommSdefVfV77uv5cVx7DXBAVQ+pah/wJHBt+OWBTHE+jTKAZsAPLANeV9UuVfUDG4EPjXG/a4EnVbVXVauAA64MU0JSQhzzclM5FGOlsvVIKwAv7mukfyD6To3BNPv6SU+KJyWojMhQUcmxt8AaOnqGlXT3EiCPTZJSafb10dDRy/G2Htq6hvuCqpo6KSvI4LLyWQD8eQTLrralm85eP0uLPaWSSVffADUtXYFzth5pYcW8HOJOk7L+hjEeYlmYai5QE3Rc644Fcy+OAjkGvAXc6ZaG2QVcIiL5IpIGXAXMC1r3GRHZKSIbRMTbg4jmfojIp0Rks4hsbmxsfBuPNzYLCtKpinGuytbqlkBJlc2HW07qGs2+3mHNn8bTqMup+zU8rmMyEyC9Jlbh7wF6/QMcbemmrCCdJbMymJuTyvMj+FW8vJTyYqcSQrlbEcGLAOvs9bOvvmNSnfSGMZOIpVKJ9DUufIP+cmA7MAdYAdwrIlmquhf4d+CPwO+AHTgWDMB9wBnu+cdxmohFez9U9QFVXa2qqwsLYxui6eSq+KLyS5wMg4PKtuoWrj57DknxcWP6CkbihK9vWLb2eFoKN7T3Bup+BTM7O5VjrZNjqQQnKYY71muauxhUJyJPRLhsWREv72+ip3/41p6nkDxLZcmsjJAmWTtqWhlU86cYxkjEUqnUEmpdlOBYJMGsB36pDgeAKqAcQFUfVNVVqnoJzrbYfne8XlUHXIvmRwxtcUVzv0llYUE63f0DgeTAieZQUyftPX7WLi7g/IV5Y0Y1jURLVx95aaElRgKVisfY/urq89PZ62dWhOZTxZOYAFlZ10FeehLZqYnDHOteZQMvIm9deRHd/QO8fujEsOtU1HUwLy+VDDfoIC0pgfl5aVTWO8pm6xHHGlwxLydWj2IYM5pYKpU3gcUiUiYiSThO9KfDzqkGLgMQkVnAUuCQe1zk/iwFrsNpYYyIzA5a/yGcrTLca18vIskiUgYsBjbF4LmipqzAceQeilFmvedPWVWay2XlRRxq9HH4JHw4zZ3DLZVouz8GtxEOZ46XAOmLfQLk3roOyoszKS/OpDJs+8sLlljgKpULFuaTmhgfcQusoq6DpbNCi4AuLc4MWCpbq1tYXJRB9ggl7g3jdCdmSsV1sH8G+D2wF3hKVXeLyO0i4jX5+jrwThF5C3gO+IKqNrlzvxCRPcAzwB2q6jkM/p+IvCUiO4FLgc+599sNPIXTROx37pqxQ5diSKzDirfVtJCVksDCgnTWuQ7okXwFI6GqnPD1hYQTg1NQEsb2qTR0DM9R8QgkQMZ4C2xwUNlX18HSgFIJjdaqavKR71ox4CQSXrSogOf2NoRsTfb0D7iVpUPLrpQXZ3H4hI+uPv+kJz0axkwjmirFJ40b7vts2Nj9Qe+PAe8bYe3FI4x/YpT7fQP4xkkJGwNmZ6WQnBAXM2f91iOtrCzNJS5OKM1PY1FRBs9XNHDL2uj7dnT3D9DrHwwJJwai7v5Y3+6WaBnBUQ9Orso584ZNTxjVzV109w9QXpzJoIKvb4Cjrd3My0sD3HBi10rxuGxZEX/aW8/+hs5A7a4DDZ0MDGrAn+LhXfePe+ot6dEwxmBmtCWcocTFScBZP9G09/SzryE0Cumy8iLeqDpBZ2/0zbVOdLqJj2EVcFMT44mPk6gtlVkRLJW5OY6lEh6NNdFUBEVseQphb1BplaoISmVdeREi8F/P7Q9YNeGRXx5eBNjjb1QD5qQ3jNEwpRJjYqVUdtS0ogqr5ucExtaVF9E/oLy8P/pQ6Uh1v8DJM4mmVEtDRw9JCXERfQy56UlcvLiAx9+ops9/cjk00VBR144ILJmVyVLX6vAUREdPP40dvYGtSI9ZWSn80+Xl/Hbncf79dxWB6yQlxLEgPy3k3NK8NFIS43ijqtmSHg1jDEypxJiygnSqm7vwn2Ri4khsPdKKSGgU0rnzc8lKSeC5vdH7VZrdgpeReoxkpiSM2ae+ob2XwozkEYsd3rq2jIaOXn6zM3aBeJV1HU55+KR40pMTKM1LC1gvh5ucpMWFYZYKwO3vWsiNF87nhy8e4qFXqqio62DJrIxhLYHj4ySgrCzp0TBGx5RKjCkrSMc/qNS2TGwS4NbqFpYUZQZCfwES4uN419Ii/lzZEHUYb/MI218Amcljd39s6OiJuPXl8a4lhSwuyuDBl6tilq/jRGwN+UHKizMDW25VJ7xw4uHWhYjw5Q+cyeVnzuJrv9nDpqrmYZFfHt62mjnpDWN0TKnEmIURIsCe3FTN//3NnpO+ppf0GMlhfFl5EU2dfbx6cHgORiQC218ZkS2VsR31kbPpPUSEW9eWsftYO68fCu0EWVHXzi0Pv/m2eq509w1w+IQvUKsLHKVS1eRzorkafYjA/LAtLY/4OOG/rl/JuaW59PoHh0V+DV3TUTbmTzGM0TGlEmMW5DtKxasB9uvtR7nrl2/x45er2FZ9cmVVDjX5aO/xR/zWfNmyIublpXLnk9uiylmprHeSBoMrDHtkpY7eU6XZ18fBxs6QD/RIfHDlXPLTk3jw5UOBsaOt3dy0YRPPVzTwyoGmUVaPzv6GDlQdReKxtDiLQXWiuaqaOpmTnRpS1yyclMR4fnzTam5YU8rlZxZHPOf9Z8/mxgvnc35Z3knLahinA6ZUYkxeehJZKQlUNXXy6oEm/uHnO1izII/MlAQefLnqpK651VVGwU56j8yURB5Zv4ZBVW56aNOYVsDW6hZWleZE9ImMZam8UNmAKoEijSORkhjPxy6Yz5/2NnCosZO2rn5u3rCJrt4BEuJkxD7w0eAlJS4NitjylNze4+1UNfkC1uJo5KQl8W/XvSMQhhzOrKwUvnbtWaMqJ8MwTKnEHBGhrDCDVw+c4NOPbaGsIJ0fud+K/3dXHbVB1W+jZVu1l/QYOQppYWEGD958HvXtPdz68Jt09UVWDK1dfRxq9LFyBD9BVkriqCHFz1U0UJiZzJlzIvshgvnEBfNJio/j/o0H+eRjmzl8wscPbzyXMwozIrbrjZaKug5SE+MpDVIGC/LTSU6Io6KuI2KOimEYscOUyiSwsCCdQ00+0pMTeHj9GrJTE7npnQsAeOTVw+O+XnDS40isKs3lezes4q2jbdzx060MRHDce82mRkrmy0xJoLPXH9Hp3z8wyIuVjaxbWhRVNFRhZjIfXDmHpzbXsqmqmXv+agXvPKOApW4GfCTauvp5cd/o4dEVde0smZVBfJAM8XHCklmZvHKgiY4evykVw5hETKlMAitLc8hJS+ThW85jjpsQODcnlaveMZsnN9WMK1nxZ29WU1nfwTvPyB/z3Pcun8W/XL2cP1c2Rvxw9srmn1OSE3F9ZkqCm6E+XL7Nh1vo6PWzbllR1LJ/8uKFZKYk8H/ev4xrzpkDOFtVR1u7aYsQuvzgy4e4ccMmNoywTaiqgS6N4SwtzgxYQKZUDGPyMKUyCdx44QI2ffE9wz78bl1bRkevn6ferBlhZSh/rmjgi7/axSVLCqMuxXLD+aWkJcXzXISy+FurWygvziI9gpMeRm/U9XxFPUnxcaxdVBCVHACLZ2Wy7Z/fy20XLwyMeQ72ffXDrZXNbkXgr/92D8++dXzYfGNnL82+vmFlVYKvC4y4TWgYxsRjSmWSSEoY/qteMS+H1fNz2fBKVcTtqWB21LTyNz/dyrLZmdz3sVUkxkf3T5ecEM/aRQU8H1Y8cWBQ2VHTFtHZ7zFa/a/nKhq44Iz8ERXSSIQnFnqKtuJ4aCkXR75W/mp1CeeW5vLZn23njbBS9YGyKhGiz7zrJsYLc3JGDnk2DGNiMaUyxdx2cRm1Ld38blcdA4Ma8VXV5OOWh9+kIDOJDTefN+4P8suWFXGsrSfEIb6/oYPO3shhyR5ZKZErFVc1+TjU6GPd0rff5Gx2dgqZKQnDnPX76jvw9Q1w4Rn5/OjG1czLTeWTj26msq4j8Hvx6ntF2v7yFE1pXtowRWYYRuyIaZViY2zeu7yYeXmp3PH41lHPy01zQoVHSzQciUuXOn6P5ysaWOYWRwzuxTISI1kqXnn9dWOEEkeDiLCsOGuYUgmETZfmkpuexMPr13Ddfa9y+XdeDDmvKDN5WN0ygIKMZAozk1lodboMY1IxpTLFxMcJ996wio2jRDkJcMVZxSf9AVmUlcLZJdk8t7eeOy5dBDgf2nnpSSNmmkNw98dQS+X5inoWF2VQOsra8bC0OJNfbTuKqgbyZbYeaSUvPSkQKjwvL42nPn0hv915jOCdwtHK0N97w8phfWIMw4gtplSmAefMy+GcGLenXVdexH89t58Tnb3kZySztbqFlfMiJz16ZAX61A9ZKh09/Wyqah5Xz5axKJ+dSefrfmpbhnqgbIuQlFlWkM5n1i2O+rrnLxw7Qs4wjInFNptPE9aVF6EKL1Q2BpIex6pjlRnBp/Ly/ib6B3TMLPrx4EVqeY73Fl8fh5pGTso0DGP6YkrlNOGsOdkUZibzfGUD22pagdG3jgBSEuNIiJMQn8rvd9eRnZrIqgnsfuh1XvQqC2935bOKwIYx8zClcpoQFyesW1rEi5WNbKpqHjXp0WOoUZdjqfxyay3/s/0YH1wxZ0IjqjJTEinJTQ0467dWtxAfJ5wzL3vC7mEYxuQQU6UiIleISKWIHBCRuyLMZ4vIMyKyQ0R2i8j6oLk7RWSXO/7ZoPFviUiFiOwUkV+JSI47vkBEukVku/u6P5bPNhNZt6yIjl4/j79RPWrSYzBZqU5PlZf2N/JP/72TCxfm88X3L5tw2cqLswLbX05SZiZpSebyM4yZRsyUiojEA98HrgSWAzeIyPKw0+4A9qjqOcC7gXtEJElEzgI+CawBzgGuFhHPQ/tH4CxVPRvYB9wddL2DqrrCfd0eq2ebqaxdVEBSfBxt3f2jJj0Gk5mSwFtH27j9sS0sKsrghzeeS3LCxFfqLS/O5FCTj+6+AbZXt9rWl2HMUGJpqawBDqjqIVXtA54Erg07R4FMcUJ8MoBmwA8sA15X1S5V9QMbgQ8BqOof3DGA14GSGD7DKUV6cgIXuDXDov3QzkxO5FCjj+zURB5evyaQEDnRlM/OZGBQefat4/j6BqJWeoZhTC9iqVTmAsFFrWrdsWDuxVEgx4C3gDtVdRDYBVwiIvkikgZcBcyLcI9bgP8NOi4TkW0islFELo4klIh8SkQ2i8jmxsbRK+Ceilx+5iziBM5bEF2zqVlZyWSlJPDwLWsozo5duRMvAuyJTdWAOekNY6YSy03rSAkQ4QWuLge2A+uAM4A/ishLqrpXRP4dZ6urE9iBY8EMXVzkS+7YT92h40Cpqp4QkXOB/xGRM1U1pKiUqj4APACwevXq2DRNn8Zcf14p55flj9iMKpyvXHMmX7iynNnZqTGVa0F+OkkJcWw+0hKS9GgYxswilpZKLaHWRQmORRLMeuCX6nAAqALKAVT1QVVdpaqX4GyL7fcWichNwNXAx9Stkqiqvap6wn2/BTgILInJk81g4uOERUXRZ+bnpCXFXKGAU2hysSvXSJ0oDcOY/sRSqbwJLBaRMhFJAq4Hng47pxq4DEBEZgFLgUPucZH7sxS4DnjCPb4C+AJwjaoG2iaKSKEbHICILAQWe9cyZgZeYUhLejSMmUvMtr9U1S8inwF+D8QDG1R1t4jc7s7fD3wdeFhE3sLZLvuCqja5l/iFiOQD/cAdqtrijt8LJONslYHj0L8duAT4moj4gQHgdlVtjtXzGROP51cxf4phzFwkuMfG6cbq1at18+bNUy2G4VLf3sOGl6v4h8uXRt0vxjCMyUdEtqjq6khzll1mTBtmZaVw91UTn1hpGMbkYV8HDcMwjAnDlIphGIYxYZhSMQzDMCYMUyqGYRjGhGFKxTAMw5gwTKkYhmEYE4YpFcMwDGPCMKViGIZhTBindUa9iDQCR8axpABoGvOsqcFkOzlMtpPDZDs5ThXZ5qtqYaSJ01qpjBcR2TxSaYKpxmQ7OUy2k8NkOzlOB9ls+8swDMOYMEypGIZhGBOGKZXx8cBUCzAKJtvJYbKdHCbbyXHKy2Y+FcMwDGPCMEvFMAzDmDBMqRiGYRgThimVKBCRK0SkUkQOiMhdUyzLBhFpEJFdQWN5IvJHEdnv/pySfrwiMk9E/iwie0Vkt4jcOV3kE5EUEdkkIjtc2b46XWQLkjFeRLaJyG+mk2wiclhE3hKR7SKyeZrJliMi/y0iFe7f3YXTQTYRWer+vrxXu4h8djrI5sr3Off/wS4RecL9/zEhsplSGQMRiQe+D1wJLAduEJHlUyjSw8AVYWN3Ac+p6mLgOfd4KvADf6+qy4ALgDvc39V0kK8XWKeq5wArgCtE5IJpIpvHncDeoOPpJNulqroiKI9husj2X8DvVLUcOAfn9zflsqlqpfv7WgGcC3QBv5oOsonIXODvgNWqehYQD1w/YbKpqr1GeQEXAr8POr4buHuKZVoA7Ao6rgRmu+9nA5VT/XtzZfk18N7pJh+QBmwFzp8usgEl7n/kdcBvptO/K3AYKAgbm3LZgCygCjfgaDrJFibP+4BXpotswFygBsjDaSn/G1fGCZHNLJWx8f4BPGrdsenELFU9DuD+LJpieRCRBcBK4A2miXzu9tJ2oAH4o6pOG9mA7wD/BAwGjU0X2RT4g4hsEZFPTSPZFgKNwEPutuGPRSR9msgWzPXAE+77KZdNVY8C/wFUA8eBNlX9w0TJZkplbCTCmMVhj4KIZAC/AD6rqu1TLY+Hqg6osx1RAqwRkbOmWCQARORqoEFVt0y1LCNwkaquwtkCvkNELplqgVwSgFXAfaq6EvAxtVuEwxCRJOAa4OdTLYuH6yu5FigD5gDpIvLxibq+KZWxqQXmBR2XAMemSJaRqBeR2QDuz4apEkREEnEUyk9V9ZfTTT4AVW0FXsDxTU0H2S4CrhGRw8CTwDoR+ck0kQ1VPeb+bMDxC6yZJrLVArWuxQnw3zhKZjrI5nElsFVV693j6SDbe4AqVW1U1X7gl8A7J0o2Uypj8yawWETK3G8d1wNPT7FM4TwN3OS+vwnHlzHpiIgADwJ7VfXbQVNTLp+IFIpIjvs+Fec/VsV0kE1V71bVElVdgPP39byqfnw6yCYi6SKS6b3H2XvfNR1kU9U6oEZElrpDlwF7poNsQdzA0NYXTA/ZqoELRCTN/T97GU6Aw8TINpUOrJnyAq4C9gEHgS9NsSxP4OyD9uN8U7sVyMdx8u53f+ZNkWxrcbYGdwLb3ddV00E+4GxgmyvbLuBf3PEply1Mzncz5Kifctlw/BY73Ndu7+9/OsjmyrEC2Oz+u/4PkDuNZEsDTgDZQWPTRbav4nyp2gU8BiRPlGxWpsUwDMOYMGz7yzAMw5gwTKkYhmEYE4YpFcMwDGPCMKViGIZhTBimVAzDMIwJw5SKMaMQkRdE5PKwsc+KyA/GWLN6pPkJkusJEdkpIp+bivVB1/m1iLw2yvwCCapwPco53W513R0i8mpQLsjbxq0s/DcTdT1jemFKxZhpPIGTIBhMcG2lSUdEioF3qurZqvqfk7FeRBIijOXgZJTniEjZeOUI46A6VXbPAR4Bvvg2rxdMDmBK5RTFlIox0/hv4GoRSYZA4co5wMsicp+IbJagfinhiEhn0Pu/FJGH3feFIvILEXnTfV0UYW2KiDwkTm+RbSJyqTv1B6DI/WZ/cdiaD4jIG+75fxKRWRHEClkvIitE5HXXcvmV19fCtbj+VUQ24pTJD+cvgGdwSr0EFK+InOtaHK8BdwSNLxCRl0Rkq/t6Z6TfGU414JbRfgejjJ8pTh+b7e7zLAa+CZzhjn1rhHsaM5WpyOa0l73ezgv4LXCt+/4u4Fvu+zz3ZzxOba+z3eMXcHpHAHQGXecvgYfd948Da933pTilZsLv+/fAQ+77cpxyFymEtSIIW5MLgSTj24B7IpwTsh4nO/xd7vuvAd8Jeo4fjPJ7+RNwMbAE2DnC9b7l3Qsn4zvFfb8Y2BwkTzdORYSDOBUcSsf4HYw0/j3gY+54EpA62u/LXjP/NcyENowZgLcF9mv35y3u+F+JU5o9AacfxHKcD9RoeA+w3CmFBECWiGSqakfQOWtxPiRR1QoROYLzAT5aJeYS4Gdugb4knP4fIyIi2UCOqm50hx4htMLtz0ZYNwtYBLysqioifnGqMNeEXe8xnCKHAInAvSKyAhhwn8XjoDoVnRGRjwAP4BTgHOl3MNL4a8CXRKQE+KWq7g/6HRunILb9ZcxE/ge4TERWAamqutX1IfwDcJmqno1jzaREWBtclyh4Pg64UN1ufao6N0yhQOQ2CGPxPeBeVX0H8OkRZBoPvhHGP4JjFVWJU+14AY7CFUZu1fA5oB6nY+JqHKUXiacBr9z9SL+DiOOq+jhO6fdu4Pcism6E9cYpgikVY8ahqp04W0EbGHLQZ+F84La539qvjLyaehFZJiJxwIeCxv8AfMY7cL+9h/Mi8DF3fgnONlnlGOJmA0fd9zeNdiKAqrYBLUG+mU8AG0dZ4nEDcIWqLlCn2vG5wPXqlPlvE5G17nkfC5PtuKoOuveJH+Haa3G2wWDk30HEcRFZCBxS1e/iKKezgQ4gM4pnMmYgplSMmcoTON+wnwRQ1R04VYh34yibV0ZYdxdO+9TncXwFHn8HrHadyXuA2yOs/QEQLyJv4WxD3ayqvWPI+RXg5yLyEtAUxXOBo3y+JSI7carwfm20k91ghVLgdW9MVauAdhE5H1gPfN911HeHPc9NIvI6zlZVsBXkOdJ3AP+K4w/y1kT6HYw0/hFglzgdN8uBR1X1BPCKiOwyR/2ph1UpNgzDMCYMs1QMwzCMCcOUimEYhjFhmFIxDMMwJgxTKoZhGMaEYUrFMAzDmDBMqRiGYRgThikVwzAMY8L4/0kscQP/x/1MAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65 SAMME.R\n"
     ]
    }
   ],
   "source": [
    "ada_range = range(1, 80)\n",
    "ada_scores_SAMME = []\n",
    "ada_scores_SAMME_R = []\n",
    "ada_max = 0\n",
    "ada_max_score = 0\n",
    "algorithm_max = 0\n",
    "\n",
    "algorithm = ['SAMME', 'SAMME.R']\n",
    "\n",
    "for a in ada_range:\n",
    "    for algo in range(len(algorithm)):\n",
    "        ada = AdaBoostClassifier(n_estimators=a, algorithm= algorithm[algo], random_state=0)\n",
    "        scores = cross_val_score(ada, X_train, y_train, scoring='accuracy')\n",
    "        if algo == 0:\n",
    "            ada_scores_SAMME.append(scores.mean())\n",
    "        else:\n",
    "            ada_scores_SAMME_R.append(scores.mean())\n",
    "        if scores.mean() > ada_max_score:\n",
    "            ada_max = a\n",
    "            ada_max_score = scores.mean()\n",
    "            algorithm_max = algorithm[algo]\n",
    "\n",
    "plt.plot(ada_range, ada_scores_SAMME)\n",
    "plt.xlabel('Value of a for AdaBoost')\n",
    "plt.ylabel('Cross-Validated Accuracy')\n",
    "plt.title('SAMME')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(ada_range, ada_scores_SAMME_R)\n",
    "plt.xlabel('Value of a for AdaBoost')\n",
    "plt.ylabel('Cross-Validated Accuracy')\n",
    "plt.title('SAMME.R')\n",
    "plt.show()\n",
    "\n",
    "print(ada_max, algorithm_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03065c4f",
   "metadata": {},
   "source": [
    "## Runnig Optimized AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "e6e7b7b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-6 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-6 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-6 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-6 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-6 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-6 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-6 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-6 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-6 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-6 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-6 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-6 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>AdaBoostClassifier(n_estimators=65, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;AdaBoostClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.ensemble.AdaBoostClassifier.html\">?<span>Documentation for AdaBoostClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>AdaBoostClassifier(n_estimators=65, random_state=0)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "AdaBoostClassifier(n_estimators=65, random_state=0)"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada = AdaBoostClassifier(n_estimators=65, algorithm=\"SAMME.R\", random_state=0)\n",
    "ada.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "b48f3cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_values = ada.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "4e0c34dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94.6031746031746"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = metrics.accuracy_score(y_test, predicted_values) * 100\n",
    "acc.append(x)\n",
    "model.append('AdaBoost')\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "2272e400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.97      0.96       521\n",
      "         1.0       0.85      0.75      0.80       109\n",
      "\n",
      "    accuracy                           0.93       630\n",
      "   macro avg       0.90      0.86      0.88       630\n",
      "weighted avg       0.93      0.93      0.93       630\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Classification report and breakdown\n",
    "print(classification_report(y_test,predicted_values))\n",
    "\n",
    "y_pred = ada.predict(X_test)\n",
    "y_true = y_test\n",
    "\n",
    "cm_Ada = confusion_matrix(y_true,y_pred)\n",
    "\n",
    "f, ax = plt.subplots(figsize=(10,8))\n",
    "sns.heatmap(cm_Ada, annot=True, linewidth=0.5, fmt=\".0f\",cmap='viridis', ax = ax)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Actual vs. Predicted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "26002c39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy =  0.944047619047619\n",
      "Testing accuracy =  0.9349206349206349\n"
     ]
    }
   ],
   "source": [
    "# Storing the accuracy values for model results comparison later\n",
    "\n",
    "#Print Train Accuracy\n",
    "ada_train_accuracy = metrics.accuracy_score(y_train, ada.predict(X_train))\n",
    "print(\"Training accuracy = \",metrics.accuracy_score(y_train, ada.predict(X_train)))\n",
    "\n",
    "#Print Test Accuracy\n",
    "ada_test_accuracy = metrics.accuracy_score(y_test, ada.predict(X_test))\n",
    "print(\"Testing accuracy = \",metrics.accuracy_score(y_test, ada.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "d5a8b8dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation score:  [0.93015873 0.93174603 0.91587302 0.92698413 0.92539683]\n"
     ]
    }
   ],
   "source": [
    "# Cross validation on dataset\n",
    "score = cross_val_score(ada, X, y, cv=5)\n",
    "print('Cross validation score: ',score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "02b3a2a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9260317460317461"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mean score\n",
    "score.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06554069",
   "metadata": {},
   "source": [
    "## XGBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "359658d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def report_best_scores(results, n_top=3):\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
    "        for candidate in candidates:\n",
    "            print(\"Model with rank: {0}\".format(i))\n",
    "            print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
    "                  results['mean_test_score'][candidate],\n",
    "                  results['std_test_score'][candidate]))\n",
    "            print(\"Parameters: {0}\".format(results['params'][candidate]))\n",
    "            print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "9ca4895d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 200 candidates, totalling 1000 fits\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.957 (std: 0.007)\n",
      "Parameters: {'colsample_bytree': 0.8167605036202489, 'gamma': 0.00541882574014918, 'learning_rate': 0.3016145929257791, 'max_depth': 5, 'n_estimators': 108, 'subsample': 0.7277254550361659}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import uniform, randint\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "xgb_model = xgb.XGBClassifier(objective=\"binary:logistic\", random_state=0)\n",
    "\n",
    "params = {\n",
    "    \"colsample_bytree\": uniform(0.7, 0.3),\n",
    "    \"gamma\": uniform(0, 0.5),\n",
    "    \"learning_rate\": uniform(0.03, 0.3), # default 0.1 \n",
    "    \"max_depth\": randint(2, 6), # default 3\n",
    "    \"n_estimators\": randint(100, 150), # default 100\n",
    "    \"subsample\": uniform(0.6, 0.4)\n",
    "}\n",
    "\n",
    "search = RandomizedSearchCV(xgb_model, param_distributions=params, random_state=42, n_iter=200, cv=5, verbose=1, n_jobs=1, return_train_score=True)\n",
    "\n",
    "search.fit(X_train, y_train)\n",
    "\n",
    "report_best_scores(search.cv_results_, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "5ba6349d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with rank: 1\n",
      "Mean validation score: 0.957 (std: 0.007)\n",
      "Parameters: {'colsample_bytree': 0.8167605036202489, 'gamma': 0.00541882574014918, 'learning_rate': 0.3016145929257791, 'max_depth': 5, 'n_estimators': 108, 'subsample': 0.7277254550361659}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report_best_scores(search.cv_results_, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "7cfbef94",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = xgb.XGBClassifier(objective=\"binary:logistic\", random_state=0, colsample_bytree=0.81676, gamma = 0.005419, learning_rate = 0.3016145, max_depth = 5, n_estimators = 108, subsample = 0.7277)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "predicted_values = xgb_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "c1feb028",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94.6031746031746"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = metrics.accuracy_score(y_test, predicted_values) * 100\n",
    "acc.append(x)\n",
    "model.append('XGBoost')\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "518b15e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.98      0.97       521\n",
      "         1.0       0.91      0.81      0.85       109\n",
      "\n",
      "    accuracy                           0.95       630\n",
      "   macro avg       0.93      0.90      0.91       630\n",
      "weighted avg       0.95      0.95      0.95       630\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Classification report and breakdown\n",
    "print(classification_report(y_test,predicted_values))\n",
    "\n",
    "y_pred = xgb_model.predict(X_test)\n",
    "y_true = y_test\n",
    "\n",
    "cm_XGB = confusion_matrix(y_true,y_pred)\n",
    "\n",
    "f, ax = plt.subplots(figsize=(10,8))\n",
    "sns.heatmap(cm_XGB, annot=True, linewidth=0.5, fmt=\".0f\",cmap='viridis', ax = ax)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Actual vs. Predicted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "5710ee2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy =  0.9912698412698413\n",
      "Testing accuracy =  0.9523809523809523\n"
     ]
    }
   ],
   "source": [
    "# Storing the accuracy values for model results comparison later\n",
    "\n",
    "#Print Train Accuracy\n",
    "xgb_train_accuracy = metrics.accuracy_score(y_train, xgb_model.predict(X_train))\n",
    "print(\"Training accuracy = \",metrics.accuracy_score(y_train, xgb_model.predict(X_train)))\n",
    "\n",
    "#Print Test Accuracy\n",
    "xgb_test_accuracy = metrics.accuracy_score(y_test, xgb_model.predict(X_test))\n",
    "print(\"Testing accuracy = \",metrics.accuracy_score(y_test, xgb_model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "30825a62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation score:  [0.93015873 0.93174603 0.91587302 0.92698413 0.92539683]\n"
     ]
    }
   ],
   "source": [
    "# Cross validation on dataset\n",
    "score = cross_val_score(ada, X, y, cv=5)\n",
    "print('Cross validation score: ',score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "552a6b79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9260317460317461"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mean score\n",
    "score.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d59f76",
   "metadata": {},
   "source": [
    "## Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "f467a373",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=[10,4],dpi = 100, facecolor='white')\n",
    "plt.title('Accuracy Comparison')\n",
    "plt.xlabel('Accuracy')\n",
    "plt.ylabel('ML Algorithms')\n",
    "sns.barplot(x = acc,y = model,palette='viridis')\n",
    "print(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "48d460ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.846031746031746,\n",
       " 0.8539682539682539,\n",
       " 0.8809523809523809,\n",
       " 0.946031746031746,\n",
       " 0.9349206349206349,\n",
       " 0.9349206349206349,\n",
       " 0.9349206349206349,\n",
       " 0.9523809523809523,\n",
       " 0.8539682539682539,\n",
       " 0.946031746031746,\n",
       " 0.946031746031746,\n",
       " 94.6031746031746,\n",
       " 0.946031746031746,\n",
       " 94.6031746031746,\n",
       " 88.09523809523809,\n",
       " 95.23809523809523]"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "71505319",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Logistic Regression',\n",
       " 'SVM',\n",
       " 'Logistic Regression',\n",
       " 'Random Forest',\n",
       " 'AdaBoost',\n",
       " 'AdaBoost',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'SVM',\n",
       " 'Random Forest',\n",
       " 'AdaBoost',\n",
       " 'AdaBoost',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'Logistic Regression',\n",
       " 'Single_Layer Perceptron']"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12806ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dfc4337",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a046a6f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532ffcef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b100da67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ecd2c7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67fb7d9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf2a505",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992e7156",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
